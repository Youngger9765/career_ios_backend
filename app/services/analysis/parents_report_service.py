"""
Parents Report Service - Generates parent-child dialogue reports

Extracted from session_analysis.py for better modularity.
Handles RAG retrieval, prompt construction, and report generation.
"""

import json
import logging
import re
import time
from typing import TYPE_CHECKING, Dict, List, Tuple

from sqlalchemy.orm import Session as DBSession

from app.services.utils.ai_validation import validate_ai_output_length

if TYPE_CHECKING:
    from app.models.session import Session
    from app.schemas.session import ParentsReportReference

logger = logging.getLogger(__name__)


class ParentsReportService:
    """Service for generating parent-child dialogue reports"""

    def __init__(self, db: DBSession):
        self.db = db

    async def generate_report(
        self,
        session: "Session",
        transcript: str,
        use_rag: bool = True,
    ) -> Tuple[Dict, List["ParentsReportReference"], List[str], int, Dict]:
        """
        Generate a parent-child dialogue report.

        Args:
            session: Session model with scenario info
            transcript: Full transcript text
            use_rag: Whether to use RAG for theory references

        Returns:
            Tuple of (analysis_dict, rag_references, rag_sources, latency_ms, token_usage)
        """
        from app.services.external.gemini_service import GeminiService

        start_time = time.time()

        # RAG: Retrieve relevant parenting theories
        rag_context = ""
        rag_sources = []
        rag_references = []

        if use_rag:
            rag_context, rag_sources, rag_references = await self._retrieve_rag_context(
                session, transcript
            )

        # Build prompt with optional RAG context
        prompt = self._build_report_prompt(session, transcript, rag_context)

        # Call Gemini
        gemini_service = GeminiService()
        gemini_response = await gemini_service.chat_completion(
            prompt=prompt,
            temperature=0.7,
            return_metadata=True,
        )

        llm_raw_response = gemini_response["text"]

        # Parse response
        analysis = self._parse_report_response(llm_raw_response)

        # Calculate latency
        latency_ms = int((time.time() - start_time) * 1000)
        logger.info(f"Report generated in {latency_ms}ms")

        # Extract usage metadata from Gemini response
        usage_metadata = gemini_response.get("usage_metadata", {})
        prompt_tokens = usage_metadata.get("prompt_token_count", 0) or 0
        completion_tokens = usage_metadata.get("candidates_token_count", 0) or 0
        total_tokens = usage_metadata.get("total_token_count", 0) or 0

        # Calculate Gemini Flash 1.5 cost using centralized pricing
        from app.core.pricing import (
            GEMINI_1_5_FLASH_REPORT_INPUT_USD_PER_1M_TOKENS,
            GEMINI_1_5_FLASH_REPORT_OUTPUT_USD_PER_1M_TOKENS,
            calculate_gemini_cost,
        )

        estimated_cost_usd = calculate_gemini_cost(
            input_tokens=prompt_tokens,
            output_tokens=completion_tokens,
            input_price_per_1m=GEMINI_1_5_FLASH_REPORT_INPUT_USD_PER_1M_TOKENS,
            output_price_per_1m=GEMINI_1_5_FLASH_REPORT_OUTPUT_USD_PER_1M_TOKENS,
        )

        # Build token usage data
        token_usage = {
            "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens,
            "total_tokens": total_tokens,
            "estimated_cost_usd": estimated_cost_usd,
            "model_name": gemini_service.model_name,
            "provider": "gemini",
            "llm_raw_response": llm_raw_response,
        }

        return analysis, rag_references, rag_sources, latency_ms, token_usage

    async def _retrieve_rag_context(
        self,
        session: "Session",
        transcript: str,
    ) -> Tuple[str, List[str], List["ParentsReportReference"]]:
        """Retrieve RAG context for report generation"""
        from app.schemas.session import ParentsReportReference
        from app.services.external.openai_service import OpenAIService
        from app.services.rag.rag_retriever import RAGRetriever

        rag_context = ""
        rag_sources = []
        rag_references = []

        try:
            openai_service = OpenAIService()
            rag_retriever = RAGRetriever(openai_service)

            # Build a more effective search query
            scenario_info = session.scenario or ""
            scenario_desc = session.scenario_description or ""
            search_query = f"{scenario_info} {scenario_desc}\n{transcript[:800]}"
            logger.info(f"RAG search query (first 200 chars): {search_query[:200]}...")

            # Search for parenting-related theories
            rag_results = await rag_retriever.search(
                query=search_query,
                top_k=5,
                threshold=0.25,  # Lower threshold for better recall
                db=self.db,
                category="parenting",
            )

            if rag_results:
                rag_context = "\n\nã€åƒè€ƒç†è«–ã€‘\n"
                for i, theory in enumerate(rag_results, 1):
                    theory_text = theory.get("text", "")[:200]
                    theory_doc = theory.get("document", "")
                    theory_title = theory.get("title", theory_doc)
                    theory_category = theory.get("category", "æ•™é¤Šç†è«–")

                    rag_context += f"{i}. {theory_text}... (ä¾†æº: {theory_doc})\n"
                    rag_sources.append(theory_doc)

                    # Build reference for response
                    rag_references.append(
                        ParentsReportReference(
                            title=theory_title,
                            content=theory_text,
                            source=theory_doc,
                            theory=theory_category,
                        )
                    )
                logger.info(f"RAG found {len(rag_results)} theories for report")
            else:
                logger.warning(
                    "RAG search returned no results - "
                    "check if parenting documents exist in vector DB"
                )
        except Exception as e:
            # RAG failure should not block report generation
            logger.warning(f"RAG search failed (continuing without RAG): {e}")

        return rag_context, rag_sources, rag_references

    def _build_report_prompt(
        self,
        session: "Session",
        transcript: str,
        rag_context: str,
    ) -> str:
        """Build the analysis prompt for report generation"""
        # Build RAG instruction if we have context
        rag_instruction = ""
        if rag_context:
            rag_instruction = """
ã€é‡è¦ã€‘è«‹åƒè€ƒä¸Šè¿°ç†è«–ä¾†æ”¯æŒä½ çš„åˆ†æå’Œå»ºè­°ã€‚åœ¨ analyze å’Œ suggestion ä¸­å¯ä»¥å¼•ç”¨ç›¸é—œç†è«–ã€‚
"""

        # Calculate transcript duration hint
        transcript_length = len(transcript)
        duration_hint = (
            "çŸ­å°è©±"
            if transcript_length < 500
            else "ä¸­ç­‰å°è©±"
            if transcript_length < 2000
            else "é•·å°è©±"
        )

        # Build scenario context for report
        scenario_section = ""
        if session.scenario or session.scenario_description:
            scenario_section = f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€å®¶é•·ç…©æƒ±æƒ…å¢ƒã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{session.scenario or ''}
{session.scenario_description or ''}

âš ï¸ è«‹åœç¹ä¸Šè¿°å®¶é•·çš„ç…©æƒ±æƒ…å¢ƒé€²è¡Œåˆ†æï¼Œæä¾›é‡å°æ€§çš„å»ºè­°ã€‚
"""

        return f"""ä½ æ˜¯å°ˆæ¥­çš„è¦ªå­æºé€šåˆ†æå¸«ï¼Œç²¾é€š 8 å¤§æ•™é¤Šæµæ´¾ï¼ˆé˜¿å¾·å‹’æ­£å‘æ•™é¤Šã€è–©æçˆ¾ã€ABAè¡Œç‚ºåˆ†æã€Dan Siegel å…¨è…¦æ•™é¤Šã€Gottman æƒ…ç·’è¼”å°ã€Ross Greene å”ä½œå•é¡Œè§£æ±ºã€Dr. Becky Kennedyã€ç¤¾æœƒæ„è­˜æ•™é¤Šï¼‰ï¼Œè² è²¬åˆ†æå®¶é•·èˆ‡å­©å­çš„å°è©±ï¼Œæä¾›å»ºè¨­æ€§çš„å›é¥‹ã€‚
{scenario_section}{rag_context}{rag_instruction}
ã€å°è©±é€å­—ç¨¿ã€‘ï¼ˆ{duration_hint}ï¼Œå…± {transcript_length} å­—ï¼‰
{transcript}

ã€åˆ†æè¦æ±‚ã€‘
è«‹ä»¥ä¸­æ€§ã€å®¢è§€ã€æº«å’Œçš„ç«‹å ´**æ·±å…¥åˆ†æ**é€™æ¬¡å°è©±ã€‚
âš ï¸ é‡è¦ï¼šè«‹æ ¹æ“šå°è©±é•·åº¦æä¾›**ç›¸æ‡‰æ·±åº¦çš„åˆ†æ**ï¼š
- çŸ­å°è©±ï¼ˆ< 500 å­—ï¼‰ï¼šæä¾›åŸºæœ¬åˆ†æ
- ä¸­ç­‰å°è©±ï¼ˆ500-2000 å­—ï¼‰ï¼šæä¾›è©³ç´°åˆ†æï¼ŒåŒ…å«å¤šå€‹è§€å¯Ÿé»
- é•·å°è©±ï¼ˆ> 2000 å­—ï¼‰ï¼šæä¾›å®Œæ•´ã€æ·±å…¥çš„åˆ†æï¼Œæ¶µè“‹å°è©±ä¸­çš„å„å€‹é—œéµæ™‚åˆ»

è«‹æä¾›ä»¥ä¸‹ 4 å€‹éƒ¨åˆ†ï¼š

1. **é¼“å‹µæ¨™é¡Œ**ï¼ˆencouragementï¼‰
   - âš ï¸ **å¿…é ˆ 15 å­—ä»¥å…§**ï¼ˆé€™æ˜¯ç¡¬æ€§é™åˆ¶ï¼ï¼‰
   - ä¸€å¥å…·é«”çš„æ­£å‘è§€å¯Ÿï¼ŒæŒ‡å‡ºå®¶é•·åšå¾—å¥½çš„åœ°æ–¹
   - ä¸è¦ç”¨ã€Œå¾ˆæ£’ã€ã€Œå¾ˆå¥½ã€ç­‰ç©ºæ³›è©å½™
   - ä¾‹å¦‚ï¼šã€Œä½ æ²’æ€¥è‘—åé§ã€ã€ã€Œæœ‰çµ¦å­©å­èªªçš„ç©ºé–“ã€ã€ã€Œé€™æ¬¡æœ‰åœ¨åŒç†ã€ã€ã€Œä½ æ­£åœ¨æ¥ä½å­©å­ã€

2. **å¾…è§£æ±ºçš„è­°é¡Œ**ï¼ˆissueï¼‰
   - æŒ‡å‡ºé€™æ¬¡å°è©±ä¸­æœ€éœ€è¦æ”¹é€²çš„åœ°æ–¹
   - å®¢è§€æè¿°ï¼Œä¸æ‰¹åˆ¤
   - å¦‚æœå°è©±è¼ƒé•·ï¼Œå¯ä»¥åˆ—å‡ºå¤šå€‹è­°é¡Œ

3. **æºé€šå…§å®¹åˆ†æ**ï¼ˆanalyzeï¼‰
   - **æ·±å…¥åˆ†æ**ç‚ºä½•é€™æ¨£çš„æºé€šæ–¹å¼å¯èƒ½æœ‰å•é¡Œ
   - è§£é‡‹èƒŒå¾Œçš„å¿ƒç†å­¸æˆ–æ•™é¤Šç†è«–åŸç†
   - å¼•ç”¨ç›¸é—œæ•™é¤Šæµæ´¾çš„è§€é»ï¼ˆå¦‚ï¼šè–©æçˆ¾å†°å±±ç†è«–ã€é˜¿å¾·å‹’æ­¸å±¬æ„Ÿã€Gottman æƒ…ç·’è¼”å°ç­‰ï¼‰
   - åˆ†æå°è©±ä¸­çš„æƒ…ç·’å‹•æ…‹ã€æ¬ŠåŠ›é—œä¿‚ã€æºé€šæ¨¡å¼
   - âš ï¸ å°æ–¼é•·å°è©±ï¼Œè«‹æä¾›å®Œæ•´ã€è©³ç›¡çš„åˆ†æï¼ˆ300-500 å­—ï¼‰

4. **å»ºè­°ä¸‹æ¬¡å¯ä»¥é€™æ¨£èªª**ï¼ˆsuggestionï¼‰
   - æä¾›å…·é«”ã€å¯ç›´æ¥ä½¿ç”¨çš„æ›¿ä»£èªªæ³•
   - ç”¨ã€Œã€æ¨™ç¤ºå»ºè­°çš„è©±èª
   - æä¾›å¤šå€‹æƒ…å¢ƒä¸‹çš„å»ºè­°è©±è¡“
   - è§£é‡‹ç‚ºä»€éº¼é€™æ¨£èªªæ›´æœ‰æ•ˆ
   - âš ï¸ å°æ–¼é•·å°è©±ï¼Œæä¾›å¤šç¨®æƒ…å¢ƒçš„å»ºè­°ï¼ˆ200-400 å­—ï¼‰

ã€èªæ°£è¦æ±‚ã€‘
- æº«å’Œã€åŒç†ã€å»ºè¨­æ€§
- é¿å…æ‰¹åˆ¤æˆ–è®“å®¶é•·æ„Ÿåˆ°è¢«æŒ‡è²¬
- âš ï¸ èªè¨€é¢¨æ ¼ï¼šç”¨ç”Ÿæ´»åŒ–ã€å£èªåŒ–çš„æ–¹å¼è¡¨é”ï¼Œåƒä¸€å€‹æœ‰ç¶“é©—çš„æœ‹å‹åœ¨åˆ†äº«è‚²å…’å¿ƒå¾—
- âš ï¸ å°ˆæ¥­è¡“èªä½¿ç”¨åŸå‰‡ï¼š
  - é©åº¦ä¿ç•™ç°¡å–®æ˜“æ‡‚çš„å°ˆæ¥­è©å½™ï¼ˆå¦‚ã€ŒåŒç†ã€ã€Œç•Œé™ã€ã€Œæƒ…ç·’ã€ã€Œæ­¸å±¬æ„Ÿã€ã€Œåƒ¹å€¼æ„Ÿã€ï¼‰ï¼Œå±•ç¾å°ˆæ¥­å¯ä¿¡åº¦
  - é¿å…éåº¦å­¸è¡“åŒ–çš„è¡¨è¿°ï¼ˆå¦‚ã€Œå†°å±±ç†è«–ã€ã€Œæƒ…ç·’æ•™ç·´æ™‚åˆ»ã€ã€Œé»ƒé‡‘æƒ…ç·’æ•™è‚²æ™‚åˆ»ã€ã€Œæ¬ŠåŠ›é¬¥çˆ­å¾ªç’°ã€ï¼‰
  - ä¸è¦ç›´æ¥å¼•ç”¨å°ˆå®¶åå­—ï¼ˆå¦‚ Gottmanã€é˜¿å¾·å‹’ã€è–©æçˆ¾ã€Dan Siegelã€Ross Greeneã€Dr. Becky Kennedy ç­‰ï¼‰
  - æ”¹ç”¨ã€Œç ”ç©¶ç™¼ç¾...ã€ã€Œå°ˆå®¶å»ºè­°...ã€ã€Œå¿ƒç†å­¸ç ”ç©¶é¡¯ç¤º...ã€ç­‰ä¸­æ€§è¡¨è¿°
- âš ï¸ ç†è«–æ¦‚å¿µè½‰è­¯ï¼š
  - ã€Œæƒ…ç·’æ•™ç·´ã€â†’ã€Œé™ªä¼´å­©å­é¢å°æƒ…ç·’ã€
  - ã€Œé»ƒé‡‘æ™‚åˆ»ã€â†’ã€Œå¾ˆé›£å¾—çš„æ™‚åˆ»ã€ã€Œå¥½æ©Ÿæœƒã€
  - ã€Œå†°å±±ç†è«–ã€â†’ã€Œè¡¨é¢è¡Œç‚ºèƒŒå¾Œçš„çœŸæ­£éœ€æ±‚ã€ã€Œå­©å­çœŸæ­£æƒ³èªªçš„ã€
  - ã€Œæ¬ŠåŠ›é¬¥çˆ­ã€â†’ã€Œè¦ªå­ä¹‹é–“çš„æ‹‰æ‰¯ã€ã€Œå°ç«‹ã€
  - ã€Œå’Œå–„è€Œå …å®šã€â†’ã€Œæº«æŸ”ä½†å …å®šã€ã€Œç†è§£ä½†ä¸ç¸±å®¹ã€
- å±•ç¾å°ˆæ¥­æ·±åº¦ï¼Œä½†ç”¨å®¶é•·è½å¾—æ‡‚çš„è©±
- å¯ä»¥èªªç†è«–è§€é»ï¼Œä½†è¦ç”¨æ•…äº‹åŒ–ã€æƒ…å¢ƒåŒ–çš„æ–¹å¼è§£é‡‹

ã€è¼¸å‡ºæ ¼å¼ã€‘
è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š

{{
  "encouragement": "15 å­—ä»¥å…§çš„é¼“å‹µæ¨™é¡Œ",
  "issue": "å¾…è§£æ±ºçš„è­°é¡Œï¼ˆå¯ä»¥æ˜¯å¤šé»ï¼Œç”¨æ›è¡Œåˆ†éš”ï¼‰",
  "analyze": "æºé€šå…§å®¹æ·±å…¥åˆ†æï¼ˆæ ¹æ“šå°è©±é•·åº¦ï¼Œæä¾› 150-500 å­—çš„åˆ†æï¼‰",
  "suggestion": "å»ºè­°ä¸‹æ¬¡å¯ä»¥é€™æ¨£èªªï¼ˆæä¾›å¤šå€‹æƒ…å¢ƒçš„å…·é«”è©±è¡“ï¼Œ150-400 å­—ï¼‰"
}}

è«‹é–‹å§‹æ·±å…¥åˆ†æã€‚"""

    MAX_ENCOURAGEMENT_CHARS = 15  # é¼“å‹µæ¨™é¡Œæœ€å¤§å­—æ•¸

    def _parse_report_response(self, llm_raw_response: str) -> Dict:
        """Parse LLM response to extract report data"""
        try:
            if "```json" in llm_raw_response:
                json_start = llm_raw_response.find("```json") + 7
                json_end = llm_raw_response.find("```", json_start)
                json_text = llm_raw_response[json_start:json_end].strip()
            elif "{" in llm_raw_response:
                json_start = llm_raw_response.find("{")
                json_end = llm_raw_response.rfind("}") + 1
                json_text = llm_raw_response[json_start:json_end]
            else:
                raise ValueError("No JSON found in response")

            json_text = re.sub(r",(\s*[}\]])", r"\1", json_text)
            result = json.loads(json_text)

            # Validate encouragement field using centralized helper
            if "encouragement" in result:
                encouragement = result["encouragement"]
                validated = validate_ai_output_length(
                    text=encouragement,
                    min_chars=4,  # Minimum meaningful encouragement
                    max_chars=self.MAX_ENCOURAGEMENT_CHARS,  # 15 chars
                    field_name="encouragement",
                )
                if validated is None:
                    # Too short - use a default
                    result["encouragement"] = "ä½ æ­£åœ¨é€²æ­¥ä¸­"  # 6 chars
                    logger.warning(
                        f"Encouragement too short, using default: {result['encouragement']}"
                    )
                else:
                    result["encouragement"] = validated

            return result

        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"Failed to parse report response: {e}")
            raise ValueError(f"Failed to parse AI response: {e}")

    def save_report_record(
        self,
        session_id,
        client_id,
        counselor_id,
        tenant_id: str,
        analysis: Dict,
        rag_references: List["ParentsReportReference"],
        token_usage: Dict,
    ) -> None:
        """Create or update Report record in database"""
        from sqlalchemy import select

        from app.models.report import Report, ReportStatus

        try:
            existing_report = self.db.execute(
                select(Report).where(
                    Report.session_id == session_id,
                    Report.deleted_at.is_(None),
                )
            ).scalar_one_or_none()

            # Build content for Report
            report_content_json = {
                "encouragement": analysis.get("encouragement", ""),
                "issue": analysis.get("issue", ""),
                "analyze": analysis.get("analyze", ""),
                "suggestion": analysis.get("suggestion", ""),
                "references": [ref.model_dump() for ref in rag_references],
            }

            # Build markdown content
            report_content_markdown = f"""# è¦ªå­å°è©±å ±å‘Š

## ğŸŒŸ é¼“å‹µ
{analysis.get("encouragement", "")}

## ğŸ’¡ å¾…è§£æ±ºçš„è­°é¡Œ
{analysis.get("issue", "")}

## ğŸ“Š æºé€šå…§å®¹åˆ†æ
{analysis.get("analyze", "")}

## ğŸ’¬ å»ºè­°ä¸‹æ¬¡å¯ä»¥é€™æ¨£èªª
{analysis.get("suggestion", "")}
"""

            if existing_report:
                # Update existing report
                existing_report.content_json = report_content_json
                existing_report.content_markdown = report_content_markdown
                existing_report.status = ReportStatus.DRAFT
                existing_report.prompt_tokens = token_usage.get("prompt_tokens", 0)
                existing_report.completion_tokens = token_usage.get(
                    "completion_tokens", 0
                )
                logger.info(f"Updated existing Report for session {session_id}")
            else:
                # Create new report
                new_report = Report(
                    session_id=session_id,
                    client_id=client_id,
                    created_by_id=counselor_id,
                    tenant_id=tenant_id,
                    status=ReportStatus.DRAFT,
                    mode="island_parents",
                    content_json=report_content_json,
                    content_markdown=report_content_markdown,
                    prompt_tokens=token_usage.get("prompt_tokens", 0),
                    completion_tokens=token_usage.get("completion_tokens", 0),
                )
                self.db.add(new_report)
                logger.info(f"Created new Report for session {session_id}")

            self.db.commit()
        except Exception as e:
            # Report creation failure should not block response
            logger.error(f"Failed to create/update Report record: {e}", exc_info=True)
            self.db.rollback()
