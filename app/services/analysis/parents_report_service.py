"""
Parents Report Service - Generates parent-child dialogue reports

Extracted from session_analysis.py for better modularity.
Handles RAG retrieval, prompt construction, and report generation.
"""

import json
import logging
import re
import time
from typing import TYPE_CHECKING, Dict, List, Tuple

from sqlalchemy.orm import Session as DBSession

if TYPE_CHECKING:
    from app.models.session import Session
    from app.schemas.session import ParentsReportReference

logger = logging.getLogger(__name__)


class ParentsReportService:
    """Service for generating parent-child dialogue reports"""

    def __init__(self, db: DBSession):
        self.db = db

    async def generate_report(
        self,
        session: "Session",
        transcript: str,
        use_rag: bool = True,
    ) -> Tuple[Dict, List["ParentsReportReference"], List[str], int, Dict]:
        """
        Generate a parent-child dialogue report.

        Args:
            session: Session model with scenario info
            transcript: Full transcript text
            use_rag: Whether to use RAG for theory references

        Returns:
            Tuple of (analysis_dict, rag_references, rag_sources, latency_ms, token_usage)
        """
        from app.services.external.gemini_service import GeminiService

        start_time = time.time()

        # RAG: Retrieve relevant parenting theories
        rag_context = ""
        rag_sources = []
        rag_references = []

        if use_rag:
            rag_context, rag_sources, rag_references = await self._retrieve_rag_context(
                session, transcript
            )

        # Build prompt with optional RAG context
        prompt = self._build_report_prompt(session, transcript, rag_context)

        # Call Gemini
        gemini_service = GeminiService()
        gemini_response = await gemini_service.chat_completion(
            prompt=prompt,
            temperature=0.7,
            return_metadata=True,
        )

        llm_raw_response = gemini_response["text"]

        # Parse response
        analysis = self._parse_report_response(llm_raw_response)

        # Calculate latency
        latency_ms = int((time.time() - start_time) * 1000)
        logger.info(f"Report generated in {latency_ms}ms")

        # Build token usage data
        token_usage = {
            "prompt_tokens": gemini_response.get("prompt_tokens", 0),
            "completion_tokens": gemini_response.get("completion_tokens", 0),
            "total_tokens": gemini_response.get("total_tokens", 0),
            "estimated_cost_usd": gemini_response.get("estimated_cost_usd", 0),
            "llm_raw_response": llm_raw_response,
        }

        return analysis, rag_references, rag_sources, latency_ms, token_usage

    async def _retrieve_rag_context(
        self,
        session: "Session",
        transcript: str,
    ) -> Tuple[str, List[str], List["ParentsReportReference"]]:
        """Retrieve RAG context for report generation"""
        from app.schemas.session import ParentsReportReference
        from app.services.external.openai_service import OpenAIService
        from app.services.rag.rag_retriever import RAGRetriever

        rag_context = ""
        rag_sources = []
        rag_references = []

        try:
            openai_service = OpenAIService()
            rag_retriever = RAGRetriever(openai_service)

            # Build a more effective search query
            scenario_info = session.scenario or ""
            scenario_desc = session.scenario_description or ""
            search_query = f"{scenario_info} {scenario_desc}\n{transcript[:800]}"
            logger.info(f"RAG search query (first 200 chars): {search_query[:200]}...")

            # Search for parenting-related theories
            rag_results = await rag_retriever.search(
                query=search_query,
                top_k=5,
                threshold=0.25,  # Lower threshold for better recall
                db=self.db,
                category="parenting",
            )

            if rag_results:
                rag_context = "\n\nã€åƒè€ƒç†è«–ã€‘\n"
                for i, theory in enumerate(rag_results, 1):
                    theory_text = theory.get("text", "")[:200]
                    theory_doc = theory.get("document", "")
                    theory_title = theory.get("title", theory_doc)
                    theory_category = theory.get("category", "æ•™é¤Šç†è«–")

                    rag_context += f"{i}. {theory_text}... (ä¾†æº: {theory_doc})\n"
                    rag_sources.append(theory_doc)

                    # Build reference for response
                    rag_references.append(
                        ParentsReportReference(
                            title=theory_title,
                            content=theory_text,
                            source=theory_doc,
                            theory=theory_category,
                        )
                    )
                logger.info(f"RAG found {len(rag_results)} theories for report")
            else:
                logger.warning(
                    "RAG search returned no results - "
                    "check if parenting documents exist in vector DB"
                )
        except Exception as e:
            # RAG failure should not block report generation
            logger.warning(f"RAG search failed (continuing without RAG): {e}")

        return rag_context, rag_sources, rag_references

    def _build_report_prompt(
        self,
        session: "Session",
        transcript: str,
        rag_context: str,
    ) -> str:
        """Build the analysis prompt for report generation"""
        # Build RAG instruction if we have context
        rag_instruction = ""
        if rag_context:
            rag_instruction = """
ã€é‡è¦ã€‘è«‹åƒè€ƒä¸Šè¿°ç†è«–ä¾†æ”¯æŒä½ çš„åˆ†æå’Œå»ºè­°ã€‚åœ¨ analyze å’Œ suggestion ä¸­å¯ä»¥å¼•ç”¨ç›¸é—œç†è«–ã€‚
"""

        # Calculate transcript duration hint
        transcript_length = len(transcript)
        duration_hint = (
            "çŸ­å°è©±"
            if transcript_length < 500
            else "ä¸­ç­‰å°è©±"
            if transcript_length < 2000
            else "é•·å°è©±"
        )

        # Build scenario context for report
        scenario_section = ""
        if session.scenario or session.scenario_description:
            scenario_section = f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€å®¶é•·ç…©æƒ±æƒ…å¢ƒã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{session.scenario or ''}
{session.scenario_description or ''}

âš ï¸ è«‹åœç¹ä¸Šè¿°å®¶é•·çš„ç…©æƒ±æƒ…å¢ƒé€²è¡Œåˆ†æï¼Œæä¾›é‡å°æ€§çš„å»ºè­°ã€‚
"""

        return f"""ä½ æ˜¯å°ˆæ¥­çš„è¦ªå­æºé€šåˆ†æå¸«ï¼Œç²¾é€š 8 å¤§æ•™é¤Šæµæ´¾ï¼ˆé˜¿å¾·å‹’æ­£å‘æ•™é¤Šã€è–©æçˆ¾ã€ABAè¡Œç‚ºåˆ†æã€Dan Siegel å…¨è…¦æ•™é¤Šã€Gottman æƒ…ç·’è¼”å°ã€Ross Greene å”ä½œå•é¡Œè§£æ±ºã€Dr. Becky Kennedyã€ç¤¾æœƒæ„è­˜æ•™é¤Šï¼‰ï¼Œè² è²¬åˆ†æå®¶é•·èˆ‡å­©å­çš„å°è©±ï¼Œæä¾›å»ºè¨­æ€§çš„å›é¥‹ã€‚
{scenario_section}{rag_context}{rag_instruction}
ã€å°è©±é€å­—ç¨¿ã€‘ï¼ˆ{duration_hint}ï¼Œå…± {transcript_length} å­—ï¼‰
{transcript}

ã€åˆ†æè¦æ±‚ã€‘
è«‹ä»¥ä¸­æ€§ã€å®¢è§€ã€æº«å’Œçš„ç«‹å ´**æ·±å…¥åˆ†æ**é€™æ¬¡å°è©±ã€‚
âš ï¸ é‡è¦ï¼šè«‹æ ¹æ“šå°è©±é•·åº¦æä¾›**ç›¸æ‡‰æ·±åº¦çš„åˆ†æ**ï¼š
- çŸ­å°è©±ï¼ˆ< 500 å­—ï¼‰ï¼šæä¾›åŸºæœ¬åˆ†æ
- ä¸­ç­‰å°è©±ï¼ˆ500-2000 å­—ï¼‰ï¼šæä¾›è©³ç´°åˆ†æï¼ŒåŒ…å«å¤šå€‹è§€å¯Ÿé»
- é•·å°è©±ï¼ˆ> 2000 å­—ï¼‰ï¼šæä¾›å®Œæ•´ã€æ·±å…¥çš„åˆ†æï¼Œæ¶µè“‹å°è©±ä¸­çš„å„å€‹é—œéµæ™‚åˆ»

è«‹æä¾›ä»¥ä¸‹ 4 å€‹éƒ¨åˆ†ï¼š

1. **é¼“å‹µæ¨™é¡Œ**ï¼ˆencouragementï¼‰
   - ä¸€æ®µæ­£å‘é¼“å‹µçš„è©±ï¼Œè‚¯å®šå®¶é•·é¡˜æ„æºé€šçš„å¿ƒæ„
   - å…·é«”æŒ‡å‡ºå®¶é•·åšå¾—å¥½çš„åœ°æ–¹
   - ä¾‹å¦‚ï¼šã€Œé€™æ¬¡ä½ å·²ç¶“åšäº†ä¸€ä»¶é‡è¦çš„äº‹ï¼šé¡˜æ„å¥½å¥½è·Ÿå­©å­è«‡ã€‚ç•¶ä½ èªªã€æˆ‘æƒ³è½è½ä½ çš„æƒ³æ³•ã€æ™‚ï¼Œå±•ç¾äº†é–‹æ”¾çš„æ…‹åº¦ã€‚ã€

2. **å¾…è§£æ±ºçš„è­°é¡Œ**ï¼ˆissueï¼‰
   - æŒ‡å‡ºé€™æ¬¡å°è©±ä¸­æœ€éœ€è¦æ”¹é€²çš„åœ°æ–¹
   - å®¢è§€æè¿°ï¼Œä¸æ‰¹åˆ¤
   - å¦‚æœå°è©±è¼ƒé•·ï¼Œå¯ä»¥åˆ—å‡ºå¤šå€‹è­°é¡Œ

3. **æºé€šå…§å®¹åˆ†æ**ï¼ˆanalyzeï¼‰
   - **æ·±å…¥åˆ†æ**ç‚ºä½•é€™æ¨£çš„æºé€šæ–¹å¼å¯èƒ½æœ‰å•é¡Œ
   - è§£é‡‹èƒŒå¾Œçš„å¿ƒç†å­¸æˆ–æ•™é¤Šç†è«–åŸç†
   - å¼•ç”¨ç›¸é—œæ•™é¤Šæµæ´¾çš„è§€é»ï¼ˆå¦‚ï¼šè–©æçˆ¾å†°å±±ç†è«–ã€é˜¿å¾·å‹’æ­¸å±¬æ„Ÿã€Gottman æƒ…ç·’è¼”å°ç­‰ï¼‰
   - åˆ†æå°è©±ä¸­çš„æƒ…ç·’å‹•æ…‹ã€æ¬ŠåŠ›é—œä¿‚ã€æºé€šæ¨¡å¼
   - âš ï¸ å°æ–¼é•·å°è©±ï¼Œè«‹æä¾›å®Œæ•´ã€è©³ç›¡çš„åˆ†æï¼ˆ300-500 å­—ï¼‰

4. **å»ºè­°ä¸‹æ¬¡å¯ä»¥é€™æ¨£èªª**ï¼ˆsuggestionï¼‰
   - æä¾›å…·é«”ã€å¯ç›´æ¥ä½¿ç”¨çš„æ›¿ä»£èªªæ³•
   - ç”¨ã€Œã€æ¨™ç¤ºå»ºè­°çš„è©±èª
   - æä¾›å¤šå€‹æƒ…å¢ƒä¸‹çš„å»ºè­°è©±è¡“
   - è§£é‡‹ç‚ºä»€éº¼é€™æ¨£èªªæ›´æœ‰æ•ˆ
   - âš ï¸ å°æ–¼é•·å°è©±ï¼Œæä¾›å¤šç¨®æƒ…å¢ƒçš„å»ºè­°ï¼ˆ200-400 å­—ï¼‰

ã€èªæ°£è¦æ±‚ã€‘
- æº«å’Œã€åŒç†ã€å»ºè¨­æ€§
- é¿å…æ‰¹åˆ¤æˆ–è®“å®¶é•·æ„Ÿåˆ°è¢«æŒ‡è²¬
- å±•ç¾å°ˆæ¥­æ·±åº¦ï¼Œè®“å®¶é•·æ„Ÿå—åˆ°ã€Œæœ‰æ–™ã€çš„åˆ†æ

ã€è¼¸å‡ºæ ¼å¼ã€‘
è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š

{{
  "encouragement": "æ­£å‘é¼“å‹µæ¨™é¡Œï¼ˆåŒ…å«å…·é«”è§€å¯Ÿï¼‰",
  "issue": "å¾…è§£æ±ºçš„è­°é¡Œï¼ˆå¯ä»¥æ˜¯å¤šé»ï¼Œç”¨æ›è¡Œåˆ†éš”ï¼‰",
  "analyze": "æºé€šå…§å®¹æ·±å…¥åˆ†æï¼ˆæ ¹æ“šå°è©±é•·åº¦ï¼Œæä¾› 150-500 å­—çš„åˆ†æï¼‰",
  "suggestion": "å»ºè­°ä¸‹æ¬¡å¯ä»¥é€™æ¨£èªªï¼ˆæä¾›å¤šå€‹æƒ…å¢ƒçš„å…·é«”è©±è¡“ï¼Œ150-400 å­—ï¼‰"
}}

è«‹é–‹å§‹æ·±å…¥åˆ†æã€‚"""

    def _parse_report_response(self, llm_raw_response: str) -> Dict:
        """Parse LLM response to extract report data"""
        try:
            if "```json" in llm_raw_response:
                json_start = llm_raw_response.find("```json") + 7
                json_end = llm_raw_response.find("```", json_start)
                json_text = llm_raw_response[json_start:json_end].strip()
            elif "{" in llm_raw_response:
                json_start = llm_raw_response.find("{")
                json_end = llm_raw_response.rfind("}") + 1
                json_text = llm_raw_response[json_start:json_end]
            else:
                raise ValueError("No JSON found in response")

            json_text = re.sub(r",(\s*[}\]])", r"\1", json_text)
            return json.loads(json_text)

        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"Failed to parse report response: {e}")
            raise ValueError(f"Failed to parse AI response: {e}")

    def save_report_record(
        self,
        session_id,
        client_id,
        counselor_id,
        tenant_id: str,
        analysis: Dict,
        rag_references: List["ParentsReportReference"],
        token_usage: Dict,
    ) -> None:
        """Create or update Report record in database"""
        from sqlalchemy import select

        from app.models.report import Report, ReportStatus

        try:
            existing_report = self.db.execute(
                select(Report).where(
                    Report.session_id == session_id,
                    Report.deleted_at.is_(None),
                )
            ).scalar_one_or_none()

            # Build content for Report
            report_content_json = {
                "encouragement": analysis.get("encouragement", ""),
                "issue": analysis.get("issue", ""),
                "analyze": analysis.get("analyze", ""),
                "suggestion": analysis.get("suggestion", ""),
                "references": [ref.model_dump() for ref in rag_references],
            }

            # Build markdown content
            report_content_markdown = f"""# è¦ªå­å°è©±å ±å‘Š

## ğŸŒŸ é¼“å‹µ
{analysis.get("encouragement", "")}

## ğŸ’¡ å¾…è§£æ±ºçš„è­°é¡Œ
{analysis.get("issue", "")}

## ğŸ“Š æºé€šå…§å®¹åˆ†æ
{analysis.get("analyze", "")}

## ğŸ’¬ å»ºè­°ä¸‹æ¬¡å¯ä»¥é€™æ¨£èªª
{analysis.get("suggestion", "")}
"""

            if existing_report:
                # Update existing report
                existing_report.content_json = report_content_json
                existing_report.content_markdown = report_content_markdown
                existing_report.status = ReportStatus.DRAFT
                existing_report.prompt_tokens = token_usage.get("prompt_tokens", 0)
                existing_report.completion_tokens = token_usage.get(
                    "completion_tokens", 0
                )
                logger.info(f"Updated existing Report for session {session_id}")
            else:
                # Create new report
                new_report = Report(
                    session_id=session_id,
                    client_id=client_id,
                    created_by_id=counselor_id,
                    tenant_id=tenant_id,
                    status=ReportStatus.DRAFT,
                    mode="island_parents",
                    content_json=report_content_json,
                    content_markdown=report_content_markdown,
                    prompt_tokens=token_usage.get("prompt_tokens", 0),
                    completion_tokens=token_usage.get("completion_tokens", 0),
                )
                self.db.add(new_report)
                logger.info(f"Created new Report for session {session_id}")

            self.db.commit()
        except Exception as e:
            # Report creation failure should not block response
            logger.error(f"Failed to create/update Report record: {e}", exc_info=True)
            self.db.rollback()
