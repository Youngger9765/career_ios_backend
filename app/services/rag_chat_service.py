"""Service layer for RAG-powered chat operations"""

import json
import re
from typing import List, Optional, Tuple

from pydantic import BaseModel
from sqlalchemy import Float, Integer, String, bindparam, select, text
from sqlalchemy.orm import Session

from app.models.document import Document
from app.services.openai_service import OpenAIService


class Citation(BaseModel):
    chunk_id: int
    doc_id: int
    document_title: str
    text: str
    similarity_score: float


class IntentResult(BaseModel):
    needs_search: bool
    reason: str


class RAGChatService:
    """Service for RAG chat operations"""

    def __init__(self, db: Session):
        self.db = db
        self.openai_service = OpenAIService()

    async def get_available_documents(self) -> List[str]:
        """Get list of available document titles from database

        Returns:
            List of unique document titles sorted alphabetically
        """
        result = self.db.execute(select(Document.title).distinct())
        doc_titles = [row[0] for row in result.fetchall()]
        return sorted(set(doc_titles))

    def _build_intent_system_prompt(self, doc_titles: List[str]) -> str:
        """Build system prompt for intent classification

        Args:
            doc_titles: List of available document titles

        Returns:
            System prompt string for intent classification
        """
        doc_list = "\n".join([f"- {title}" for title in doc_titles])

        return f"""You are a classifier for a career counseling AI assistant.

Your job: Determine if the question needs to search our professional documents.

ğŸ“š **Available documents in our database:**
{doc_list}

**Document coverage includes:**
- è·æ¶¯è«®è©¢æ¦‚è«–èˆ‡èˆˆè¶£ç†±æƒ… (Career counseling fundamentals & passion exploration)
- å„ªå‹¢è·èƒ½åˆ†æ (Strengths & competency analysis)
- ç”Ÿæ¶¯æˆç†Ÿèˆ‡åƒ¹å€¼è§€ (Career maturity & values)
- æ±‚è·ç­–ç•¥ã€å±¥æ­·èˆ‡é¢è©¦æŠ€å·§ (Job search strategies, resume & interview skills)
- å¿ƒç†è«®è©¢æŠ€å·§ (Psychological counseling techniques)
- ç¶œåˆè·æ¶¯å¯¦æˆ°éŒ¦å›Š (Comprehensive career practice toolkit)
- ä¸»äººæ€ç¶­ (Owner mindset and proactive thinking)
- è·éŠç²¾é¸æ–‡ç«  (Curated career development articles)

Reply ONLY with JSON:
{{"needs_search": true/false, "reason": "brief explanation"}}

âœ… needs_search = TRUE for:
- Career-related questions (è·æ¶¯ã€å·¥ä½œã€æ±‚è·ã€é¢è©¦ã€å±¥æ­·)
- Personal development questions (æˆé•·ã€ç™¼å±•ã€ç›®æ¨™ã€è¦åŠƒã€èˆˆè¶£ã€ç†±æƒ…)
- Life purpose questions (äººç”Ÿæ„ç¾©ã€åƒ¹å€¼è§€ã€æƒ³è¦çš„ç”Ÿæ´»)
- Career confusion or exploration (è¿·èŒ«ã€å›°æƒ‘ã€é¸æ“‡ã€æ¢ç´¢)
- Skill or competency questions (èƒ½åŠ›ã€å„ªå‹¢ã€å°ˆé•·ã€æŠ€èƒ½)
- Work-life balance (å·¥ä½œç”Ÿæ´»å¹³è¡¡ã€å£“åŠ›)
- Career transitions (è½‰è·ã€æ›å·¥ä½œã€è·æ¶¯è½‰æ›)
- Mindset questions (æ€ç¶­ã€å¿ƒæ…‹ã€ä¸»äººæ€ç¶­)
- Any question that MIGHT relate to career counseling or personal development
- **Any question that mentions topics in our document titles**

âŒ needs_search = FALSE ONLY for:
- Pure greetings with no question (åªæ˜¯ã€Œä½ å¥½ã€ã€Œhiã€ã€Œhelloã€)
- System commands (é‡ç½®ã€æ¸…é™¤ã€è¨­å®š)
- Completely unrelated topics (å¤©æ°£ã€æ•¸å­¸è¨ˆç®—ã€å¨›æ¨‚å…«å¦ã€ä»Šå¤©åƒä»€éº¼)

ğŸ”‘ Key principle: When in doubt, choose TRUE.
Career counseling is broad - almost any life question can relate to career.

Examples:
- "æˆ‘æƒ³è¦æ´»å¾—æ›´å¥½" â†’ TRUE (relates to life purpose & career direction)
- "å› ç‚ºæƒ³è¦æ´»å¾—æ›´å¥½" â†’ TRUE (implies career motivation)
- "å¦‚ä½•æ‰¾åˆ°ç†±æƒ…" â†’ TRUE (passion exploration)
- "æˆ‘å¾ˆè¿·èŒ«" â†’ TRUE (career confusion)
- "ä¸»äººæ€ç¶­æ˜¯ä»€éº¼" â†’ TRUE (we have ä¸»äººæ€ç¶­å…¨.pdf)
- "ä½ å¥½" â†’ FALSE (just greeting)
- "ä»Šå¤©å¤©æ°£å¦‚ä½•" â†’ FALSE (weather)
- "1+1ç­‰æ–¼å¤šå°‘" â†’ FALSE (math calculation)"""

    async def classify_intent(self, question: str) -> IntentResult:
        """Classify if question needs RAG search

        Args:
            question: User's question

        Returns:
            IntentResult with needs_search flag and reason
        """
        doc_titles = await self.get_available_documents()
        intent_system_prompt = self._build_intent_system_prompt(doc_titles)

        intent_check = await self.openai_service.chat_completion(
            messages=[
                {"role": "system", "content": intent_system_prompt},
                {"role": "user", "content": question},
            ],
            temperature=0.2,  # Lower temperature for consistent classification
        )

        # Parse intent response
        try:
            intent_data = json.loads(intent_check)
        except json.JSONDecodeError:
            # Try to extract JSON from response
            json_match = re.search(r"\{.*\}", intent_check, re.DOTALL)
            if json_match:
                intent_data = json.loads(json_match.group(0))
            else:
                # Default to search if parsing fails
                intent_data = {
                    "needs_search": True,
                    "reason": "default to search on parse error",
                }

        return IntentResult(
            needs_search=intent_data.get("needs_search", True),
            reason=intent_data.get("reason", ""),
        )

    async def generate_direct_answer(
        self,
        question: str,
        system_prompt: Optional[str] = None,
        temperature: float = 0.6,
    ) -> str:
        """Generate direct answer without RAG search

        Args:
            question: User's question
            system_prompt: Optional custom system prompt
            temperature: OpenAI temperature parameter

        Returns:
            Direct answer string
        """
        default_system_prompt = (
            "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è·æ¶¯è«®è©¢åŠ©ç†ã€‚æ ¹æ“šå•é¡Œé¡å‹å›ç­”ï¼š\n\n"
            "å¦‚æœæ˜¯æ‰“æ‹›å‘¼ï¼šå‹å–„å›æ‡‰ï¼Œä¸¦ä»‹ç´¹ä½ å¯ä»¥å¹«åŠ©çš„å…§å®¹\n"
            "å¦‚æœæ˜¯é–’èŠï¼šç°¡çŸ­å›æ‡‰ï¼Œå¼•å°å›åˆ°è·æ¶¯ç›¸é—œè©±é¡Œ\n"
            "å¦‚æœè¶…å‡ºç¯„åœï¼šèªªæ˜ä½ çš„å°ˆæ¥­ç¯„åœåœ¨è·æ¶¯è«®è©¢ï¼Œè³‡æ–™åº«åŒ…å«ä»¥ä¸‹ä¸»é¡Œï¼š\n"
            "- è·æ¶¯è«®è©¢æ¦‚è«–èˆ‡èˆˆè¶£ç†±æƒ…\n"
            "- å„ªå‹¢è·èƒ½åˆ†æ\n"
            "- ç”Ÿæ¶¯æˆç†Ÿèˆ‡åƒ¹å€¼è§€\n"
            "- æ±‚è·ç­–ç•¥ã€å±¥æ­·èˆ‡é¢è©¦æŠ€å·§\n"
            "- å¿ƒç†è«®è©¢æŠ€å·§\n"
            "- ç¶œåˆè·æ¶¯å¯¦æˆ°éŒ¦å›Š\n\n"
            "ä½¿ç”¨èˆ‡å•é¡Œç›¸åŒçš„èªè¨€å›ç­”ï¼ˆç¹é«”ä¸­æ–‡æˆ–è‹±æ–‡ï¼‰"
        )

        answer = await self.openai_service.chat_completion(
            messages=[
                {"role": "system", "content": system_prompt or default_system_prompt},
                {"role": "user", "content": question},
            ],
            temperature=temperature,
        )

        return answer

    async def search_similar_chunks(
        self,
        query_embedding: List[float],
        top_k: int,
        similarity_threshold: float,
        chunk_strategy: Optional[str] = None,
        category: Optional[str] = None,
    ) -> List[Tuple]:
        """Search for similar document chunks using vector similarity

        Args:
            query_embedding: Query embedding vector
            top_k: Number of results to return
            similarity_threshold: Minimum similarity score
            chunk_strategy: Optional chunk strategy filter
            category: Optional category filter (e.g., "parenting", "career")

        Returns:
            List of result rows with (chunk_id, doc_id, text, document_title, similarity_score)
        """
        embedding_str = "[" + ",".join(map(str, query_embedding)) + "]"

        # Build params dict and WHERE clause dynamically
        params = {
            "query_embedding": embedding_str,
            "threshold": similarity_threshold,
            "top_k": top_k,
        }

        # Build WHERE clause filters
        where_filters = [
            "1 - (e.embedding <=> CAST(:query_embedding AS vector)) >= :threshold"
        ]

        # Build bindparams list dynamically
        bind_params = [
            bindparam("query_embedding", type_=String),
            bindparam("threshold", type_=Float),
            bindparam("top_k", type_=Integer),
        ]

        # Only add filters and bindparams if values provided
        if chunk_strategy:
            where_filters.append("c.chunk_strategy = :chunk_strategy")
            params["chunk_strategy"] = chunk_strategy
            bind_params.append(bindparam("chunk_strategy", type_=String))

        if category:
            where_filters.append("d.category = :category")
            params["category"] = category
            bind_params.append(bindparam("category", type_=String))

        where_clause = " AND ".join(where_filters)

        # Build query with dynamic filters
        query_sql = text(
            f"""
            SELECT
                c.id as chunk_id,
                c.doc_id,
                c.text,
                d.title as document_title,
                1 - (e.embedding <=> CAST(:query_embedding AS vector)) as similarity_score
            FROM chunks c
            JOIN embeddings e ON c.id = e.chunk_id
            JOIN documents d ON c.doc_id = d.id
            WHERE {where_clause}
            ORDER BY e.embedding <=> CAST(:query_embedding AS vector)
            LIMIT :top_k
        """
        ).bindparams(*bind_params)

        result = self.db.execute(query_sql, params)
        return result.fetchall()

    def build_citations(self, rows: List[Tuple]) -> List[Citation]:
        """Build citation list from search results

        Args:
            rows: Search result rows

        Returns:
            List of Citation objects
        """
        citations = []
        for row in rows:
            citations.append(
                Citation(
                    chunk_id=row.chunk_id,
                    doc_id=row.doc_id,
                    document_title=row.document_title,
                    text=row.text,
                    similarity_score=float(row.similarity_score),
                )
            )
        return citations

    def build_context(self, rows: List[Tuple]) -> str:
        """Build context string from search results

        Args:
            rows: Search result rows

        Returns:
            Formatted context string with numbered citations
        """
        context_parts = []
        for idx, row in enumerate(rows):
            context_parts.append(f"[{idx + 1}] {row.text}")
        return "\n\n".join(context_parts)

    async def generate_rag_answer(
        self,
        question: str,
        context: str,
        system_prompt: Optional[str] = None,
        temperature: float = 0.6,
    ) -> str:
        """Generate answer using RAG context

        Args:
            question: User's question
            context: Retrieved context from documents
            system_prompt: Optional custom system prompt
            temperature: OpenAI temperature parameter

        Returns:
            Generated answer string
        """
        default_system_prompt = (
            "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è·æ¶¯è«®è©¢åŠ©ç†ã€‚æ ¹æ“šæä¾›çš„æ–‡æœ¬ä¾†å›ç­”å•é¡Œã€‚\n\n"
            "å›ç­”æ™‚è«‹éµå¾ªï¼š\n"
            "1. ä¸»è¦æ ¹æ“šæ–‡æœ¬å…§å®¹ä¸¦ç”¨ [1]ã€[2] æ¨™è¨»ä¾†æº\n"
            "2. ä¿æŒå°ˆæ¥­ã€å®¢è§€ä¸”å…·åŒç†å¿ƒçš„èªæ°£\n"
            "3. å¦‚æœæ–‡æœ¬ä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šï¼Œè«‹æ˜ç¢ºèªªæ˜\n"
            "4. é©ç•¶å¼•ç”¨é—œéµæ¦‚å¿µã€ç†è«–å’Œæœ€ä½³å¯¦è¸\n"
            "5. è€ƒæ…®å€‹åˆ¥å·®ç•°å’Œå¤šå…ƒè§€é»\n"
            "6. ä½¿ç”¨èˆ‡å•é¡Œç›¸åŒçš„èªè¨€å›ç­”ï¼ˆç¹é«”ä¸­æ–‡æˆ–è‹±æ–‡ï¼‰"
        )

        answer = await self.openai_service.chat_completion_with_context(
            question=question,
            context=context,
            system_prompt=system_prompt or default_system_prompt,
            temperature=temperature,
        )

        return answer

    def generate_no_results_answer(self, question: str) -> str:
        """Generate guidance answer when no search results found

        Args:
            question: User's question

        Returns:
            Guidance answer string
        """
        # Check if it's a simple greeting
        if question.strip().lower() in ["hello", "hi", "ä½ å¥½", "å—¨", "å“ˆå›‰"]:
            return (
                "ä½ å¥½ï¼æˆ‘æ˜¯è·æ¶¯è«®è©¢ AI åŠ©ç† ğŸ‘‹\n\n"
                "æˆ‘å¯ä»¥å”åŠ©ä½ ï¼š\n"
                "âœ¨ æ¢ç´¢è·æ¶¯èˆˆè¶£èˆ‡ç†±æƒ…\n"
                "âœ¨ åˆ†æå„ªå‹¢è·èƒ½\n"
                "âœ¨ æ±‚è·ç­–ç•¥èˆ‡å±¥æ­·é¢è©¦æŒ‡å°\n"
                "âœ¨ è·æ¶¯ç™¼å±•è¦åŠƒå»ºè­°\n\n"
                "æœ‰ä»€éº¼è·æ¶¯å•é¡Œæƒ³å•æˆ‘å—ï¼Ÿ"
            )

        # Default guidance for no results
        return (
            "æŠ±æ­‰ï¼Œæˆ‘åœ¨è³‡æ–™åº«ä¸­æ‰¾ä¸åˆ°èˆ‡ä½ å•é¡Œç›´æ¥ç›¸é—œçš„å…§å®¹ã€‚\n\n"
            "ğŸ“š æˆ‘çš„çŸ¥è­˜åº«ç›®å‰åŒ…å«ä»¥ä¸‹ä¸»é¡Œï¼š\n"
            "1. è·æ¶¯è«®è©¢æ¦‚è«–èˆ‡èˆˆè¶£ç†±æƒ…æ¢ç´¢\n"
            "2. å„ªå‹¢è·èƒ½åˆ†æèˆ‡ç™¼å±•\n"
            "3. ç”Ÿæ¶¯æˆç†Ÿåº¦èˆ‡åƒ¹å€¼è§€\n"
            "4. æ±‚è·ç­–ç•¥ã€å±¥æ­·æ’°å¯«èˆ‡é¢è©¦æŠ€å·§\n"
            "5. å¿ƒç†è«®è©¢æŠ€å·§èˆ‡å¯¦å‹™\n"
            "6. ç¶œåˆè·æ¶¯å¯¦æˆ°æ¡ˆä¾‹\n\n"
            "ğŸ’¡ å»ºè­°ï¼š\n"
            "- è©¦è‘—ç”¨æ›´å…·é«”çš„è·æ¶¯ç›¸é—œé—œéµå­—é‡æ–°æå•\n"
            "- ä¾‹å¦‚ï¼šã€Œå¦‚ä½•æ¢ç´¢è·æ¶¯èˆˆè¶£ï¼Ÿã€ã€ã€Œå±¥æ­·æ’°å¯«æŠ€å·§ã€ã€ã€Œé¢è©¦æº–å‚™è¦é»ã€\n"
            "- æˆ–ç›´æ¥å•æˆ‘ä¸Šè¿°ä»»ä¸€ä¸»é¡Œçš„å•é¡Œ"
        )
