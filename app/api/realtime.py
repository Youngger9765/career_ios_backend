"""
Realtime STT Counseling API
"""
import logging
import os
import uuid
from datetime import datetime, timezone
from typing import List

import httpx
from fastapi import APIRouter, BackgroundTasks, Depends, HTTPException
from sqlalchemy.orm import Session

from app.core.database import get_db
from app.schemas.realtime import (
    CacheMetadata,
    CodeerTokenMetadata,
    CounselingMode,
    ImprovementSuggestion,
    ParentsReportRequest,
    ParentsReportResponse,
    ProviderMetadata,
    RAGSource,
    RealtimeAnalyzeRequest,
    RealtimeAnalyzeResponse,
    SafetyLevel,
)
from app.services.cache_manager import CacheManager
from app.services.gbq_service import gbq_service
from app.services.gemini_service import GeminiService
from app.services.openai_service import OpenAIService
from app.services.rag_chat_service import RAGChatService

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/v1/realtime", tags=["Realtime Counseling"])

# Initialize services
gemini_service = GeminiService()
openai_service = OpenAIService()
cache_manager = CacheManager()

# Safety assessment sliding window configuration
SAFETY_WINDOW_SPEAKER_TURNS = (
    10  # Number of recent speaker turns to evaluate (~1 minute)
)
SAFETY_WINDOW_CHARACTERS = 300  # Fallback: character count for sliding window

# Annotated window configuration for AI safety assessment
ANNOTATED_SAFETY_WINDOW_TURNS = (
    5  # Last 5-10 turns highlighted for AI safety evaluation
)

# System instruction for cache (å›ºå®šä¸è®Šçš„éƒ¨åˆ†)
CACHE_SYSTEM_INSTRUCTION = """ä½ æ˜¯å°ˆæ¥­è«®è©¢ç£å°ï¼Œåˆ†æå³æ™‚è«®è©¢å°è©±ã€‚ä½ çš„è§’è‰²æ˜¯ç«™åœ¨æ¡ˆä¸»èˆ‡è«®è©¢å¸«ä¹‹é–“ï¼Œæä¾›æº«æš–ã€åŒç†ä¸”å…·é«”å¯è¡Œçš„å°ˆæ¥­å»ºè­°ã€‚

ã€è§’è‰²å®šç¾©ã€‘CRITICAL - å¿…é ˆåš´æ ¼éµå®ˆï¼š
- "counselor" = è«®è©¢å¸«/è¼”å°å¸«ï¼ˆå°ˆæ¥­åŠ©äººè€…ï¼Œæä¾›å”åŠ©çš„ä¸€æ–¹ï¼‰
- "client" = æ¡ˆä¸»/å€‹æ¡ˆ/å®¶é•·ï¼ˆæ±‚åŠ©è€…ï¼Œæœ‰å›°æ“¾éœ€è¦å”åŠ©çš„ä¸€æ–¹ï¼‰
- æ‰€æœ‰å•é¡Œã€å›°æ“¾ã€ç—‡ç‹€éƒ½æ˜¯ã€Œæ¡ˆä¸»/å€‹æ¡ˆã€é¢è‡¨çš„ï¼Œä¸æ˜¯è«®è©¢å¸«çš„å•é¡Œ
- åˆ†æç„¦é»ï¼šæ¡ˆä¸»çš„ç‹€æ³ã€éœ€æ±‚ã€é¢¨éšª
- å»ºè­°å°è±¡ï¼šçµ¦è«®è©¢å¸«çš„å°ˆæ¥­å»ºè­°ï¼ˆå¦‚ä½•å”åŠ©æ¡ˆä¸»ï¼‰

ã€åˆ†æç¯„åœã€‘CRITICAL - å¿…é ˆåš´æ ¼éµå®ˆï¼š
ğŸ¯ **ä¸»è¦åˆ†æç„¦é»**ï¼šæœ€æ–°ä¸€åˆ†é˜å…§çš„å°è©±å…§å®¹
   - ä½ æœƒæ”¶åˆ°å®Œæ•´çš„å°è©±è¨˜éŒ„ï¼ˆå¯èƒ½é•·é”æ•¸ååˆ†é˜ï¼‰
   - ä½†ä½ çš„åˆ†æå¿…é ˆèšç„¦åœ¨ã€Œæœ€å¾Œå‡ºç¾çš„å°è©±ã€ï¼ˆæœ€æ–°ä¸€åˆ†é˜ï¼‰
   - å‰é¢çš„å°è©±åƒ…ä½œç‚ºèƒŒæ™¯è„ˆçµ¡åƒè€ƒï¼Œå¹«åŠ©ä½ ç†è§£å‰å› å¾Œæœ

ã€å®‰å…¨ç­‰ç´šè©•ä¼°è¦å‰‡ã€‘CRITICAL - å¿…é ˆåš´æ ¼éµå®ˆï¼š
âš ï¸ **åƒ…æ ¹æ“šã€Œã€æœ€è¿‘å°è©± - ç”¨æ–¼å®‰å…¨è©•ä¼°ã€‘ã€å€å¡Šåˆ¤æ–·å®‰å…¨ç­‰ç´š**
   - æ¨™è¨»å€å¡Šé¡¯ç¤ºæœ€è¿‘ 5-10 å€‹å°è©±è¼ªæ¬¡
   - ä¸è¦å› ç‚ºå®Œæ•´é€å­—ç¨¿ä¸­å‡ºç¾éçš„å±éšªè©å°±è©•ä¼°ç‚ºé«˜é¢¨éšª
   - å¦‚æœæœ€è¿‘å°è©±å·²ç¶“ç·©å’Œã€æ­£å‘ï¼Œå³ä½¿ä¹‹å‰æœ‰å±éšªå…§å®¹ï¼Œä¹Ÿæ‡‰è©•ä¼°ç‚ºè¼ƒä½é¢¨éšª
   - å®‰å…¨ç­‰ç´šåæ˜ ç•¶å‰ç‹€æ…‹ï¼Œä¸æ˜¯æ­·å²ç‹€æ…‹

ğŸ¯ **å»ºè­°å…§å®¹**ï¼š
   - å¯ä»¥åƒè€ƒå®Œæ•´å°è©±æ­·å²ï¼Œæä¾›æ›´æœ‰æ·±åº¦çš„å»ºè­°
   - ä½†è¦èšç„¦åœ¨æœ€è¿‘å°è©±çš„ç•¶å‰ç‹€æ…‹

ã€æ ¸å¿ƒåŸå‰‡ã€‘åŒç†å„ªå…ˆã€æº«å’Œå¼•å°ã€å…·é«”è¡Œå‹•ï¼š

1. **åŒç†èˆ‡ç†è§£ç‚ºå…ˆ**
   - æ°¸é å…ˆç†è§£èˆ‡åŒç†æ¡ˆä¸»ï¼ˆå®¶é•·ï¼‰çš„æ„Ÿå—å’Œè™•å¢ƒ
   - èªå¯æ•™é¤Šå£“åŠ›ã€æƒ…ç·’å¤±æ§æ˜¯æ­£å¸¸çš„äººæ€§åæ‡‰
   - é¿å…æ‰¹åˆ¤ã€æŒ‡è²¬æˆ–è®“æ¡ˆä¸»æ„Ÿåˆ°è¢«å¦å®š

2. **æº«å’Œã€éæ‰¹åˆ¤çš„èªæ°£**
   - âŒ ç¦æ­¢ç”¨èªï¼šã€Œè¡¨é”å‡ºå°å­©å­ä½¿ç”¨èº«é«”æš´åŠ›çš„è¡å‹•ã€ã€Œå¯èƒ½é€ æˆå‚·å®³ã€ã€Œä¸ç•¶ç®¡æ•™ã€
   - âœ… å»ºè­°ç”¨èªï¼šã€Œç†è§£åˆ°åœ¨æ•™é¤Šå£“åŠ›ä¸‹ï¼Œçˆ¶æ¯æœ‰æ™‚æœƒæ„Ÿåˆ°æƒ…ç·’å¤±æ§æ˜¯å¾ˆæ­£å¸¸çš„ã€
   - âœ… ä½¿ç”¨ï¼šã€Œå¯ä»¥è€ƒæ…®ã€ã€Œæˆ–è¨±ã€ã€Œè©¦è©¦çœ‹ã€ç­‰æŸ”å’Œå¼•å°è©
   - âœ… ç„¦é»æ”¾åœ¨ã€Œå¦‚ä½•èª¿æ•´ã€è€Œéã€Œå“ªè£¡åšéŒ¯ã€

3. **å…·é«”ã€ç°¡æ½”çš„å»ºè­°**
   - å»ºè­°è¦å…·é«”å¯è¡Œï¼Œä½†ä¿æŒç°¡çŸ­ï¼ˆä¸è¶…é 50 å­—ï¼‰
   - é¿å…æŠ½è±¡æ¦‚å¿µï¼Œç”¨å…·é«”åšæ³•
   - ä¸è¦å†—é•·çš„æ­¥é©Ÿèªªæ˜æˆ–å°è©±ç¯„ä¾‹

ã€è¼¸å‡ºæ ¼å¼ã€‘è«‹æä¾›ä»¥ä¸‹ JSON æ ¼å¼å›æ‡‰ï¼š

{
  "summary": "æ¡ˆä¸»è™•å¢ƒç°¡è¿°ï¼ˆ1-2 å¥ï¼‰",
  "alerts": [
    "ğŸ’¡ åŒç†æ¡ˆä¸»æ„Ÿå—ï¼ˆ1 å¥ï¼‰",
    "âš ï¸ éœ€é—œæ³¨çš„éƒ¨åˆ†ï¼ˆ1 å¥ï¼‰"
  ],
  "suggestions": [
    "ğŸ’¡ æ ¸å¿ƒå»ºè­°ï¼ˆç°¡çŸ­ï¼Œ< 50 å­—ï¼‰",
    "ğŸ’¡ å…·é«”åšæ³•ï¼ˆç°¡çŸ­ï¼Œ< 50 å­—ï¼‰"
  ]
}

ã€èªæ°£è¦æ±‚ã€‘æº«å’Œã€åŒç†ã€ç°¡æ½”ï¼Œé¿å…æ‰¹åˆ¤æˆ–éåº¦èªªæ•™

ã€RAG ä½¿ç”¨è¦æ±‚ã€‘CRITICAL - å¿…é ˆåš´æ ¼éµå®ˆï¼š
- ç•¶åˆ†ææ¶‰åŠè¦ªå­æ•™é¤Šã€å…’ç«¥ç™¼å±•ã€ç®¡æ•™ç­–ç•¥ç­‰å°ˆæ¥­çŸ¥è­˜æ™‚ï¼Œå¿…é ˆåƒè€ƒä¸Šæ–¹æä¾›çš„ã€ŒğŸ“š ç›¸é—œè¦ªå­æ•™é¤ŠçŸ¥è­˜åº«å…§å®¹ã€
- å„ªå…ˆä½¿ç”¨çŸ¥è­˜åº«ä¸­çš„ç†è«–ã€æ–¹æ³•ã€å»ºè­°ï¼ˆå¦‚æ­£å‘æ•™é¤Šã€æƒ…ç·’æ•™é¤Šç­‰ï¼‰
- ä¸è¦åƒ…æ†‘ä¸€èˆ¬å¸¸è­˜æˆ–æƒ³åƒå›ç­”å°ˆæ¥­å•é¡Œ
- å¦‚æœçŸ¥è­˜åº«å…§å®¹ç›¸é—œï¼Œè«‹åœ¨å»ºè­°ä¸­èå…¥ï¼ˆä¸éœ€æ˜ç¢ºæ¨™æ³¨ä¾†æºï¼‰
"""

# Parenting-related keywords that trigger RAG search
# Keywords organized by category for better maintainability
PARENTING_KEYWORDS = [
    # === åŸºæœ¬è©å½™ (Basic Terms) ===
    "è¦ªå­",
    "å­©å­",
    "å°å­©",
    "å…’ç«¥",
    "é’å°‘å¹´",
    "æ•™é¤Š",
    "è‚²å…’",
    "ç®¡æ•™",
    "çˆ¶æ¯",
    "åª½åª½",
    "çˆ¸çˆ¸",
    "è¦ªè·",
    "å®¶åº­",
    # === æƒ…ç·’ç›¸é—œ (Emotions) ===
    "æƒ…ç·’",
    "ç”Ÿæ°£",
    "æ†¤æ€’",
    "é›£é",
    "å‚·å¿ƒ",
    "å®³æ€•",
    "ç„¦æ…®",
    "æ“”å¿ƒ",
    "å£“åŠ›",
    "å“­",
    "å“­æ³£",
    "å¤±æœ›",
    "æŒ«æŠ˜",
    # === è¡Œç‚ºå•é¡Œ (Behavior Issues) ===
    "è¡Œç‚º",
    "æ‰“äºº",
    "æ”»æ“Š",
    "æ‹’çµ•",
    "ç™¼è„¾æ°£",
    "å›é€†",
    "ä¸è½è©±",
    "é ‚å˜´",
    # === æ—¥å¸¸å ´æ™¯ (Daily Situations) ===
    "åŠŸèª²",
    "ä½œæ¥­",
    "ç¡è¦º",
    "ç¡çœ ",
    "åƒé£¯",
    "ç”¨é¤",
    "æ”¶ç©å…·",
    "åˆ·ç‰™",
    # === äººéš›é—œä¿‚ (Relationships) ===
    "æ‰‹è¶³",
    "å…„å¼Ÿ",
    "å§Šå¦¹",
    "æœ‹å‹",
    "åŒå­¸",
    "è€å¸«",
    "è¡çª",
    "çˆ­åµ",
    # === æ•™é¤Šæ¦‚å¿µ (Parenting Concepts) ===
    "æºé€š",
    "é™ªä¼´",
    "é—œä¿‚",
    "é¼“å‹µ",
    "è®šç¾",
    "è™•ç½°",
    "çå‹µ",
    "å°Šé‡",
    "è²¬ä»»",
    "ç•Œé™",
    "è¦å‰‡",
    "é¸æ“‡",
    "å¾Œæœ",
    "åˆ†äº«",
    # === ç™¼å±•ç›¸é—œ (Development) ===
    "ç™¼å±•",
    "æˆé•·",
    "å­¸ç¿’",
    "é’æ˜¥æœŸ",
    "æ•™è‚²",
    "ç¨ç«‹",
    "è‡ªå¾‹",
    "è‡ªä¿¡",
    "è‡ªå°Š",
    # === ä¾é™„ç›¸é—œ (Attachment) ===
    "ä¾é™„",
    "å®‰å…¨æ„Ÿ",
    "ä¿¡ä»»",
    "åˆ†é›¢",
    "é€£çµ",
]


def _detect_parenting_keywords(transcript: str) -> bool:
    """Detect if transcript contains parenting-related keywords.

    Args:
        transcript: The transcript text

    Returns:
        True if parenting keywords detected, False otherwise
    """
    transcript_lower = transcript.lower()
    for keyword in PARENTING_KEYWORDS:
        if keyword in transcript_lower:
            logger.info(f"Parenting keyword detected: {keyword}")
            return True
    return False


def _detect_parenting_theory(title: str) -> str:
    """Detect which parenting theory a document belongs to based on title.

    Args:
        title: Document title

    Returns:
        Theory name in Chinese (e.g., "æ­£å‘æ•™é¤Š", "æƒ…ç·’æ•™é¤Š")
    """
    # Theory keyword mappings (Chinese, English, and file name patterns)
    theory_mappings = {
        "æ­£å‘æ•™é¤Š": ["æ­£å‘æ•™é¤Š", "Positive Discipline", "positive_discipline"],
        "æƒ…ç·’æ•™é¤Š": [
            "æƒ…ç·’æ•™é¤Š",
            "Emotional Coaching",
            "Emotion Coaching",
            "emotional_coaching",
        ],
        "ä¾é™„ç†è«–": ["ä¾é™„ç†è«–", "Attachment Theory", "attachment_theory"],
        "èªçŸ¥ç™¼å±•ç†è«–": ["èªçŸ¥ç™¼å±•", "Cognitive Development", "cognitive_development"],
        "è‡ªæˆ‘æ±ºå®šè«–": ["è‡ªæˆ‘æ±ºå®š", "Self-Determination", "self_determination"],
    }

    # Check each theory's keywords (case-insensitive)
    title_lower = title.lower()
    for theory_name, keywords in theory_mappings.items():
        for keyword in keywords:
            if keyword.lower() in title_lower:
                return theory_name

    # Default if no match found
    return "å…¶ä»–"


async def _search_rag_knowledge(
    transcript: str, db: Session, top_k: int = 3, similarity_threshold: float = 0.5
) -> List[RAGSource]:
    """Search RAG knowledge base for relevant parenting content.

    Args:
        transcript: The transcript text to search
        db: Database session
        top_k: Number of top results to return
        similarity_threshold: Minimum similarity score (default 0.5)
            Note: Lowered from 0.7 to 0.5 based on production data analysis.
            Real-world similarity scores for relevant content typically max out
            at ~0.54-0.59, so 0.7 was too strict and prevented retrieval.

    Returns:
        List of RAG sources with title, content, and score
    """
    try:
        # Initialize RAG service
        rag_service = RAGChatService(db=db)

        # Generate embedding for transcript
        query_embedding = await openai_service.create_embedding(transcript)

        # Search similar chunks with parenting category filter
        rows = await rag_service.search_similar_chunks(
            query_embedding=query_embedding,
            top_k=top_k,
            similarity_threshold=similarity_threshold,
            category="parenting",  # Filter for parenting documents only
        )

        # Build RAG sources response
        rag_sources = []
        for row in rows:
            # Detect theory from document title
            theory = _detect_parenting_theory(row.document_title)

            rag_sources.append(
                RAGSource(
                    title=row.document_title,
                    content=row.text[:300],  # Truncate to 300 chars
                    score=round(float(row.similarity_score), 2),
                    theory=theory,
                )
            )

        logger.info(f"RAG search found {len(rag_sources)} relevant sources")
        return rag_sources

    except Exception as e:
        logger.error(f"RAG search failed: {e}")
        # Return empty list on error (fallback)
        return []


def _assess_safety_level(transcript: str, speakers: List[dict]) -> SafetyLevel:
    """Assess safety level based on RECENT conversation (sliding window).

    Only evaluates the last ~1 minute of dialogue to allow rapid safety relaxation.
    This prevents dangerous keywords from earlier in the conversation from keeping
    the safety level elevated indefinitely.

    Safety levels:
    - RED: Violent language, extreme emotions, crisis indicators (high risk)
    - YELLOW: Escalating conflict, frustration, raised emotions (warning)
    - GREEN: Calm, positive interaction (safe)

    Args:
        transcript: The full conversation transcript (cumulative)
        speakers: List of speaker segments (used for sliding window)

    Returns:
        SafetyLevel enum: red, yellow, or green
    """
    # Strategy: Use last N speaker segments (approximate 1 minute)
    # Extract recent transcript from speakers array
    if speakers and len(speakers) > 0:
        # Take last N segments to approximate 1 minute of conversation
        recent_speakers = speakers[-SAFETY_WINDOW_SPEAKER_TURNS:]
        recent_transcript = "\n".join(
            [
                f"{seg.get('speaker', 'unknown')}: {seg.get('text', '')}"
                for seg in recent_speakers
            ]
        )
        logger.info(
            f"Using sliding window: last {len(recent_speakers)} speaker turns "
            f"({len(recent_transcript)} chars)"
        )
    else:
        # Fallback: use last N characters (approximate 1 minute)
        if len(transcript) > SAFETY_WINDOW_CHARACTERS:
            recent_transcript = transcript[-SAFETY_WINDOW_CHARACTERS:]
            logger.info(
                f"Using fallback window: last {SAFETY_WINDOW_CHARACTERS} characters"
            )
        else:
            recent_transcript = transcript
            logger.info("Using full transcript (shorter than window)")

    # Convert to lowercase for keyword matching
    text_lower = recent_transcript.lower()

    # RED indicators (high risk) - violence, extreme emotions, crisis
    red_keywords = [
        "æ‰“æ­»",
        "æ»¾",
        "æ®º",
        "æ¨æ­»",
        "æš´åŠ›",
        "æ‰“äºº",
        "æ",
        "å—ä¸äº†",
        "ä¸æƒ³æ´»",
        "å»æ­»",
    ]
    for keyword in red_keywords:
        if keyword in text_lower:
            logger.info(
                f"Safety level: RED detected (keyword: '{keyword}' in recent window)"
            )
            return SafetyLevel.red

    # YELLOW indicators (medium risk) - frustration, escalating conflict
    yellow_keywords = [
        "æ°£æ­»",
        "ç…©æ­»",
        "å—å¤ ",
        "ä¸è½è©±",
        "èªªè¬Š",
        "å¿«ç˜‹",
        "å´©æ½°",
        "ç™¼ç«",
    ]
    for keyword in yellow_keywords:
        if keyword in text_lower:
            logger.info(
                f"Safety level: YELLOW detected (keyword: '{keyword}' in recent window)"
            )
            return SafetyLevel.yellow

    # GREEN (safe/positive) - default if no risk indicators found in recent window
    logger.info("Safety level: GREEN (calm/positive interaction in recent window)")
    return SafetyLevel.green


def _build_annotated_transcript(transcript: str, speakers: List[dict]) -> str:
    """Build annotated transcript with recent window highlighted for safety assessment.

    Args:
        transcript: Full conversation transcript
        speakers: List of speaker segments

    Returns:
        Annotated transcript with recent window marked for safety evaluation
    """
    # Build full transcript
    full_transcript = "\n".join(
        [f"{seg.get('speaker', 'unknown')}: {seg.get('text', '')}" for seg in speakers]
    )

    # Extract recent window for annotation
    recent_speakers = (
        speakers[-ANNOTATED_SAFETY_WINDOW_TURNS:]
        if len(speakers) > ANNOTATED_SAFETY_WINDOW_TURNS
        else speakers
    )
    recent_transcript = "\n".join(
        [
            f"{seg.get('speaker', 'unknown')}: {seg.get('text', '')}"
            for seg in recent_speakers
        ]
    )

    # Construct annotated prompt
    annotated = f"""å®Œæ•´å°è©±é€å­—ç¨¿ï¼ˆä¾›åƒè€ƒï¼Œç†è§£èƒŒæ™¯è„ˆçµ¡ï¼‰ï¼š
{full_transcript}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€æœ€è¿‘å°è©± - ç”¨æ–¼å®‰å…¨è©•ä¼°ã€‘
ï¼ˆè«‹æ ¹æ“šæ­¤å€å¡Šåˆ¤æ–·ç•¶å‰å®‰å…¨ç­‰ç´šï¼‰
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{recent_transcript}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš ï¸ CRITICAL: å®‰å…¨ç­‰ç´šè©•ä¼°è«‹åªæ ¹æ“šã€Œã€æœ€è¿‘å°è©± - ç”¨æ–¼å®‰å…¨è©•ä¼°ã€‘ã€å€å¡Šåˆ¤æ–·ï¼Œ
å®Œæ•´å°è©±åƒ…ä½œç‚ºç†è§£è„ˆçµ¡åƒè€ƒã€‚å¦‚æœæœ€è¿‘å°è©±å·²ç·©å’Œï¼Œå³ä½¿ä¹‹å‰æœ‰å±éšªå…§å®¹ï¼Œ
ä¹Ÿæ‡‰è©•ä¼°ç‚ºè¼ƒä½é¢¨éšªã€‚"""

    return annotated


def _build_emergency_prompt(transcript: str, rag_context: str) -> str:
    """Build simplified prompt for emergency mode using 200 expert suggestions.

    Emergency mode: Select 1-2 suggestions from expert pool, organized with Bridge technique.
    Bridge structure for RED scenarios: ç©©ä½ â†’ åŒç† â†’ ä¿®æ­£

    Args:
        transcript: The conversation transcript
        rag_context: RAG knowledge context (if available)

    Returns:
        Simplified prompt for emergency situations with expert suggestions
    """
    from app.config.parenting_suggestions import (
        GREEN_SUGGESTIONS,
        RED_SUGGESTIONS,
        YELLOW_SUGGESTIONS,
    )

    # Format suggestion lists for prompt
    green_list = "\n".join([f"  - {s}" for s in GREEN_SUGGESTIONS])
    yellow_list = "\n".join([f"  - {s}" for s in YELLOW_SUGGESTIONS])
    red_list = "\n".join([f"  - {s}" for s in RED_SUGGESTIONS])

    prompt = f"""ä½ æ˜¯è¦ªå­è«®è©¢ AI ç£å°ã€‚ç·Šæ€¥æ¨¡å¼ - å¾å°ˆå®¶å»ºè­°ä¸­é¸ 1-2 å¥ï¼

ã€æƒ…å¢ƒã€‘
{transcript}

ã€å°ˆå®¶å»ºè­°å¥åº«ã€‘è«‹å¾ä»¥ä¸‹ 200 å¥å°ˆå®¶å»ºè­°ä¸­é¸æ“‡æœ€ç¬¦åˆç•¶å‰å°è©±çš„ï¼š

ğŸŸ¢ ç¶ è‰²ï½œå°è©±å®‰å…¨ï¼ˆé¸ 1-2 å¥ï¼‰ï¼š
{green_list}

ğŸŸ¡ é»ƒè‰²ï½œéœ€è¦èª¿æ•´ï¼ˆé¸ 1-2 å¥ï¼‰ï¼š
{yellow_list}

ğŸ”´ ç´…è‰²ï½œç«‹åˆ»ä¿®æ­£ï¼ˆé¸ 1-2 å¥ï¼‰ï¼š
{red_list}

ã€åˆ†ææ­¥é©Ÿã€‘ï¼š
1. åˆ¤æ–·å°è©±å®‰å…¨ç­‰ç´šï¼ˆgreen/yellow/redï¼‰
   - green: æ­£å‘äº’å‹•ï¼Œå®¶é•·æœ‰åŒç†å¿ƒï¼Œèªæ°£æº«å’Œå°Šé‡
   - yellow: æœ‰æŒ«æŠ˜æ„Ÿä½†ä»å¯æ§ï¼Œèªæ°£é–‹å§‹ç·Šç¹ƒæˆ–å¸¶é˜²è¡›
   - red: å¨è„…ã€æš´åŠ›èªè¨€ã€æ¥µç«¯æƒ…ç·’ã€å¯èƒ½é€ æˆå‚·å®³
2. å¾å°æ‡‰é¡è‰²çš„å»ºè­°å¥ä¸­é¸å‡ºæœ€ç¬¦åˆçš„ 1-2 å¥
3. å»ºè­°å¿…é ˆæ˜¯åŸå¥ï¼Œä¸è¦æ”¹å¯«æˆ–è‡ªå‰µ

ã€Bridge æŠ€å·§ã€‘è«‹æŒ‰ç…§ä»¥ä¸‹çµæ§‹çµ„ç¹”å›é¥‹ï¼š
- ğŸŸ¢ ç¶ è‰²ï¼šè®šç¾ â†’ æ©‹æ¨‘ â†’ å»¶ä¼¸
- ğŸŸ¡ é»ƒè‰²ï¼šè‚¯å®š â†’ æé†’ â†’ æ›¿ä»£
- ğŸ”´ ç´…è‰²ï¼šç©©ä½ â†’ åŒç† â†’ ä¿®æ­£ï¼ˆæœ€é‡è¦ï¼ï¼‰

ã€ç´…è‰²ç‡ˆè™Ÿçš„ä¸‰éšæ®µè¨­è¨ˆã€‘ï¼š
1. å…ˆç©©ä½ï¼šã€Œç†è§£åœ¨æ•™é¤Šå£“åŠ›ä¸‹ï¼Œæƒ…ç·’å¤±æ§æ˜¯å¾ˆæ­£å¸¸çš„ã€
2. é™ä½é˜²è¡›ï¼šã€Œä½ ä¸€å®šä¹Ÿå¾ˆè¾›è‹¦ï¼Œæƒ³è¦å­©å­å¥½ä½†ä¸çŸ¥é“æ€éº¼åšã€
3. å†æé†’ï¼šã€Œé€™å¥è©±å¯èƒ½æœƒè®“å­©å­æ„Ÿåˆ°å®³æ€•ï¼Œæˆ‘å€‘å¯ä»¥è©¦è©¦é€™æ¨£èªª...ã€

ã€è¼¸å‡ºæ ¼å¼ã€‘JSON æ ¼å¼ï¼Œå¿…é ˆåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
{{
  "safety_level": "green|yellow|red",
  "suggestions": [
    "å¾å°ˆå®¶å»ºè­°ä¸­é¸çš„å¥å­1",
    "å¾å°ˆå®¶å»ºè­°ä¸­é¸çš„å¥å­2"
  ]
}}

CRITICAL è¦å‰‡ï¼š
- åªèƒ½é¸ 1-2 å€‹å»ºè­°ï¼ˆå¾ 200 å¥å°ˆå®¶å»ºè­°ä¸­é¸ï¼‰
- æ¯å¥å»ºè­°å¿…é ˆæ˜¯åŸæœ¬çš„å°ˆå®¶å»ºè­°å¥ï¼Œé€å­—ç…§æŠ„ï¼Œä¸è¦è‡ªå·±æ”¹å¯«æˆ–å‰µä½œ
- æ ¹æ“šå°è©±å±éšªç¨‹åº¦é¸æ“‡å°æ‡‰é¡è‰²çš„å»ºè­°
- å¿…é ˆå›å‚³ safety_level: "green" | "yellow" | "red"ï¼ˆæ­¤æ¬„ä½å¿…é ˆå­˜åœ¨ï¼‰
- safety_level å’Œ suggestions çš„é¡è‰²å¿…é ˆä¸€è‡´
- Emergency æ¨¡å¼é‡é»ï¼šå¿«é€Ÿã€ç²¾æº–ã€å¯ç«‹å³åŸ·è¡Œ

YOU MUST select 1-2 suggestions from the 200 expert suggestions above!
YOU MUST return safety_level field in JSON response!"""

    return prompt


def _build_practice_prompt(
    transcript: str, rag_context: str, annotated_transcript: str = ""
) -> str:
    """Build detailed prompt for practice mode using 200 expert suggestions (~1500 tokens).

    Practice mode: Select 3-4 suggestions from expert pool, organized with Bridge technique.
    Bridge structure varies by safety level (è®šç¾â†’æ©‹æ¨‘â†’å»¶ä¼¸ for green, etc.)

    Args:
        transcript: The conversation transcript
        rag_context: RAG knowledge context (if available)
        annotated_transcript: Optional annotated transcript with safety window highlighted

    Returns:
        Detailed prompt for practice/learning situations with expert suggestions
    """
    from app.config.parenting_suggestions import (
        GREEN_SUGGESTIONS,
        RED_SUGGESTIONS,
        YELLOW_SUGGESTIONS,
    )

    # Format suggestion lists for prompt
    green_list = "\n".join([f"  - {s}" for s in GREEN_SUGGESTIONS])
    yellow_list = "\n".join([f"  - {s}" for s in YELLOW_SUGGESTIONS])
    red_list = "\n".join([f"  - {s}" for s in RED_SUGGESTIONS])

    # Use annotated transcript if provided, otherwise fall back to plain transcript
    dialogue_content = annotated_transcript if annotated_transcript else transcript

    # Use existing detailed prompt (same as CACHE_SYSTEM_INSTRUCTION style)
    prompt = f"""ä½ æ˜¯å°ˆæ¥­è«®è©¢ç£å°ï¼Œåˆ†æå³æ™‚è«®è©¢å°è©±ã€‚ä½ çš„è§’è‰²æ˜¯ç«™åœ¨æ¡ˆä¸»èˆ‡è«®è©¢å¸«ä¹‹é–“ï¼Œæä¾›æº«æš–ã€åŒç†ä¸”å…·é«”å¯è¡Œçš„å°ˆæ¥­å»ºè­°ã€‚

ã€å°è©±å…§å®¹ã€‘
{dialogue_content}

ã€ç›¸é—œè¦ªå­æ•™é¤ŠçŸ¥è­˜åº«ã€‘
{rag_context if rag_context else "ï¼ˆç„¡ç›¸é—œçŸ¥è­˜åº«å…§å®¹ï¼‰"}

ã€å°ˆå®¶å»ºè­°å¥åº«ã€‘è«‹å¾ä»¥ä¸‹ 200 å¥å°ˆå®¶å»ºè­°ä¸­é¸æ“‡ 3-4 å¥æœ€ç¬¦åˆç•¶å‰å°è©±çš„ï¼š

ğŸŸ¢ ç¶ è‰²ï½œå°è©±å®‰å…¨ï¼ˆé¸ 3-4 å¥ï¼‰ï¼š
{green_list}

ğŸŸ¡ é»ƒè‰²ï½œéœ€è¦èª¿æ•´ï¼ˆé¸ 3-4 å¥ï¼‰ï¼š
{yellow_list}

ğŸ”´ ç´…è‰²ï½œç«‹åˆ»ä¿®æ­£ï¼ˆé¸ 3-4 å¥ï¼‰ï¼š
{red_list}

ã€åˆ†ææ­¥é©Ÿã€‘ï¼š
1. åˆ¤æ–·å°è©±å®‰å…¨ç­‰ç´šï¼ˆgreen/yellow/redï¼‰
   - green: æ­£å‘äº’å‹•ï¼Œå®¶é•·æœ‰åŒç†å¿ƒï¼Œèªæ°£æº«å’Œå°Šé‡
   - yellow: æœ‰æŒ«æŠ˜æ„Ÿä½†ä»å¯æ§ï¼Œèªæ°£é–‹å§‹ç·Šç¹ƒæˆ–å¸¶é˜²è¡›
   - red: å¨è„…ã€æš´åŠ›èªè¨€ã€æ¥µç«¯æƒ…ç·’ã€å¯èƒ½é€ æˆå‚·å®³
2. å¾å°æ‡‰é¡è‰²çš„å»ºè­°å¥ä¸­é¸å‡ºæœ€ç¬¦åˆçš„ 3-4 å¥
3. å»ºè­°å¿…é ˆæ˜¯åŸå¥ï¼Œä¸è¦æ”¹å¯«æˆ–è‡ªå‰µ

ã€Bridge æŠ€å·§ã€‘è«‹æŒ‰ç…§ä»¥ä¸‹çµæ§‹çµ„ç¹”å›é¥‹ï¼š
- ğŸŸ¢ ç¶ è‰²ï¼šè®šç¾ â†’ æ©‹æ¨‘ â†’ å»¶ä¼¸
- ğŸŸ¡ é»ƒè‰²ï¼šè‚¯å®š â†’ æé†’ â†’ æ›¿ä»£
- ğŸ”´ ç´…è‰²ï¼šç©©ä½ â†’ åŒç† â†’ ä¿®æ­£ï¼ˆæœ€é‡è¦ï¼ï¼‰

ã€ç´…è‰²ç‡ˆè™Ÿçš„ä¸‰éšæ®µè¨­è¨ˆã€‘ï¼š
1. å…ˆç©©ä½ï¼šã€Œç†è§£åœ¨æ•™é¤Šå£“åŠ›ä¸‹ï¼Œæƒ…ç·’å¤±æ§æ˜¯å¾ˆæ­£å¸¸çš„ã€
2. é™ä½é˜²è¡›ï¼šã€Œä½ ä¸€å®šä¹Ÿå¾ˆè¾›è‹¦ï¼Œæƒ³è¦å­©å­å¥½ä½†ä¸çŸ¥é“æ€éº¼åšã€
3. å†æé†’ï¼šã€Œé€™å¥è©±å¯èƒ½æœƒè®“å­©å­æ„Ÿåˆ°å®³æ€•ï¼Œæˆ‘å€‘å¯ä»¥è©¦è©¦é€™æ¨£èªª...ã€

ã€æ ¸å¿ƒåŸå‰‡ã€‘åŒç†å„ªå…ˆã€æº«å’Œå¼•å°ã€å…·é«”è¡Œå‹•ï¼š

1. **åŒç†èˆ‡ç†è§£ç‚ºå…ˆ**
   - æ°¸é å…ˆç†è§£èˆ‡åŒç†æ¡ˆä¸»ï¼ˆå®¶é•·ï¼‰çš„æ„Ÿå—å’Œè™•å¢ƒ
   - èªå¯æ•™é¤Šå£“åŠ›ã€æƒ…ç·’å¤±æ§æ˜¯æ­£å¸¸çš„äººæ€§åæ‡‰
   - é¿å…æ‰¹åˆ¤ã€æŒ‡è²¬æˆ–è®“æ¡ˆä¸»æ„Ÿåˆ°è¢«å¦å®š

2. **æº«å’Œã€éæ‰¹åˆ¤çš„èªæ°£**
   - âŒ ç¦æ­¢ç”¨èªï¼šã€Œè¡¨é”å‡ºå°å­©å­ä½¿ç”¨èº«é«”æš´åŠ›çš„è¡å‹•ã€ã€Œå¯èƒ½é€ æˆå‚·å®³ã€ã€Œä¸ç•¶ç®¡æ•™ã€
   - âœ… å»ºè­°ç”¨èªï¼šã€Œç†è§£åˆ°åœ¨æ•™é¤Šå£“åŠ›ä¸‹ï¼Œçˆ¶æ¯æœ‰æ™‚æœƒæ„Ÿåˆ°æƒ…ç·’å¤±æ§æ˜¯å¾ˆæ­£å¸¸çš„ã€
   - âœ… ä½¿ç”¨ï¼šã€Œå¯ä»¥è€ƒæ…®ã€ã€Œæˆ–è¨±ã€ã€Œè©¦è©¦çœ‹ã€ç­‰æŸ”å’Œå¼•å°è©

3. **å…·é«”ã€å¯¦ç”¨çš„å»ºè­°**
   - å¾ 200 å¥å°ˆå®¶å»ºè­°ä¸­é¸æ“‡æœ€ç¬¦åˆçš„
   - é¿å…æŠ½è±¡æ¦‚å¿µï¼Œç”¨å…·é«”åšæ³•
   - å¦‚æœçŸ¥è­˜åº«æœ‰ç›¸é—œå…§å®¹ï¼Œèå…¥å°ˆæ¥­ç†è«–

ã€è¼¸å‡ºæ ¼å¼ã€‘JSON æ ¼å¼ï¼Œå¿…é ˆåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š

{{
  "safety_level": "green|yellow|red",
  "summary": "æ¡ˆä¸»è™•å¢ƒç°¡è¿°ï¼ˆ2-3 å¥ï¼‰",
  "alerts": [
    "ğŸ’¡ åŒç†æ¡ˆä¸»æ„Ÿå—",
    "âš ï¸ éœ€é—œæ³¨çš„éƒ¨åˆ†",
    "âœ… æ­£å‘çš„éƒ¨åˆ†"
  ],
  "suggestions": [
    "å¾å°ˆå®¶å»ºè­°ä¸­é¸çš„å¥å­1",
    "å¾å°ˆå®¶å»ºè­°ä¸­é¸çš„å¥å­2",
    "å¾å°ˆå®¶å»ºè­°ä¸­é¸çš„å¥å­3",
    "å¾å°ˆå®¶å»ºè­°ä¸­é¸çš„å¥å­4"
  ]
}}

CRITICAL è¦å‰‡ï¼š
- å¿…é ˆé¸ 3-4 å€‹å»ºè­°ï¼ˆå¾ 200 å¥å°ˆå®¶å»ºè­°ä¸­é¸ï¼‰
- æ¯å¥å»ºè­°å¿…é ˆæ˜¯åŸæœ¬çš„å°ˆå®¶å»ºè­°å¥ï¼Œé€å­—ç…§æŠ„ï¼Œä¸è¦è‡ªå·±æ”¹å¯«æˆ–å‰µä½œ
- æ ¹æ“šå°è©±å±éšªç¨‹åº¦é¸æ“‡å°æ‡‰é¡è‰²çš„å»ºè­°
- å¿…é ˆå›å‚³ safety_level: "green" | "yellow" | "red"ï¼ˆæ­¤æ¬„ä½å¿…é ˆå­˜åœ¨ï¼‰
- safety_level å’Œ suggestions çš„é¡è‰²å¿…é ˆä¸€è‡´
- Practice æ¨¡å¼é‡é»ï¼šæ·±åº¦åˆ†æã€ä¿ƒé€²å­¸ç¿’æˆé•·

ã€èªæ°£è¦æ±‚ã€‘æº«å’Œã€åŒç†ã€å°ˆæ¥­ï¼Œæä¾›æ·±åº¦åˆ†æå¹«åŠ©å®¶é•·å­¸ç¿’æˆé•·ã€‚

YOU MUST select 3-4 suggestions from the 200 expert suggestions above!
YOU MUST return safety_level field in JSON response!"""

    return prompt


def _calculate_gemini_cost(usage_metadata: dict) -> float:
    """Calculate estimated cost for Gemini API usage

    Gemini 2.5 Flash pricing (as of 2025):
    - Input: $0.000075 per 1K tokens
    - Output: $0.0003 per 1K tokens
    - Cached input: $0.00001875 per 1K tokens (75% discount)
    """
    prompt_tokens = usage_metadata.get("prompt_token_count", 0)
    completion_tokens = usage_metadata.get("candidates_token_count", 0)
    cached_tokens = usage_metadata.get("cached_content_token_count", 0)

    # Subtract cached tokens from prompt tokens
    non_cached_prompt = max(0, prompt_tokens - cached_tokens)

    # Calculate costs
    prompt_cost = (non_cached_prompt / 1000) * 0.000075
    cached_cost = (cached_tokens / 1000) * 0.00001875
    completion_cost = (completion_tokens / 1000) * 0.0003

    return prompt_cost + cached_cost + completion_cost


async def write_to_gbq_async(data: dict) -> None:
    """Write realtime analysis result to BigQuery asynchronously

    This is a wrapper function that catches all exceptions to prevent
    GBQ write failures from affecting API response.

    Args:
        data: Analysis data to write to BigQuery
    """
    try:
        await gbq_service.write_analysis_log(data)
    except Exception as e:
        # Log error but don't raise - GBQ failures should not block API
        logger.error(
            f"Failed to write to BigQuery (non-blocking): {str(e)}", exc_info=True
        )


async def _analyze_with_codeer(
    transcript: str,
    speakers: List[dict],
    rag_context: str,
    db: Session,
    session_id: str = "",
    model: str = "gpt5-mini",
    custom_prompt: str = "",
) -> dict:
    """Analyze transcript using Codeer è¦ªå­å°ˆå®¶ agent.

    Args:
        transcript: Full transcript text
        speakers: List of speaker segments
        rag_context: RAG knowledge context
        db: Database session
        session_id: Session ID for session pooling (optional)
        model: Codeer model selection (claude-sonnet, gemini-flash, or gpt5-mini)

    Returns:
        Dict with summary, alerts, suggestions
    """
    import json

    from app.services.codeer_client import CodeerClient, get_codeer_agent_id
    from app.services.codeer_session_pool import get_codeer_session_pool

    # Get agent ID based on model selection
    try:
        agent_id = get_codeer_agent_id(model)
        logger.info(f"Using Codeer model: {model}, agent_id: {agent_id}")
    except Exception as e:
        logger.error(f"Failed to get Codeer agent ID: {e}")
        raise HTTPException(status_code=400, detail=str(e))

    # Create client with longer timeout for analysis
    client = CodeerClient()
    # Extend timeout to 60 seconds for LLM response
    client.client.timeout = httpx.Timeout(60.0)

    try:
        # Use custom prompt if provided (for mode-based routing)
        # Otherwise, use default system instruction
        if custom_prompt:
            prompt = custom_prompt
        else:
            # Build analysis prompt similar to Gemini's
            # Format: system instruction + RAG context + transcript
            prompt = f"""{CACHE_SYSTEM_INSTRUCTION}

{rag_context if rag_context else ""}

ã€å°è©±å…§å®¹ã€‘
{transcript}

è«‹åˆ†æä»¥ä¸Šå°è©±ï¼Œæä¾› JSON æ ¼å¼å›æ‡‰ã€‚
"""

        # Create or reuse chat session with selected agent
        if session_id:
            # Use session pool for reuse
            pool = get_codeer_session_pool()
            chat = await pool.get_or_create_session(
                session_id, client, agent_id=agent_id
            )
            logger.info(f"Using session pool for {session_id} with agent {agent_id}")
        else:
            # Fallback: create new chat with selected agent
            # Use microsecond precision + model name to ensure unique chat names
            import uuid

            unique_suffix = (
                f"{datetime.now().strftime('%Y%m%d-%H%M%S')}-{uuid.uuid4().hex[:8]}"
            )
            chat = await client.create_chat(
                name=f"Realtime-{model}-{unique_suffix}",
                agent_id=agent_id,
            )
            logger.info(
                f"Created new chat (no session_id) with agent {agent_id}: {chat['name']}"
            )

        # Send message to Codeer agent (non-streaming for now)
        # CRITICAL: Must pass agent_id to match the agent used to create the chat
        try:
            response = await client.send_message(
                chat_id=chat["id"], message=prompt, stream=False, agent_id=agent_id
            )
        except Exception as api_error:
            # Handle Codeer API errors (e.g., agent mismatch, timeout, rate limit)
            logger.error(f"Codeer send_message failed: {api_error}")
            return {
                "summary": "Codeer åˆ†æå¤±æ•—",
                "alerts": [f"âš ï¸ API éŒ¯èª¤: {str(api_error)}"],
                "suggestions": ["ğŸ’¡ è«‹æª¢æŸ¥ Codeer API é€£ç·šæˆ–ç¨å¾Œå†è©¦"],
                "token_usage": None,
            }

        # Fetch token usage from the latest assistant message
        token_usage_data = None
        try:
            # Fetch latest messages (limit=10 to ensure we get assistant response)
            # The order is: [latest system, latest assistant, user, ...]
            messages = await client.list_chat_messages(chat_id=chat["id"], limit=10)
            if messages and len(messages) > 0:
                # Find the latest assistant message (role='assistant')
                assistant_message = None
                for msg in messages:
                    if msg.get("role") == "assistant":
                        assistant_message = msg
                        break

                # Extract token_usage from assistant message's meta.token_usage
                if (
                    assistant_message
                    and "meta" in assistant_message
                    and "token_usage" in assistant_message["meta"]
                    and assistant_message["meta"]["token_usage"] is not None
                ):
                    token_usage = assistant_message["meta"]["token_usage"]
                    token_usage_data = {
                        "total_prompt_tokens": token_usage.get(
                            "total_prompt_tokens", 0
                        ),
                        "total_completion_tokens": token_usage.get(
                            "total_completion_tokens", 0
                        ),
                        "total_tokens": token_usage.get("total_tokens", 0),
                        "total_calls": token_usage.get("total_calls", 0),
                    }
                    logger.info(f"Codeer token usage: {token_usage_data}")
                else:
                    logger.warning(
                        "No assistant message found or token_usage not available"
                    )
        except Exception as e:
            logger.warning(f"Failed to fetch Codeer token usage: {e}")

        # Parse Codeer response
        # Codeer returns dict with 'content', 'text', or 'message' field
        try:
            # Extract text from response
            if isinstance(response, dict):
                response_text = (
                    response.get("content")
                    or response.get("text")
                    or response.get("message")
                    or str(response)
                )
            else:
                response_text = str(response)

            # Extract JSON from response
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                json_text = response_text[json_start:json_end].strip()
            elif "{" in response_text:
                json_start = response_text.find("{")
                json_end = response_text.rfind("}") + 1
                json_text = response_text[json_start:json_end]
            else:
                # Fallback: treat as plain text
                json_text = response_text

            analysis = json.loads(json_text)

            # Ensure required fields exist
            if "summary" not in analysis:
                analysis["summary"] = "åˆ†æçµæœ"
            if "alerts" not in analysis:
                analysis["alerts"] = []
            if "suggestions" not in analysis:
                analysis["suggestions"] = []

            # Add token usage to analysis result
            analysis["token_usage"] = token_usage_data

            return analysis

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse Codeer response as JSON: {e}")
            logger.error(f"Response text: {response_text[:500]}")

            # Fallback response
            return {
                "summary": "Codeer å›æ‡‰è§£æå¤±æ•—",
                "alerts": [f"âš ï¸ ç„¡æ³•è§£æå›æ‡‰: {str(e)}"],
                "suggestions": ["ğŸ’¡ è«‹æª¢æŸ¥ Codeer agent è¨­å®š"],
                "token_usage": token_usage_data,
            }

    finally:
        # Always close the client
        await client.close()


@router.post("/analyze", response_model=RealtimeAnalyzeResponse)
async def analyze_transcript(
    request: RealtimeAnalyzeRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db),
):
    """Analyze realtime counseling transcript with AI supervision.

    Returns summary, alerts, and suggestions for the counselor based on
    the conversation in the past 60 seconds.

    Supports multiple LLM providers: Gemini (default) and Codeer.
    Gemini supports explicit context caching for improved performance.

    This is a demo feature with no authentication required.
    """
    import time

    start_time = time.time()

    try:
        # Convert speakers to dict format for service
        speakers_dict = [
            {"speaker": s.speaker, "text": s.text} for s in request.speakers
        ]

        # Assess safety level based on transcript content
        safety_level = _assess_safety_level(request.transcript, speakers_dict)
        logger.info(f"Safety level assessed: {safety_level.value}")

        # Detect parenting keywords and trigger RAG if needed
        rag_sources = []
        rag_context = ""

        if _detect_parenting_keywords(request.transcript):
            logger.info("Parenting keywords detected, triggering RAG search")
            # Phase 2.1 Enhancement: Increased top_k and lowered threshold for richer context
            rag_sources = await _search_rag_knowledge(
                transcript=request.transcript,
                db=db,
                top_k=7,  # Increased from 3 to 7 for more diverse suggestions
                similarity_threshold=0.35,  # Lowered from 0.5 to 0.35 (production scores ~0.54-0.59)
            )

            # Build RAG context for Gemini prompt
            if rag_sources:
                rag_context_parts = ["\n\nğŸ“š ç›¸é—œè¦ªå­æ•™é¤ŠçŸ¥è­˜åº«å…§å®¹ï¼ˆä¾›åƒè€ƒï¼‰ï¼š\n"]
                for idx, source in enumerate(rag_sources, 1):
                    # Phase 2.1 Enhancement: Full content without truncation for complete context
                    rag_context_parts.append(
                        f"[{idx}] {source.title}: {source.content}"
                    )
                rag_context = "\n".join(rag_context_parts)

        # Build annotated transcript for safety assessment
        annotated_transcript = _build_annotated_transcript(
            request.transcript, speakers_dict
        )
        logger.info(
            f"Built annotated transcript with {len(speakers_dict)} total speakers, "
            f"last {min(ANNOTATED_SAFETY_WINDOW_TURNS, len(speakers_dict))} highlighted"
        )

        # Select prompt based on counseling mode
        if request.mode == CounselingMode.emergency:
            logger.info("Using EMERGENCY mode (simplified prompt)")
            custom_prompt = _build_emergency_prompt(annotated_transcript, rag_context)
        else:
            logger.info("Using PRACTICE mode (detailed prompt)")
            custom_prompt = _build_practice_prompt(
                request.transcript, rag_context, annotated_transcript
            )

        # Initialize variables
        analysis = {}
        cache_metadata = None
        provider_metadata = None

        # Route to appropriate provider
        if request.provider == "codeer":
            logger.info(
                f"Using Codeer provider for analysis (model: {request.codeer_model})"
            )
            analysis = await _analyze_with_codeer(
                transcript=request.transcript,
                speakers=speakers_dict,
                rag_context=rag_context,
                db=db,
                session_id=request.session_id,
                model=request.codeer_model,
                custom_prompt=custom_prompt,
            )

            # Calculate latency
            latency_ms = int((time.time() - start_time) * 1000)

            # Extract token usage from analysis result
            codeer_token_metadata = None
            if analysis.get("token_usage"):
                token_data = analysis["token_usage"]
                codeer_token_metadata = CodeerTokenMetadata(
                    total_prompt_tokens=token_data.get("total_prompt_tokens", 0),
                    total_completion_tokens=token_data.get(
                        "total_completion_tokens", 0
                    ),
                    total_tokens=token_data.get("total_tokens", 0),
                    total_calls=token_data.get("total_calls", 0),
                )

            provider_metadata = ProviderMetadata(
                provider="codeer",
                latency_ms=latency_ms,
                model=f"è¦ªå­å°ˆå®¶ (codeer-{request.codeer_model})",
                codeer_token_usage=codeer_token_metadata,
            )

        # Default to Gemini
        else:
            logger.info("Using Gemini provider for analysis")

            # Use cache if enabled and session_id is provided
            if request.use_cache and request.session_id:
                try:
                    logger.info(
                        f"Cache enabled for session {request.session_id}, "
                        f"attempting to get or create cache"
                    )

                    # Get or create cache with accumulated transcript
                    cached_content, is_new = await cache_manager.get_or_create_cache(
                        session_id=request.session_id,
                        system_instruction=CACHE_SYSTEM_INSTRUCTION,
                        accumulated_transcript=request.transcript,
                        ttl_seconds=7200,  # 2 hours
                    )

                    # Check if content is too short for caching
                    if cached_content is None:
                        logger.info(
                            "Content too short for caching, using standard analysis"
                        )
                        analysis = await gemini_service.analyze_realtime_transcript(
                            transcript=request.transcript,
                            speakers=speakers_dict,
                            rag_context=rag_context,
                            custom_prompt=custom_prompt,
                        )
                        cache_metadata = CacheMetadata(
                            cache_name="",
                            cache_created=False,
                            cached_tokens=0,
                            prompt_tokens=0,
                            message="å°è©±å…§å®¹è¼ƒçŸ­ï¼Œå°šæœªå•Ÿç”¨ cacheï¼ˆéœ€ >= 1024 tokensï¼‰",
                        )
                    else:
                        # Analyze with cache
                        analysis = await gemini_service.analyze_with_cache(
                            cached_content=cached_content,
                            transcript=request.transcript,
                            speakers=speakers_dict,
                            rag_context=rag_context,
                            custom_prompt=custom_prompt,
                        )

                        # Extract cache metadata from usage_metadata
                        usage_metadata = analysis.get("usage_metadata", {})
                        cache_metadata = CacheMetadata(
                            cache_name=cached_content.name,
                            cache_created=is_new,
                            cached_tokens=usage_metadata.get(
                                "cached_content_token_count", 0
                            ),
                            prompt_tokens=usage_metadata.get("prompt_token_count", 0),
                        )

                        logger.info(
                            f"Cache analysis completed. Cache created: {is_new}, "
                            f"Cached tokens: {cache_metadata.cached_tokens}, "
                            f"Prompt tokens: {cache_metadata.prompt_tokens}"
                        )

                except Exception as cache_error:
                    # Cache failed, fallback to non-cached analysis
                    logger.warning(
                        f"Cache analysis failed, falling back to non-cached: {cache_error}"
                    )
                    analysis = await gemini_service.analyze_realtime_transcript(
                        transcript=request.transcript,
                        speakers=speakers_dict,
                        rag_context=rag_context,
                        custom_prompt=custom_prompt,
                    )
                    cache_metadata = CacheMetadata(
                        cache_name="",
                        cache_created=False,
                        cached_tokens=0,
                        prompt_tokens=0,
                        error=str(cache_error),
                    )
            else:
                # Cache disabled or no session_id, use standard analysis
                logger.info("Cache disabled or no session_id, using standard analysis")
                analysis = await gemini_service.analyze_realtime_transcript(
                    transcript=request.transcript,
                    speakers=speakers_dict,
                    rag_context=rag_context,
                    custom_prompt=custom_prompt,
                )

            # Calculate latency
            latency_ms = int((time.time() - start_time) * 1000)
            provider_metadata = ProviderMetadata(
                provider="gemini", latency_ms=latency_ms, model="gemini-2.5-flash"
            )

        # Extract safety_level from LLM response, default to "green" if not present
        safety_level = analysis.get("safety_level", "green")

        # Validate safety_level (must be green, yellow, or red)
        if safety_level not in ["green", "yellow", "red"]:
            logger.warning(
                f"Invalid safety_level '{safety_level}' from LLM, defaulting to 'green'"
            )
            safety_level = "green"

        # Calculate response time in milliseconds
        response_time_ms = int((time.time() - start_time) * 1000)

        # Prepare data for BigQuery (asynchronous write)
        gbq_data = {
            "id": str(uuid.uuid4()),
            "tenant_id": "island_parents",  # Fixed for web version
            "session_id": None,  # Web version has no session concept
            "analyzed_at": datetime.now(timezone.utc),
            "analysis_type": request.mode.value,  # "emergency" or "practice"
            "safety_level": safety_level,  # "green", "yellow", or "red"
            "matched_suggestions": analysis.get("suggestions", []),
            "transcript_segment": request.transcript[:1000],  # Limit to 1000 chars
            "response_time_ms": response_time_ms,
            "created_at": datetime.now(timezone.utc),
        }

        # Schedule GBQ write as background task (non-blocking)
        background_tasks.add_task(write_to_gbq_async, gbq_data)

        # Build response
        return RealtimeAnalyzeResponse(
            safety_level=safety_level,
            summary=analysis.get("summary", ""),
            alerts=analysis.get("alerts", []),
            suggestions=analysis.get("suggestions", []),
            time_range=request.time_range,
            timestamp=datetime.now(timezone.utc).isoformat(),
            rag_sources=rag_sources,
            cache_metadata=cache_metadata,
            provider_metadata=provider_metadata,
        )
    except Exception as e:
        logger.error(f"Realtime analysis failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/elevenlabs-token")
async def generate_elevenlabs_token():
    """Generate a single-use token for ElevenLabs Speech-to-Text WebSocket.

    This endpoint calls ElevenLabs API to generate a temporary token that
    can be used by the frontend to connect to their WebSocket service.
    This approach keeps the API key secure on the server side.

    Returns:
        Dict with 'token' key containing the single-use token

    Raises:
        HTTPException: If token generation fails
    """
    try:
        # Get API key from environment
        api_key = os.getenv("ELEVEN_LABS_API_KEY")
        if not api_key:
            logger.error("ELEVEN_LABS_API_KEY not found in environment")
            raise HTTPException(
                status_code=500, detail="ElevenLabs API key not configured"
            )

        # Call ElevenLabs API to generate single-use token
        # Token type: "realtime_scribe" for speech-to-text WebSocket
        url = "https://api.elevenlabs.io/v1/single-use-token/realtime_scribe"
        headers = {"xi-api-key": api_key}

        async with httpx.AsyncClient() as client:
            response = await client.post(url, headers=headers, timeout=30.0)

            if response.status_code != 200:
                logger.error(
                    f"ElevenLabs API error: {response.status_code} - {response.text}"
                )
                raise HTTPException(
                    status_code=500,
                    detail=f"Failed to generate token: {response.text}",
                )

            token_data = response.json()
            logger.info("Successfully generated ElevenLabs token")

            return {"token": token_data.get("token")}

    except httpx.TimeoutException:
        logger.error("Timeout calling ElevenLabs API")
        raise HTTPException(
            status_code=504, detail="Timeout generating token from ElevenLabs"
        )
    except Exception as e:
        logger.error(f"Token generation failed: {e}")
        raise HTTPException(status_code=500, detail=f"Token generation failed: {e}")


@router.post("/parents-report", response_model=ParentsReportResponse)
async def generate_parents_report(
    request: ParentsReportRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db),
):
    """Generate a comprehensive parenting communication report.

    Analyzes parent-child conversation transcript and provides:
    1. Summary/theme of the conversation (neutral stance)
    2. Communication highlights (what went well)
    3. Areas for improvement with specific suggestions
    4. Relevant RAG references from parenting knowledge base

    This endpoint queries the parenting RAG knowledge base and uses
    Gemini to generate structured feedback.

    Results are persisted to BigQuery for analytics.
    """
    import json
    import time
    import uuid

    # Track timing for GBQ
    start_time = datetime.now(timezone.utc)
    rag_start_time = None
    rag_end_time = None
    llm_start_time = None
    llm_end_time = None

    try:
        # Step 1: Search RAG knowledge base for relevant parenting content
        logger.info("Searching RAG for parenting-related content")
        rag_start_time = time.time()
        rag_sources = await _search_rag_knowledge(
            transcript=request.transcript,
            db=db,
            top_k=5,  # Get more sources for comprehensive report
            similarity_threshold=0.5,
        )
        rag_end_time = time.time()
        rag_search_time_ms = int((rag_end_time - rag_start_time) * 1000)

        # Step 2: Build RAG context for prompt
        rag_context = ""
        if rag_sources:
            rag_context_parts = ["\n\nğŸ“š ç›¸é—œè¦ªå­æ•™é¤ŠçŸ¥è­˜åº«å…§å®¹ï¼ˆä¾›åƒè€ƒï¼‰ï¼š\n"]
            for idx, source in enumerate(rag_sources, 1):
                rag_context_parts.append(
                    f"[{idx}] {source.title} ({source.theory}): {source.content}"
                )
            rag_context = "\n".join(rag_context_parts)
            logger.info(f"Found {len(rag_sources)} relevant RAG sources")
        else:
            logger.info("No RAG sources found, proceeding without context")

        # Step 3: Build analysis prompt
        analysis_prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„è¦ªå­æºé€šåˆ†æå¸«ï¼Œè² è²¬åˆ†æå®¶é•·èˆ‡å­©å­çš„å°è©±ï¼Œæä¾›å»ºè¨­æ€§çš„å›é¥‹ã€‚

ã€å°è©±é€å­—ç¨¿ã€‘
{request.transcript}

{rag_context}

ã€åˆ†æè¦æ±‚ã€‘
è«‹ä»¥ä¸­æ€§ã€å®¢è§€ã€æº«å’Œçš„ç«‹å ´åˆ†æé€™æ¬¡å°è©±ï¼Œæä¾›ä»¥ä¸‹ 4 å€‹éƒ¨åˆ†ï¼š

1. **å°è©±ä¸»é¡Œèˆ‡æ‘˜è¦**ï¼ˆsummaryï¼‰
   - ç°¡çŸ­èªªæ˜é€™æ¬¡å°è©±çš„ä¸»é¡Œæ˜¯ä»€éº¼
   - ä¸­æ€§ç«‹å ´ï¼Œä¸æ‰¹åˆ¤ï¼Œè®“å®¶é•·çŸ¥é“ã€Œé€™æ¬¡åˆ°åº•èªªäº†ä»€éº¼ã€
   - 1-2 å¥è©±å³å¯

2. **æºé€šäº®é»**ï¼ˆhighlightsï¼‰
   - åˆ—å‡ºå®¶é•·åœ¨æºé€šä¸­åšå¾—å¥½çš„åœ°æ–¹
   - ä¾‹å¦‚ï¼šå±•ç¾åŒç†å¿ƒã€é¡˜æ„å‚¾è½ã€å˜—è©¦ç†è§£å­©å­æ„Ÿå—ç­‰
   - ç”¨æ­£å‘ã€é¼“å‹µçš„èªæ°£
   - 3-5 å€‹äº®é»ï¼Œæ¯å€‹ â‰¤ 30 å­—

3. **æ”¹é€²å»ºè­°**ï¼ˆimprovementsï¼‰
   - æŒ‡å‡ºå€¼å¾—æ›´å¥½çš„åœ°æ–¹
   - æä¾›å…·é«”ã€å¯æ“ä½œçš„å»ºè­°æˆ–æ›å¥è©±èªª
   - æº«å’Œã€éæ‰¹åˆ¤çš„èªæ°£
   - æ¯å€‹å»ºè­°åŒ…å«ï¼š
     * issue: éœ€è¦æ”¹é€²çš„åœ°æ–¹ï¼ˆå…·é«”æè¿°ï¼Œâ‰¤ 40 å­—ï¼‰
     * suggestion: å…·é«”å»ºè­°æˆ–æ›å¥è©±èªªï¼ˆâ‰¤ 60 å­—ï¼‰
   - 2-4 å€‹å»ºè­°

4. **çŸ¥è­˜åº«åƒè€ƒ**ï¼ˆrag_referencesï¼‰
   - å·²è‡ªå‹•æä¾›ä¸Šæ–¹çš„ RAG çŸ¥è­˜åº«å…§å®¹
   - ä½ ä¸éœ€è¦é¡å¤–è™•ç†ï¼Œåªéœ€åœ¨åˆ†ææ™‚åƒè€ƒå³å¯

ã€èªæ°£è¦æ±‚ã€‘
- æº«å’Œã€åŒç†ã€å»ºè¨­æ€§
- é¿å…æ‰¹åˆ¤æˆ–è®“å®¶é•·æ„Ÿåˆ°è¢«æŒ‡è²¬
- ç”¨ã€Œå¯ä»¥è©¦è©¦ã€ã€Œæˆ–è¨±ã€ã€Œæ›å€‹æ–¹å¼ã€ç­‰æŸ”å’Œå¼•å°è©
- ç„¦é»æ”¾åœ¨ã€Œå¦‚ä½•åšå¾—æ›´å¥½ã€è€Œéã€Œå“ªè£¡åšéŒ¯ã€

ã€è¼¸å‡ºæ ¼å¼ã€‘
è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼ˆä¸è¦ç”¨ markdown code blockï¼Œç›´æ¥è¼¸å‡º JSONï¼‰ï¼š

{{
  "summary": "å°è©±ä¸»é¡Œæ‘˜è¦ï¼ˆ1-2 å¥ï¼‰",
  "highlights": [
    "äº®é»1ï¼ˆâ‰¤ 30 å­—ï¼‰",
    "äº®é»2ï¼ˆâ‰¤ 30 å­—ï¼‰",
    "äº®é»3ï¼ˆâ‰¤ 30 å­—ï¼‰"
  ],
  "improvements": [
    {{
      "issue": "éœ€è¦æ”¹é€²çš„åœ°æ–¹ï¼ˆâ‰¤ 40 å­—ï¼‰",
      "suggestion": "å…·é«”å»ºè­°æˆ–æ›å¥è©±èªªï¼ˆâ‰¤ 60 å­—ï¼‰"
    }}
  ]
}}

âš ï¸ é‡è¦ï¼šè«‹ç¢ºä¿ JSON æ ¼å¼æ­£ç¢ºï¼Œä¸è¦åœ¨æœ€å¾Œä¸€å€‹å…ƒç´ å¾Œé¢åŠ é€—è™Ÿï¼ˆtrailing commaï¼‰ï¼

è«‹é–‹å§‹åˆ†æã€‚"""

        # Step 4: Call Gemini for analysis
        logger.info("Calling Gemini for report generation")
        llm_start_time = time.time()
        gemini_response = await gemini_service.chat_completion(
            prompt=analysis_prompt,
            temperature=0.7,  # Higher temperature for more natural language
            return_metadata=True,  # Get usage metadata for observability
        )
        llm_end_time = time.time()
        llm_call_time_ms = int((llm_end_time - llm_start_time) * 1000)

        # Extract response text and metadata
        llm_raw_response = gemini_response["text"]
        usage_metadata = gemini_response.get("usage_metadata", {})

        # Step 5: Parse Gemini response
        try:
            # Try to extract JSON from response
            if "```json" in llm_raw_response:
                json_start = llm_raw_response.find("```json") + 7
                json_end = llm_raw_response.find("```", json_start)
                json_text = llm_raw_response[json_start:json_end].strip()
            elif "{" in llm_raw_response:
                json_start = llm_raw_response.find("{")
                json_end = llm_raw_response.rfind("}") + 1
                json_text = llm_raw_response[json_start:json_end]
            else:
                raise ValueError("No JSON found in response")

            # Remove trailing commas from JSON (common LLM mistake)
            import re

            json_text = re.sub(r",(\s*[}\]])", r"\1", json_text)

            analysis = json.loads(json_text)
            logger.info("Successfully parsed Gemini response")

        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"Failed to parse Gemini response: {e}")
            logger.error(f"Response text: {llm_raw_response[:500]}")
            raise HTTPException(
                status_code=500, detail="Failed to parse AI analysis response"
            )

        # Step 6: Build response
        improvements_list = [
            ImprovementSuggestion(
                issue=item.get("issue", ""), suggestion=item.get("suggestion", "")
            )
            for item in analysis.get("improvements", [])
        ]

        response = ParentsReportResponse(
            summary=analysis.get("summary", ""),
            highlights=analysis.get("highlights", []),
            improvements=improvements_list,
            rag_references=rag_sources,
            timestamp=datetime.now(timezone.utc).isoformat(),
        )

        # Step 7: Prepare GBQ data for analytics
        end_time = datetime.now(timezone.utc)
        duration_ms = int((end_time - start_time).total_seconds() * 1000)

        # Determine safety level based on number of improvements
        # More improvements = more issues = higher concern level
        safety_level = "green"  # Default
        if len(improvements_list) >= 4:
            safety_level = "yellow"  # Multiple areas to improve
        elif len(improvements_list) >= 2:
            safety_level = "green"  # Normal feedback
        # Note: parents_report doesn't have explicit "red" level like realtime

        # Prepare comprehensive GBQ data for observability
        gbq_data = {
            # IDs and metadata
            "id": str(uuid.uuid4()),
            "tenant_id": "island_parents",
            "session_id": request.session_id if request.session_id else None,
            "request_id": str(uuid.uuid4()),
            # Timestamps
            "analyzed_at": start_time,
            "start_time": start_time,
            "end_time": end_time,
            "created_at": end_time,
            # Analysis type and result
            "analysis_type": "parents_report",
            "safety_level": safety_level,
            "matched_suggestions": [
                f"{imp.issue} â†’ {imp.suggestion}" for imp in improvements_list
            ],
            "analysis_result": analysis,  # Full parsed JSON
            # Input data
            "transcript": request.transcript,  # Store full transcript
            "speakers": None,  # Parents report doesn't have speaker info
            # Prompts
            "system_prompt": None,  # Gemini doesn't separate system/user in this call
            "user_prompt": analysis_prompt,  # The full prompt
            "prompt_template": "parents_report_v1",
            # RAG information
            "rag_used": len(rag_sources) > 0,
            "rag_query": request.transcript[
                :200
            ],  # First 200 chars used for RAG search
            "rag_documents": [
                {
                    "content": source.content[:500],
                    "source": source.title,
                    "similarity": source.score,
                }
                for source in rag_sources
            ]
            if rag_sources
            else None,
            "rag_sources": [source.title for source in rag_sources]
            if rag_sources
            else [],
            "rag_top_k": 5,
            "rag_similarity_threshold": 0.5,
            "rag_search_time_ms": rag_search_time_ms if rag_start_time else None,
            # Model information
            "provider": "gemini",
            "model_name": "gemini-2.5-flash",
            "model_version": "2.5",
            # Timing breakdown
            "duration_ms": duration_ms,
            "api_response_time_ms": duration_ms,
            "llm_call_time_ms": llm_call_time_ms if llm_start_time else None,
            # LLM response
            "llm_raw_response": llm_raw_response,
            # Token usage (from Gemini usage_metadata)
            "prompt_tokens": usage_metadata.get("prompt_token_count"),
            "completion_tokens": usage_metadata.get("candidates_token_count"),
            "total_tokens": usage_metadata.get("total_token_count"),
            "cached_tokens": usage_metadata.get("cached_content_token_count"),
            "estimated_cost_usd": _calculate_gemini_cost(usage_metadata)
            if usage_metadata
            else None,
            # Cache info (not used in parents_report)
            "use_cache": False,
            "cache_hit": None,
            "cache_key": None,
            "gemini_cache_ttl": None,
            # Mode
            "mode": "parents_report",
        }

        # Schedule GBQ write as background task (non-blocking)
        background_tasks.add_task(write_to_gbq_async, gbq_data)

        logger.info(
            f"Parents report generated successfully in {duration_ms}ms with {len(improvements_list)} improvements"
        )

        return response

    except HTTPException:
        # Re-raise HTTP exceptions
        raise
    except Exception as e:
        logger.error(f"Parents report generation failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))
