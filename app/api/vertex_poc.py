"""Vertex AI RAG Engine POC API endpoints"""

import asyncio
import tempfile
import os
from typing import List, Optional
from datetime import datetime

from fastapi import APIRouter, HTTPException, UploadFile, File
from pydantic import BaseModel

from vertexai import init as vertexai_init
from vertexai.preview import rag
from vertexai.preview.generative_models import GenerativeModel, Tool
from google.cloud import aiplatform

# Configuration
PROJECT_ID = "groovy-iris-473015-h3"
LOCATION = "us-east4"  # Virginia - GA, no allowlist required (us-central1 needs allowlist)

# Initialize Vertex AI (uses Application Default Credentials)
# Make sure GOOGLE_APPLICATION_CREDENTIALS env var points to correct credentials
# or run: gcloud auth application-default login
vertexai_init(project=PROJECT_ID, location=LOCATION)
aiplatform.init(project=PROJECT_ID, location=LOCATION)

router = APIRouter(prefix="/api/rag/vertex-poc", tags=["vertex-poc"])


# ================================
# Request/Response Models
# ================================

class CreateCorpusRequest(BaseModel):
    display_name: Optional[str] = None
    description: str = "Vertex AI RAG POC Corpus"


class CreateCorpusResponse(BaseModel):
    corpus_name: str
    display_name: str
    status: str
    message: str


class UploadDefaultDocsRequest(BaseModel):
    corpus_name: str


class UploadDefaultDocsResponse(BaseModel):
    corpus_name: str
    files_count: int
    imported_count: int
    status: str


class QueryRequest(BaseModel):
    corpus_name: str
    question: str
    top_k: int = 5
    use_gemini: bool = False


class QueryContext(BaseModel):
    rank: int
    score: float
    text: str
    source: str


class QueryResponse(BaseModel):
    question: str
    method: str
    num_results: int
    contexts: List[QueryContext]
    gemini_response: Optional[str] = None
    thinking_process: Optional[str] = None  # New: capture thinking/reasoning
    grounding_score: Optional[float] = None  # New: grounding quality score
    processing_time: float


class CompareRequest(BaseModel):
    vertex_corpus_name: str
    question: str
    top_k: int = 5


class CompareResponse(BaseModel):
    question: str
    vertex_results: QueryResponse
    existing_rag_results: dict
    comparison: dict


class CorpusInfo(BaseModel):
    name: str
    display_name: str
    create_time: Optional[str] = None
    description: Optional[str] = None


class ListCorpusResponse(BaseModel):
    corpuses: List[CorpusInfo]
    total: int


# ================================
# Test Documents
# ================================

TEST_DOCUMENTS = [
    {
        "filename": "holland_interest_theory.txt",
        "content": """Holland ËÅ∑Ê•≠ËààË∂£ÁêÜË´ñ

John L. Holland ÊèêÂá∫ËÅ∑Ê•≠ËààË∂£ÁêÜË´ñÔºàHolland Codes or Holland Occupational ThemesÔºâ

Ê†∏ÂøÉÊ¶ÇÂøµÔºö
‚Ä¢ ‰∫∫ÈÉΩÂú®ËøΩÊ±ÇËàáÂÖ∂È°ûÂûãÂåπÈÖçÁöÑÂ∑•‰ΩúÁí∞Â¢ÉÔºåÈÄôÊ®£ÁöÑÁí∞Â¢ÉÂèØ‰ª•ÊñΩÂ±ïÂÄã‰∫∫ÊâçËÉΩ„ÄÅÂ±ïÁ§∫‰∫∫ÁöÑÊÖãÂ∫¶ËàáÂÉπÂÄº„ÄÅ‰∏¶ËÉΩÂãù‰ªªÂïèÈ°åËß£Ê±∫ËàáËßíËâ≤ÊâÆÊºî„ÄÇ
‚Ä¢ ‰∫∫Ê†ºËàáÂ∑•‰ΩúÁí∞Â¢ÉÁöÑÈÅ©ÈÖçÁ®ãÂ∫¶ÔºåÂΩ±Èüø‰∫ÜÂ∑•‰ΩúÊªøÊÑèÂ∫¶„ÄÅÁ©©ÂÆöÂ∫¶ÂíåËÅ∑Ê•≠ÊàêÂ∞±„ÄÇ
‚Ä¢ ËÅ∑Ê•≠ÂèØ‰ª•ÊîπËÆä‰∫∫„ÄÅ‰∫∫‰πüÂèØ‰ª•ÊîπËÆäÁí∞Â¢É„ÄÇ
‚Ä¢ ÊØèÂÄã‰∫∫ÊàñÂ§öÊàñÂ∞ëÈÉΩÊúâÈÄôÂÖ≠Á®ÆÈ°ûÂûãÔºå‰ΩÜÊòØÁâπÂÆöÈ°ûÂûãÊØîËºÉÂ∏∏Ë¢´Â±ïÁèæ„ÄÅÈ°ØÊÄß„ÄÅÂÑ™Âã¢ÊàñÊòØÊÖ£Áî®„ÄÇ

ÂÖ≠Â§ßÈ°ûÂûãÔºö

1. ÂØ¶Ë∏êËÄÖ R (Realistic)
ÊÄßÊ†ºÊèèËø∞ÔºöÂñúÊ≠°Ë¶™Ëá™ÂãïÊâã‰øÆÁêÜËàáË£ΩÈÄ†‰∫ãÁâ©„ÄÅËß£Ê±∫ÂïèÈ°å„ÄÇÈáçË¶ñË°åÂãïËÄå‰∏çÊòØË®ÄË™ûÂíåËßÄÂøµ„ÄÇÁç®Á´ã„ÄÅÂº∑ÂÅ•„ÄÅËÇ¢È´îÂçîË™ø„ÄÅÂêÉËã¶ËÄêÂãû„ÄÇÂñúÊ≠°Êà∂Â§ñÂ∑•‰Ωú„ÄÅ‰ΩøÁî®Â∑•ÂÖ∑ËàáÊ©üÊ¢∞„ÄÇÂñúÊ≠°ËôïÁêÜÂÖ∑È´îÂïèÈ°åÔºå‰∏çÂñúÊ≠°ÊäΩË±°ÂïèÈ°å„ÄÇ
Â∑•‰ΩúÂÅèÂ•ΩÔºöËôïÁêÜ‰∫ãÁâ©
ÈóúÈçµË©ûÔºöË°åÂãïÊ¥æ„ÄÅÂØ¶Èöõ„ÄÅÊâãÂ∑ß„ÄÅÊ©üÊ¢∞ÊâçËÉΩ
ÂÖ∏ÂûãËÉΩÂäõÔºöÊìç‰ΩúÂ∑•ÂÖ∑„ÄÅÈÅãÂãïÊ¥ªÂãï
Â∑•‰ΩúÂõûÂ†±ÔºöÂèØ‰ª•ÁúãÂà∞Â∑•‰ΩúÁöÑÂØ¶È´îÊàêÊûú
ÂÖ∏ÂûãËÅ∑Ê•≠ÔºöÊ©üÊ¢∞/Â∑•Á®ã„ÄÅÂ∑•Âå†„ÄÅÂªöÂ∏´„ÄÅËæ≤ÊûóÊºÅÁâß‰∫∫Âì°„ÄÅÂÅ•Ë∫´ÁëúÁèàÊïôÁ∑¥

2. ÊÄùËÄÉËÄÖ I (Investigative)
ÊÄßÊ†ºÊèèËø∞ÔºöÁ∂ìÂ∏∏Ê¥ªÂú®Ëá™Â∑±ÁöÑÊÄùËÄÉ‰∏≠„ÄÇ‰∏çÂèóÊàêË¶èÊùüÁ∏õ„ÄÅÁç®Á´ãÊÄùËÄÉ„ÄÅÂÖÖÊªøÁü•ÊÄßÂ•ΩÂ•á„ÄÅÊ¥ûÂØüÂäõ„ÄÅÈÇèËºØÂº∑„ÄÇÂñúÊ≠°ÈÄèÈÅéÈñ±ËÆÄËàáË®éË´ñ‰æÜÊé¢Á¥¢ËßÄÂøµ„ÄÅÂñúÊ≠°Ë§áÈõúËàáÊäΩË±°ÊÄßÁöÑÂøÉÊô∫ÊåëÊà∞„ÄÅÈÄèÈÅéÊÄùËÄÉËàáÂàÜÊûê‰æÜËß£Ê±∫ÂïèÈ°å„ÄÇ
Â∑•‰ΩúÂÅèÂ•ΩÔºöËôïÁêÜ‰∫ãÁâ©ËàáËßÄÂøµ
ÈóúÈçµË©ûÔºöÂàÜÊûê„ÄÅÁü•ÊÄß„ÄÅÊá∑Áñë„ÄÅÁç®Á´ã„ÄÅÂ≠∏ËÄÖ
Â∑•‰ΩúÂõûÂ†±ÔºöÂñúÊ≠°ÊúâËá™‰∏ªÊ¨äÔºåËÉΩÂ§†ÊúâËá™Áî±ÁöÑÁ©∫ÈñìÂèäÊ©üÊúÉ‰æÜÊªøË∂≥Ëá™Â∑±ÁöÑÂ•ΩÂ•áÂøÉ
ÂÖ∏ÂûãËÅ∑Ê•≠ÔºöÁßëÁ†î‰∫∫Âì°„ÄÅÊïôÂ∏´„ÄÅËªüÈ´î/Â∑•Á®ãÂ∏´„ÄÅÈÜ´Áîü„ÄÅ‰∫∫ÊñáÁ†îÁ©∂

3. ÂâµÈÄ†ËÄÖ A (Artistic)
ÊÄßÊ†ºÊèèËø∞ÔºöÊúâÊïèÈä≥ÁöÑÊÑüÊÄß„ÄÅÁõ¥Ë¶∫Âº∑„ÄÅÂØåÊÉ≥ÂÉèÂäõ„ÄÇËóâÁî±ÂØåÊúâÂâµÊÑèÁöÑÊñπÂºèË°®ÈÅîËá™Êàë„ÄÇÂú®Ë¶∫ÂØüÈ°èËâ≤„ÄÅËÅ≤Èü≥„ÄÅÊÉÖÊÑü‰∏äÈùàÊïèÔºåÂÆπÊòìÊ≤àÊµ∏ÊñºÁæéÁöÑ‰∫ãÁâ©‰πã‰∏≠„ÄÇ
Â∑•‰ΩúÂÅèÂ•ΩÔºöÂâµÈÄ†ËàáÂâµÊñ∞„ÄÅË®≠Ë®à„ÄÅË°®ÈÅîÂ±ïÁèæ„ÄÅËá™Áî±ÂΩàÊÄß„ÄÅÊúâË∂£
ÈóúÈçµË©ûÔºöË§áÈõú„ÄÅÊÉ≥ÂÉè„ÄÅË°®Áèæ„ÄÅÂâµÊÑè
Â∑•‰ΩúÂõûÂ†±ÔºöÂâµÊñ∞ËàáËÆäÂåñÔºõÁæéÊÑüÈ´îÈ©ó
ÂÖ∏ÂûãËÅ∑Ê•≠ÔºöËóùË°ìÂÆ∂„ÄÅÈü≥Ê®ÇÂÆ∂„ÄÅÊºîÂì°„ÄÅË®≠Ë®àÂ∏´„ÄÅ‰ΩúÂÆ∂
ÂêÑÁî¢Ê•≠‰∏≠ÁöÑÁ†îÁôºÂâµÊñ∞Á´ØÔºåËÄå‰∏çÊòØÁ∂≠‰øÆÁ∂≠ÈÅãÁ´Ø

4. Âä©‰∫∫ËÄÖ S (Social)
ÊÄßÊ†ºÊèèËø∞ÔºöÈáçË¶ñ‰∫∫ÈöõÈóú‰øÇÔºåÂ∞ç‰∫∫ÊïèÊÑü„ÄÅÂæÖ‰∫∫ÁúüË™†„ÄÅÂ∞ç‰∫∫ÈóúÊá∑„ÄÅÊîØÊåÅ‰ªñ‰∫∫„ÄÅÂ∞ç‰∫∫Ë≤†Ë≤¨„ÄÅËôï‰∫ãÂúìËûç„ÄÅÊúâÂêåÁêÜÂøÉÔºåÈóúÊ≥®ÁÑ¶ÈªûÊîæÂú®‰∫∫‰ª•Âèä‰∫∫ÁöÑÈúÄÊ±ÇÔºåËÄå‰∏çÊòØÂú®Êñº‰∫ãÁâ©„ÄÇ
Â∑•‰ΩúÂÅèÂ•ΩÔºöÂñúÊ≠°Ëàá‰∫∫‰∫íÂãï„ÄÅËôïÁêÜ‰ªñ‰∫∫ÂïèÈ°å
ÈóúÈçµË©ûÔºöÊ®ÇÊñºÂä©‰∫∫„ÄÅÂñúÊ≠°ÊïôÂ∞é„ÄÅÊøÄÂãµÂà•‰∫∫„ÄÅÂèØË¢´Ë´ÆË©¢„ÄÅÊúçÂãôÂà•‰∫∫„ÄÅË¶∫ÂØü‰ªñ‰∫∫ÈúÄÊ±Ç
Â∑•‰ΩúÂõûÂ†±ÔºöÂä©‰∫∫‰πãÂæåÁöÑÂõûÈ•ãËàáÁµêÊûú„ÄÅ‰∏ªÁÆ°Âêå‰∫ãÈóú‰øÇ
ÂÖ∏ÂûãËÅ∑Ê•≠ÔºöÊïôÂ∏´„ÄÅËºîÂ∞é„ÄÅÁ§æÂ∑•„ÄÅÈÜ´Ë≠∑„ÄÅÂÆóÊïô„ÄÅÂÖ¨Èóú

5. ÂΩ±ÈüøËÄÖ E (Enterprising)
ÊÄßÊ†ºÊèèËø∞ÔºöÁ≤æÂäõÂÖÖÊ≤õ„ÄÅÁÜ±ÊÉÖÁ©çÊ•µ„ÄÅËá™‰ø°„ÄÅ‰∏ªÂ∞é„ÄÅÊîøÊ≤ªÊâãËÖïÔºåÂº∑ÁÉàËá™ÊàëÈû≠Á≠ñ„ÄÇËÉΩÈÄèÈÅéËôïÁêÜ‰∫∫ÈöõËàáÁÆ°ÁêÜÂ∞àÊ°àÁöÑËÉΩÂäõ‰æÜÈÅîÊàêÂ∑•‰ΩúÁõÆÊ®ô„ÄÇ‰∫´ÂèóÈáëÈå¢„ÄÅÊ¨äÂäõ„ÄÅÂú∞‰Ωç‰ª•Âèä‰∏ªÂ∞éÊ¨äÔºåÈ°òÊÑèËóâÁî±ÊâøÊìîÈ¢®Èö™‰æÜËß£Ê±∫ÂïèÈ°å„ÄÇ
Â∑•‰ΩúÂÅèÂ•ΩÔºöËôïÁêÜË≥áÊñô„ÄÅËàá‰∫∫‰∫íÂãï
ÈóúÈçµË©ûÔºö‰ºÅÂúñÂøÉ„ÄÅÂñÑÁ§æ‰∫§„ÄÅÊàêÂ∞±ÊÑü„ÄÅÂ≠òÂú®ÊÑü
ÂÖ∏ÂûãËÉΩÂäõÔºöÈ†òÂ∞é„ÄÅÁÆ°ÁêÜ„ÄÅÁµÑÁπî
Â∑•‰ΩúÂõûÂ†±ÔºöÊàêÂ∞±ÊÑü(‰æÜÊ∫êÂæàÂ§öÔºöÂä©‰∫∫„ÄÅÂçáÈÅ∑„ÄÅÊî∂ÂÖ•„ÄÅÁ∞ΩÂñÆ„ÄÅÁç≤Âãù„ÄÅÂâµÊñ∞‚Ä¶)
ÂÖ∏ÂûãËÅ∑Ê•≠ÔºöÊ•≠ÂãôÈä∑ÂîÆ„ÄÅË°åÈä∑‰ºÅÁï´„ÄÅÁ∂ìÁáüÁÆ°ÁêÜ„ÄÅÂè∏Ê≥ïÊîøÊ≤ª

6. ÁµÑÁπîËÄÖ C (Conventional)
ÊÄßÊ†ºÊèèËø∞Ôºö‰∫ïÁÑ∂ÊúâÂ∫è„ÄÅÊ≤àÈùú„ÄÅË¨πÊÖé„ÄÅÁ≤æÁ¢∫„ÄÅË≤†Ë≤¨„ÄÅÂØ¶Èöõ„ÄÅÊ¢ùÁêÜ„ÄÇÂº∑ÁÉàÈúÄË¶ÅÂÆâÂÖ®ÊÑüËàáÁ¢∫ÂÆöÊÄß„ÄÇÂÅö‰∫ãÂñúÊ≠°ÊèêÂâçÊ∫ñÂÇôÔºåÊúâÂßãÊúâÁµÇÔºåÊ≥®ÈáçÁ¥∞ÁØÄÔºåÈÅµÂæ™ÊÖ£‰æã„ÄÇ‰ªªÂãôÂ∞éÂêëÔºåÂÅèÂ•ΩÂÆåÊàêÂà•‰∫∫ÊâÄÁôºÂãïÁöÑ‰∫ãÊÉÖ„ÄÇ
Â∑•‰ΩúÂÅèÂ•ΩÔºöËôïÁêÜË≥áÊñôËàá‰∫ãÁâ©
ÈóúÈçµË©ûÔºöË¨πÊÖé„ÄÅÈÅµÂÆàË¶èÁ´†„ÄÅËá™Âà∂
ÂÖ∏ÂûãËÉΩÂäõÔºöÂÆâÊéíÊ¨°Â∫è„ÄÅÊ≥®ÈáçÁ¥∞ÁØÄ„ÄÅÂÅµÊü•Á≥æÊ≠£„ÄÅÊ∏ÖÂñÆËàáSOP
ÂÖ∏ÂûãËÅ∑Ê•≠ÔºöÁßòÊõ∏„ÄÅË≤°ÂãôÈáëËûçÈ¢®ÁÆ°„ÄÅÊúÉË®à„ÄÅË°åÊîø‰∏ª‰ªª„ÄÅÁ∑®ËºØ„ÄÅÂÖ¨ÂÆ∂Ê©üÈóú„ÄÅÂìÅÁÆ°ÂìÅ‰øù

ÂÖ©ÂÖ©ÁµÑÂêàËàáËÅ∑Ê•≠ËààË∂£È†òÂüüÔºö
‚Ä¢ SA ÊïôÂ∏´ËºîÂ∞éË´ÆÂïÜÁ§æÂ∑•„ÄÅSI ‰∫∫È°ûÁ§æÊúÉÂøÉÁêÜÈÜ´ÁôÇÊïôËÇ≤Ë´ÆË©¢
‚Ä¢ SE Âíå‰∫∫‰∫íÂãï ÂÆ¢Êà∂Á∂ìÁêÜ„ÄÅSC Âä©ÁêÜ‰∫∫Ë≥áÂÖ¨Âãô‰∫∫Âì°
‚Ä¢ IR Â≠∏Ë°ìÁ†îÁ©∂„ÄÅÁ°¨È´îÂ∑•Á®ãÂ∏´„ÄÅIA ÂâµÊñ∞Ë®≠Ë®à(Áî¢ÂìÅ„ÄÅË°åÈä∑)„ÄÅIC Êï∏ÊìöÂàÜÊûê„ÄÅËªüÈ´îÂ∑•Á®ãÂ∏´
‚Ä¢ EC ÂïÜÁÆ°Â∑•‰ΩúË°åÈä∑Ê•≠ÂãôÁÆ°ÁêÜ„ÄÅEI Áî¢Ê•≠ÂàÜÊûêÁ≠ñÁï•Á†îÁ©∂
‚Ä¢ EA Â§ßÁúæÂÇ≥Êí≠Â™íÈ´î‰∏ªÊí≠„ÄÅER ÁîüÁî¢ÁÆ°ÁêÜÈñãÁôºÊ•≠Âãô
‚Ä¢ AE ÂêÑÁ®ÆË®≠Ë®àÂ∏´„ÄÅAR ËóùË°ì‰∫∫„ÄÅÁæéÊ•≠„ÄÅAC Á∂≤Á´ô‰ºÅÂäÉ/ÂÆ§ÂÖßË®≠Ë®à/ÈõúË™åÁ∑®ËºØ (Â∏∏ÁüõÁõæ)
‚Ä¢ CR Ë¶èÂäÉÂü∑Ë°å„ÄÅSR È§êÈ£≤ÊúçÂãô ÈÅãÂãïÊïôÁ∑¥ Áâ©Ê≤ªÊé®ÊãøÊåâÊë©

ÁêÜË´ñÊáâÁî®Ôºö
‰∏ÄËá¥ÂíåÂàÜÂåñ
‚Ä¢ ‰∏ÄËá¥ÊÄßÔºöÈ°ûÂûã‰πãÈñìÁõ∏‰ººÁöÑÁ®ãÂ∫¶„ÄÇÁõ∏ÈÑ∞(RI„ÄÅRC‚Ä¶)„ÄÅÁõ∏Èöî„ÄÅÁõ∏Â∞ç(RS„ÄÅEI„ÄÅAC)„ÄÇËëóÈáçÂú®ÂâçÂÖ©Á¢ºÁöÑÁõ∏Â∞ç‰ΩçÁΩÆ„ÄÇÁõ∏Â∞çÂ∏∂‰æÜÁüõÁõæÁå∂Ë±´ÁöÑÁîüÊ∂ØÊäâÊìáÂõ∞Êìæ„ÄÇ
‚Ä¢ ÂàÜÂåñÊÄßÔºöÂÖßÂú®ËààË∂£Âº∑Â∫¶ÁöÑÂ∑ÆÂà•„ÄÇËëóÈáçÂú®ÊúÄÈ´òÂàÜÂíåÊúÄ‰ΩéÂàÜÁöÑÂ∑ÆË∑ù„ÄÇÂàÜÂåñÊÄßÈ´òÊØîËºÉÂñÆÁ¥îÔºå‰πüÂ∞±ÊòØË™™ÂàÜÊï∏Â∑ÆÁï∞Â§ß„ÄÇÂàÜÂåñ‰ΩéÊúâÂÖ©Á®ÆÔºöÊôÆÈÅçÈ´òÊàñÊòØÊôÆÈÅç‰Ωé„ÄÇ
"""
    },
    {
        "filename": "cip_casve_model.txt",
        "content": """Ë™çÁü•Ë≥áË®äËôïÁêÜÁêÜË´ñÔºàCognitive Information Processing, CIPÔºâ

CIPÁêÜË´ñËß£Èáã‰∫∫È°ûÂ¶Ç‰ΩïËôïÁêÜË≥áË®äÁöÑÂøÉÁêÜÂ≠∏Ê°ÜÊû∂ÔºåÁâπÂà•ÈÅ©Áî®ÊñºÁîüÊ∂ØÁôºÂ±ïËàáÊ±∫Á≠ñËºîÂ∞éÔºåÂπ´Âä©ÂÄãÈ´îÊõ¥ÊúâÊïàÂú∞ËôïÁêÜËÅ∑Ê∂ØË≥áË®ä‰∏¶ÈÄ≤Ë°åÊ±∫Á≠ñ„ÄÇ

CIP ÁöÑË≥áË®äËôïÁêÜÈáëÂ≠óÂ°îÔºö
ÁÇ∫‰∫Ü‰ΩøÂÄã‰∫∫ÊàêÁÇ∫Áç®Á´ã„ÄÅË≤†Ë≤¨‰ªªÁöÑËÅ∑Ê•≠ÂïèÈ°åËß£Ê±∫ËÄÖÂíåÊ±∫Á≠ñËÄÖÔºåÊüê‰∫õË≥áË®äËôïÁêÜËÉΩÂäõÂøÖÈ†àÂú®‰∏ÄÁîü‰∏≠‰∏çÊñ∑ÁôºÂ±ï„ÄÇÈÄô‰∫õÂäüËÉΩÂèØ‰ª•Ë¢´Ë®≠ÊÉ≥ÁÇ∫ÂΩ¢Êàê‰∏ÄÂÄãÂÖ∑Êúâ‰∏âÂÄãÂàÜÂ±§ÊéíÂàóÁöÑË≥áË®äËôïÁêÜÈáëÂ≠óÂ°î„ÄÇÁü•Ë≠òÈ†òÂüü‰ΩçÊñºÂ∫ïÂ±§ÔºåÊ±∫Á≠ñÊäÄËÉΩÈ†òÂüüÂåÖÂê´‰∏≠Â±§ÔºåËÄåÂü∑Ë°åËôïÁêÜÈ†òÂüüÂâá‰ΩçÊñºÈ†ÇÁ´Ø„ÄÇ

1. Ëá™ÊàëÂíåÈÅ∏È†ÖÁü•Ë≠òÔºöÂåÖÊã¨ÂÄã‰∫∫ÁöÑÂÉπÂÄºËßÄ„ÄÅËààË∂£„ÄÅÊäÄËÉΩÂíåÂ∞±Ê•≠ÂÅèÂ•ΩÔºå‰ª•ÂèäÂ∞çËÅ∑Ê•≠„ÄÅÊïôËÇ≤„ÄÅÂüπË®ìÂíåÂ∞±Ê•≠ÁöÑ‰∫ÜËß£„ÄÇ

2. Ê±∫Á≠ñÊäÄËÉΩÔºöÂåÖÊã¨Áî®ÊñºËß£Ê±∫ÂïèÈ°åÂíåÊ±∫Á≠ñÁöÑÈÄöÁî®Ë≥áË®äËôïÁêÜÊäÄËÉΩÔºåÂ¶ÇÁêÜÊÄß„ÄÅÁõ¥Ë¶∫„ÄÅ‰æùË≥¥ÂíåÈÄÉÈÅøÁ≠â„ÄÇCASVE Âæ™Áí∞ÊòØÂÖ∂‰∏≠‰∏ÄÁ®ÆÁêÜÊÄßÁöÑÊ±∫Á≠ñÊñπÊ≥ï„ÄÇ

3. Âü∑Ë°åËôïÁêÜÔºöÊ∂âÂèäÂæåË®≠Ë™çÁü•ÂäüËÉΩÔºå‰æãÂ¶ÇËá™ÊàëÂ∞çË©±ÔºàÂÖßÂøÉÁöÑÊÉ≥Ê≥ïÔºâ„ÄÅËá™ÊàëÊÑèË≠òÔºàÂ∞çËá™Â∑±‰ΩúÁÇ∫Ê±∫Á≠ñËÄÖÁöÑË™çÁü•ÔºâÂíåÁõ£ÊéßËàáÊéßÂà∂ÔºàÁÆ°ÁêÜÊ±∫Á≠ñÈÄ≤Â∫¶ÂíåË≤†Èù¢ÊÉ≥Ê≥ïÁöÑËÉΩÂäõÔºâ

CASVEÂæ™Áí∞ÔºàÁôºÈü≥ÁÇ∫„Äåca-sah-veh„ÄçÔºâÔºö
CASVEÊ®°ÂûãÂ∞áÊ±∫Á≠ñÈÅéÁ®ãÂàÜÁÇ∫‰∫îÂÄãÈöéÊÆµÔºå‰ª•‰æøÈÄêÊ≠•ËôïÁêÜËÅ∑Ê∂ØË≥áË®äËàáÂïèÈ°åÔºö

1. CommunicationÔºàÊ∫ùÈÄöÔºâÔºö
ÁôºÁèæÂïèÈ°åÊàñÈúÄÊ±ÇÔºåÁ¢∫Ë™çÁèæÊúâÁãÄÊÖãÂíåÊúüÊúõÁãÄÊÖã‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇ

2. AnalysisÔºàÂàÜÊûêÔºâÔºö
‰ΩøÁî®ËÅ∑Ê∂ØË©ï‰º∞ÂíåË≥áË®ä‰æÜÊæÑÊ∏ÖÂíåÂ¢ûÂº∑Â∞çËá™ÊàëÁöÑÁêÜËß£ÔºåÂåÖÊã¨Ëá™ÊàëÁü•Ë≠òËàáÈÅ∏È†ÖÁü•Ë≠òÔºå‰∏¶Â∞áÂÖ©ËÄÖÁõ∏‰∫íÈóúËÅØÔºåÂª∫Á´ãÊõ¥Ë§áÈõúÁöÑËá™ÊàëËàáÈÅ∏È†ÖÁöÑÂøÉÁêÜÊ®°Âûã

3. SynthesisÔºàÁ∂úÂêàÔºâÔºö
Êì¥Â±ïÈÅ∏È†ÖÁØÑÂúç (ÁôºÊï£ÊÄùËÄÉ) Âæå Á∏ÆÂ∞èÈÅ∏È†ÖÁØÑÂúç (Êî∂ÊñÇÊÄùËÄÉ) ÔºåÁõÆÊ®ôÊòØÈÅøÂÖçÈåØÈÅéÈÅ∏È†ÖÔºåÂêåÊôÇ‰∏çÊúÉÂõ†ÈÅ∏È†ÖÈÅéÂ§öËÄå‰∏çÁü•ÊâÄÊé™

4. ValuingÔºàË©ï‰º∞ÔºâÔºö
Ë©ï‰º∞ÈÅ∏È†ÖÁöÑÊàêÊú¨ÂíåÊïàÁõäÔºå‰∏¶Á¢∫ÂÆöÂàùÊ≠•ÈÅ∏Êìá„ÄÇ

5. ExecutionÔºàÂü∑Ë°åÔºâÔºö
Âà∂ÂÆö‰∏¶Âü∑Ë°åË°åÂãïË®àÁï´Ôºå‰∏¶Âú®ÂøÖË¶ÅÊôÇÈÄ≤Ë°åÁèæÂØ¶Ê™¢È©ó„ÄÇÂÆåÊàêÂü∑Ë°åÂæåÊúÉÂõûÂà∞Ê∫ùÈÄöÈöéÊÆµÔºåË©ï‰º∞ÂïèÈ°åÊòØÂê¶Â∑≤Ëß£Ê±∫

CASVE Âæ™Áí∞ÂèØËÉΩÂõ†ÁÇ∫Â§öÁ®ÆÂéüÂõ†ÈáçË§áÔºö
‚Ä¢ Âú®ÂæåÁ∫åÈöéÊÆµÈÅáÂà∞Âõ∞Èõ£ÔºåÈúÄË¶ÅÂõûÂà∞ÂÖàÂâçÁöÑÈöéÊÆµ„ÄÇ
‚Ä¢ ÁôºÁèæÂÖàÂâçÁöÑÈÅ∏Êìá‰∏çÈÅ©ÂêàÔºåÊàñÊòØÂá∫Áèæ‰∫ÜÊñ∞ÁöÑÈÅ∏Êìá„ÄÇ
‚Ä¢ Â§ñÈÉ®Áí∞Â¢ÉÊàñÂÄã‰∫∫ÊÉÖÊ≥ÅÁôºÁîüËÆäÂåñ„ÄÇ
‚Ä¢ Âú®Ê∫ùÈÄöÈöéÊÆµÊ≤íÊúâÂÖÖÂàÜÊé¢Á¥¢ÂïèÈ°åÁöÑÂÄã‰∫∫„ÄÅÁ§æÊúÉÂíåÊÉÖÊÑüÂõ†Á¥†„ÄÇ
"""
    },
    {
        "filename": "schlossberg_transition_model.txt",
        "content": """ÁîüÊ∂ØËΩâÊèõÊ®°Âºè (Schlossberg, 1984)

ÁîüÊ∂ØËΩâÊèõÊ®°ÂºèÂåÖÂê´‰∏âÂÄã‰∏ªË¶ÅÊ≠•È©üÔºö
1. Èù¢Â∞ç / ÁúãÂæÖËΩâÊèõÔºàApproaching TransitionsÔºâ
2. Áõ§Èªû 4S Ë≥áÊ∫êÔºàTaking Stock of Coping Resources: The 4S SystemÔºâ
3. ÊéåÊè°ËΩâÊèõÔºàTaking ChargeÔºâ

‰∫∫ÂÄë‰∏ÄÈñãÂßãÁúãÂæÖËΩâÊèõÁöÑË¶ñËßíÔºåÂ∞áÊúÉÂΩ±ÈüøÂà∞ÂæåÁ∫åÁöÑÊÄùÁ∂≠ËàáË°åÂãïÔºà4SÔºâ„ÄÇ‰∏ÄÈñãÂßãÁöÑÂàùÁ¥öË©ï‰º∞ÔºåÊúÉÈùûÂ∏∏Èö±Êô¶Âú∞ÂΩ±ÈüøÊàëÂÄëÁöÑÊÄùÁ∂≠ËàáË°åÂãï„ÄÇÁ¨¨‰∏ÄÂÄãÈáçË¶ÅÁöÑÂçîÂä©ÈóúÈçµÈªûÔºåÂ∞±ÊòØÊîæÊÖ¢ÈÄôÂÄãÂàùÊ≠•Ë©ï‰º∞ÁöÑÊ≠∑Á®ãÔºå‰∏¶Ë®≠Ê≥ïÂ∞áÊ°à‰∏ªËßÄÈªûËàáË¶ñËßíÂºïÂ∞éËá≥ËºÉÊúâÊïàÁöÑÊñπÂêë„ÄÇË©≤‰∫ã‰ª∂Â∞çÊàëÊòØÂç±Ê©üÊàñËΩâÊ©üÔºü

4S Á≥ªÁµ±Ôºö

1. ÊÉÖÊ≥ÅÔºàSituationÔºâ
ÂÄãÈ´îÊÄéÈ∫ºÁúãÂæÖÁèæÂú®ÁôºÁîüÁöÑ‰∫ãÊÉÖÔºåÂú®ÊÉÖÊ≥Å‰∏≠ÊàëÂÄëÈúÄË¶ÅÂõûÁ≠î‰ª•‰∏ãÂïèÈ°åÔºö
‚Ä¢ Ëß∏Áôº TriggerÔºöÊòØ‰ªÄÈ∫ºËß∏Áôº‰∫ÜÈÄôÂÄãËΩâÊèõÔºü
‚Ä¢ ÊôÇÊ©ü TimingÔºöÈÄôÂÄãËΩâÊèõËàáÂÄã‰∫∫ÊâÄË™çÂÆöÁöÑÁ§æÊúÉÊôÇÈêòÔºàsocial clockÔºâÊúâ‰ΩïÁõ∏ÈóúÔºüÈÄôÂÄãËΩâÊèõÊòØ‰æÜÁöÑÊ≠£Â•ΩÈÇÑÊòØ‰æÜÂæó‰∏çÂ∑ßÔºü
‚Ä¢ ÊéßÂà∂ ControlÔºöÊàëÂÄëÂú®ÈÄôÂÄãËΩâÊèõ‰∏≠ÂèØ‰ª•ÊéßÂà∂ÁöÑÈÉ®ÂàÜÊúâÂì™‰∫õÔºü
‚Ä¢ ËßíËâ≤ÊîπËÆä Role ChangeÔºöÈÄôÂÄãËΩâÊèõÊòØÂê¶ÊúâÊ∂âÂèäËßíËâ≤ÁöÑÊîπËÆäÔºü
‚Ä¢ ÊåÅÁ∫åÊôÇÈñì DurationÔºöÈÄôÂÄãËΩâÊèõÊòØÊ∞∏‰πÖÊÄßÁöÑÊàñÊòØÊö´ÊôÇÊÄßÁöÑÔºü
‚Ä¢ Êó©ÂÖàÁ∂ìÈ©ó Previous ExperienceÔºöÂÄãÈ´îÈÅéÂéªÁ¢∞Âà∞È°û‰ººËΩâÊèõÊÉÖÊ≥ÅÊôÇÊòØÊÄéÈ∫ºÊ®£ÁöÑÂë¢Ôºü
‚Ä¢ ÁõÆÂâçÂ£ìÂäõ Concurrent StressÔºöÈÄôÂÄãËΩâÊèõÊúÉËÆìÂÄãÈ´îÁèæÂú®Èù¢Ëá®Âà∞ÈÇ£‰∫õÂ£ìÂäõÔºüÈÄô‰∫õÂ£ìÂäõÊúâÂ§öÂ§ßÁöÑÂΩ±ÈüøÔºü
‚Ä¢ Ë°°Èëë AssessmentÔºöÂÄãÈ´îË™çÁÇ∫ÈÄôÂÄãËΩâÊèõÊòØÊ≠£ÂêëÊàñË≤†Âêë„ÄÅËâØÊÄßÊàñÊÉ°ÊÄßÔºü

2. Ëá™ÊàëÔºàSelfÔºâ
ÂÄã‰∫∫ÁâπÊÄßÔºö
‚Ä¢ Á§æÊúÉÂøÉÁêÜËÉΩÂäõÔºàPsychosocial competenceÔºâ
‚Ä¢ ÊÄßÂà•ÂíåÊÄßÂà•ËßíËâ≤ÂÆöÁæ©ÔºàSex and Sex-role identificationÔºâ
‚Ä¢ Âπ¥ÈΩ°ÂíåÁîüÂëΩÈöéÊÆµÔºàAge and life stageÔºâ
‚Ä¢ ÂÅ•Â∫∑ÁãÄÊÖãÔºàState of HealthÔºâ
‚Ä¢ Á®ÆÊóèÔºàRace/ethnicityÔºâ
‚Ä¢ Á§æÁ∂ìÂú∞‰ΩçÔºàSocioeconomic statusÔºâ
‚Ä¢ ÂÉπÂÄºÂ∞éÂêëÔºàvalue orientationÔºâ
‚Ä¢ Êó©ÊúüËΩâÊèõÁ∂ìÈ©óÔºàprevious experience with a transition of a similar natureÔºâ

ÂøÉÁêÜË≥áÊ∫êÔºö
‚Ä¢ Ëá™ÊàëÁôºÂ±ïÔºàEgo developmentÔºâ
‚Ä¢ Ê®ÇËßÄÂèäËá™ÊàëÊïàËÉΩÔºàoptimism and self-efficacyÔºâ
‚Ä¢ ÊâøË´æÂèäÂÉπÂÄºËßÄÔºàcommitment and valuesÔºâ
‚Ä¢ ÈùàÊÄßËàáÈüåÊÄßÔºàspirituality and resiliencyÔºâ

3. ÊîØÊåÅÔºàSupportÔºâ
‚Ä¢ ‰∫∫ÈöõÊîØÊåÅÁ≥ªÁµ±ÔºàInterpersonal Support SystemsÔºâÔºöË¶™ÂØÜÈóú‰øÇ„ÄÅÂÆ∂‰∫∫„ÄÅÊúãÂèãÁ∂≤Áµ°
‚Ä¢ Á§æÊúÉÊîØÊåÅÔºàInstitutional SupportsÔºâÔºöËÅ∑Ê•≠Â∑•ÊúÉ„ÄÅÂÆóÊïôÊ©üÊßã„ÄÅÊîøÊ≤ªÂúòÈ´î„ÄÅÁ§æÁ¶èÂñÆ‰Ωç„ÄÅÁ§æÂçÄÊ©üÊßã
‚Ä¢ Áâ©ÁêÜË®≠ÁΩÆÔºàPhysical SettingÔºâÔºöÊ∞£ÂÄôÊ∫´Â∫¶„ÄÅÂ±Ö‰ΩèÁí∞Â¢É„ÄÅÈÑ∞Â±Ö„ÄÅÁîüÊ¥ªË¶èÂäÉ„ÄÅÂ∑•‰ΩúË®≠ÊñΩ
‚Ä¢ Ë≥áË®ä„ÄÅÈáëÈå¢„ÄÅË™≤Á®ã
‚Ä¢ Âº±‰∫∫ËÑàÈÄ£Áµê„ÄÅÊé®Ëñ¶„ÄÅÊ±ÇËÅ∑Âπ´Âä©

4. Á≠ñÁï•ÔºàStrategiesÔºâ
ÂçîÂä©Ê≠•È©üÔºö
1. È¶ñÂÖàÂÖà‰∫ÜËß£ÂÄãÊ°àÂ∞çÊñºÊ≠§ÁîüÊ∂ØËΩâÊèõÁöÑÊÉ≥Ê≥ïÁÇ∫‰Ωï
2. Êé•ËëóÂçîÂä©ÂÄãÊ°àÂàÜÊûêËá™Â∑±Âú®Ê≠§ËΩâÊèõ‰∏≠ÁöÑÂÑ™Âä£ËÉΩÂäõ‰ª•ÂèäÈÅéÂéªÁ∂ìÈ©óÔºå‰∏¶Âú®Ê≠§ÈöéÊÆµ‰∫ÜËß£ÂÄãÊ°àÂ∞çÊñºÁîüÊ∂ØËΩâÊèõÁöÑÂøÉÁêÜË≥áÊ∫êÂº∑Âº±Â¶Ç‰ΩïÔºå‰ª•ÂèäÂèØ‰ª•Â¶Ç‰ΩïÊèêÂçáÂíåÈÅãÁî®
3. ËÆìÂÄãÊ°àÁúãË¶ãËá™Â∑±ÁõÆÂâçÊâÄÊìÅÊúâÊîØÊåÅÁ≥ªÁµ±ÊúâÂì™‰∫õÔºåÊèêÂçáÂÄãÊ°àÂ∞çÈù¢Ëá®ÁîüÊ∂ØËΩâÊèõÊåëÊà∞ÁöÑËá™‰ø°Ôºå‰πüÂÆâÂÆöÂÄãÊ°àÁöÑÁÑ¶ÊÖÆ
4. ÊúÄÂæåÂâáÊòØËàáÂÄãÊ°à‰∏ÄËµ∑Ë®éË´ñÂõ†ÊáâÁ≠ñÁï•Ôºå‰∏¶Âú®Ë°åÂãïÁï∂‰∏≠‰∏ÄÈÇäÈÄ≤Ë°åÁèæÊ≥ÅË©ï‰º∞Ôºå‰æùÁÖßÈúÄË¶ÅÂä†Âº∑ÁöÑÂú∞ÊñπÂÜçÊ¨°ÈÄ≤Ë°åË®éË´ñÂíå‰øÆÊ≠£Ôºå‰∏çÂÅúÁöÑÂæ™Áí∞Áõ¥Âà∞ÂÄãÊ°àÈ†ÜÂà©ÂÆåÊàêÁîüÊ∂ØËΩâÊèõÁÇ∫Ê≠¢„ÄÇ
"""
    }
]


# ================================
# API Endpoints
# ================================

@router.post("/corpus/create", response_model=CreateCorpusResponse)
async def create_corpus(request: CreateCorpusRequest):
    """Âª∫Á´ã Vertex AI RAG Corpus"""
    try:
        display_name = request.display_name or f"poc-corpus-{datetime.now().strftime('%Y%m%d-%H%M%S')}"

        corpus = rag.create_corpus(
            display_name=display_name,
            description=request.description,
        )

        return CreateCorpusResponse(
            corpus_name=corpus.name,
            display_name=display_name,
            status="success",
            message=f"Corpus created successfully: {corpus.name}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create corpus: {str(e)}")


@router.delete("/corpus/{corpus_name:path}")
async def delete_corpus(corpus_name: str):
    """Âà™Èô§ Vertex AI RAG Corpus"""
    try:
        rag.delete_corpus(name=corpus_name)
        return {"status": "success", "message": f"Corpus deleted: {corpus_name}"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to delete corpus: {str(e)}")


@router.get("/corpus/list", response_model=ListCorpusResponse)
async def list_corpuses():
    """ÂàóÂá∫ÊâÄÊúâ POC CorpusÔºàÈ°ØÁ§∫ÂêçÁ®±ÂåÖÂê´ 'poc'Ôºâ"""
    try:
        # List all corpuses
        corpuses = rag.list_corpora()

        # Filter POC corpuses
        poc_corpuses = []
        for corpus in corpuses:
            if "poc" in corpus.display_name.lower():
                poc_corpuses.append(CorpusInfo(
                    name=corpus.name,
                    display_name=corpus.display_name,
                    create_time=str(corpus.create_time) if hasattr(corpus, 'create_time') else None,
                    description=getattr(corpus, 'description', None)
                ))

        return ListCorpusResponse(
            corpuses=poc_corpuses,
            total=len(poc_corpuses)
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to list corpuses: {str(e)}")


@router.delete("/corpus/{corpus_name:path}/files/all")
async def delete_all_files(corpus_name: str):
    """Âà™Èô§ corpus ‰∏≠ÁöÑÊâÄÊúâÊñá‰ª∂"""
    try:
        files = rag.list_files(corpus_name=corpus_name)
        deleted_count = 0

        for file in files:
            try:
                rag.delete_file(name=file.name)
                deleted_count += 1
                print(f"Deleted file: {file.name}")
            except Exception as e:
                print(f"Failed to delete {file.name}: {e}")

        return {
            "status": "success",
            "deleted_count": deleted_count,
            "message": f"Deleted {deleted_count} files from corpus"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to delete files: {str(e)}")


@router.post("/upload/default", response_model=UploadDefaultDocsResponse)
async def upload_default_docs(request: UploadDefaultDocsRequest):
    """‰∏äÂÇ≥È†êË®≠Ê∏¨Ë©¶Êñá‰ª∂Ôºà3 ÂÄãËÅ∑Ê∂ØÁêÜË´ñÔºâ"""
    try:
        # Create temp directory
        temp_dir = tempfile.mkdtemp()
        file_paths = []

        # Write test documents
        for doc in TEST_DOCUMENTS:
            file_path = os.path.join(temp_dir, doc["filename"])
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(doc["content"])
            file_paths.append(file_path)

        # Upload to Vertex AI
        # Â¢ûÂä† chunk size ‰ª•ÊèêÂçáÊ£ÄÁ¥¢ÊïàÊûú
        response = rag.import_files(
            corpus_name=request.corpus_name,
            paths=file_paths,
            chunk_size=1024,  # ‰ªé 512 ÊèêÂçáÂà∞ 1024
            chunk_overlap=200,  # ‰ªé 100 ÊèêÂçáÂà∞ 200
        )

        # Cleanup temp files
        import shutil
        shutil.rmtree(temp_dir)

        return UploadDefaultDocsResponse(
            corpus_name=request.corpus_name,
            files_count=len(TEST_DOCUMENTS),
            imported_count=response.imported_rag_files_count,
            status="success"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to upload documents: {str(e)}")


@router.post("/upload/custom")
async def upload_custom_docs(
    corpus_name: str,
    files: List[UploadFile] = File(...)
):
    """‰∏äÂÇ≥Ëá™Ë®ÇÊñá‰ª∂"""
    try:
        temp_dir = tempfile.mkdtemp()
        file_paths = []

        # Save uploaded files
        for file in files:
            file_path = os.path.join(temp_dir, file.filename)
            with open(file_path, "wb") as f:
                content = await file.read()
                f.write(content)
            file_paths.append(file_path)

        # Upload to Vertex AI
        # Â¢ûÂä† chunk size ‰ª•ÊèêÂçáÊ£ÄÁ¥¢ÊïàÊûú
        response = rag.import_files(
            corpus_name=corpus_name,
            paths=file_paths,
            chunk_size=1024,  # ‰ªé 512 ÊèêÂçáÂà∞ 1024
            chunk_overlap=200,  # ‰ªé 100 ÊèêÂçáÂà∞ 200
        )

        # Cleanup
        import shutil
        shutil.rmtree(temp_dir)

        return {
            "status": "success",
            "files_count": len(files),
            "imported_count": response.imported_rag_files_count
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to upload custom files: {str(e)}")


@router.post("/query", response_model=QueryResponse)
async def query_vertex_rag(request: QueryRequest):
    """Âü∑Ë°å Vertex AI RAG Êü•Ë©¢"""
    import time
    start_time = time.time()

    print(f"=== QUERY REQUEST ===")
    print(f"corpus_name: {request.corpus_name}")
    print(f"question: {request.question}")
    print(f"top_k: {request.top_k}")
    print(f"use_gemini: {request.use_gemini}")

    try:
        if request.use_gemini:
            # Method 2: RAG + Gemini generation (with retrieval contexts)
            # Step 1: Get retrieval contexts first
            retrieval_response = rag.retrieval_query(
                rag_resources=[rag.RagResource(rag_corpus=request.corpus_name)],
                text=request.question,
                similarity_top_k=request.top_k,
            )

            contexts = [
                QueryContext(
                    rank=idx + 1,
                    score=ctx.score,
                    text=ctx.text,
                    source=ctx.source_uri if hasattr(ctx, 'source_uri') else "unknown"
                )
                for idx, ctx in enumerate(retrieval_response.contexts.contexts)
            ]

            # Step 2: Generate with Gemini + Extract grounding metadata
            rag_tool = Tool.from_retrieval(
                retrieval=rag.Retrieval(
                    source=rag.VertexRagStore(
                        rag_resources=[rag.RagResource(rag_corpus=request.corpus_name)],
                        similarity_top_k=request.top_k,
                    ),
                )
            )

            model = GenerativeModel(
                model_name="gemini-2.5-flash",
                tools=[rag_tool]
            )

            response = model.generate_content(request.question)

            # Extract grounding metadata info
            grounding_chunks_count = 0
            grounding_score = None

            if hasattr(response, 'candidates') and len(response.candidates) > 0:
                candidate = response.candidates[0]
                if hasattr(candidate, 'grounding_metadata'):
                    grounding_meta = candidate.grounding_metadata

                    # Count grounding chunks
                    if hasattr(grounding_meta, 'grounding_chunks'):
                        grounding_chunks_count = len(grounding_meta.grounding_chunks)
                        print(f"‚úÖ Found {grounding_chunks_count} grounding chunks")

                    # Try to extract any quality metrics
                    if hasattr(grounding_meta, 'grounding_support'):
                        grounding_score = float(grounding_meta.grounding_support)
                        print(f"üéØ grounding_support: {grounding_score}")

                    # Check for retrieval_queries
                    if hasattr(grounding_meta, 'retrieval_queries'):
                        print(f"üîç retrieval_queries: {grounding_meta.retrieval_queries}")

            processing_time = time.time() - start_time

            return QueryResponse(
                question=request.question,
                method="rag_with_gemini",
                num_results=len(contexts),
                contexts=contexts,
                gemini_response=response.text,
                thinking_process=None,  # Not available with standard RAG
                grounding_score=grounding_score,
                processing_time=processing_time
            )
        else:
            # Method 1: Retrieval only
            response = rag.retrieval_query(
                rag_resources=[rag.RagResource(rag_corpus=request.corpus_name)],
                text=request.question,
                similarity_top_k=request.top_k,
            )

            contexts = [
                QueryContext(
                    rank=idx + 1,
                    score=ctx.score,
                    text=ctx.text,
                    source=ctx.source_uri if hasattr(ctx, 'source_uri') else "unknown"
                )
                for idx, ctx in enumerate(response.contexts.contexts)
            ]

            processing_time = time.time() - start_time

            result = QueryResponse(
                question=request.question,
                method="retrieval_only",
                num_results=len(contexts),
                contexts=contexts,
                gemini_response=None,
                processing_time=processing_time
            )

            print(f"DEBUG: Returning {len(contexts)} contexts")
            if contexts:
                print(f"DEBUG: First context:")
                print(f"  - Rank: {contexts[0].rank}")
                print(f"  - Score: {contexts[0].score}")
                print(f"  - Text preview: {contexts[0].text[:200]}...")
                print(f"  - Source: {contexts[0].source}")

            return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Query failed: {str(e)}")


@router.post("/compare", response_model=CompareResponse)
async def compare_rag_systems(request: CompareRequest):
    """Â∞çÊØî Vertex AI RAG vs ÁèæÊúâ RAG Á≥ªÁµ±"""
    try:
        # Query Vertex AI
        vertex_request = QueryRequest(
            corpus_name=request.vertex_corpus_name,
            question=request.question,
            top_k=request.top_k,
            use_gemini=False
        )
        vertex_results = await query_vertex_rag(vertex_request)

        # Query existing RAG (mock for now - you can implement real comparison)
        existing_results = {
            "method": "existing_rag",
            "num_results": 0,
            "message": "Existing RAG comparison not implemented yet"
        }

        # Compare
        comparison = {
            "vertex_avg_score": sum(c.score for c in vertex_results.contexts) / len(vertex_results.contexts) if vertex_results.contexts else 0,
            "vertex_processing_time": vertex_results.processing_time,
            "existing_avg_score": 0,
            "existing_processing_time": 0
        }

        return CompareResponse(
            question=request.question,
            vertex_results=vertex_results,
            existing_rag_results=existing_results,
            comparison=comparison
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Comparison failed: {str(e)}")


@router.get("/health")
async def health_check():
    """ÂÅ•Â∫∑Ê™¢Êü•"""
    return {
        "status": "healthy",
        "project_id": PROJECT_ID,
        "location": LOCATION,
        "vertex_ai_initialized": True
    }
