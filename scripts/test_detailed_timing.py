#!/usr/bin/env python3
"""
è©³ç´°è¨ˆæ™‚æ¸¬è©¦ - åˆ†è§£æ¯å€‹ç’°ç¯€çš„è€—æ™‚
"""

import asyncio
import os
import sys
import time

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.core.database import SessionLocal  # noqa: E402
from app.models.case import Case  # noqa: E402
from app.models.client import Client  # noqa: E402
from app.models.session import Session as SessionModel  # noqa: E402
from app.services.gemini_service import GeminiService  # noqa: E402
from app.services.openai_service import OpenAIService  # noqa: E402
from app.services.rag_retriever import RAGRetriever  # noqa: E402


async def test_detailed_timing():
    """æ¸¬è©¦æ¯å€‹ç’°ç¯€çš„è©³ç´°è¨ˆæ™‚"""

    db = SessionLocal()

    try:
        print("=" * 60)
        print("ğŸ” è©³ç´°è¨ˆæ™‚æ¸¬è©¦")
        print("=" * 60)
        print()

        # æº–å‚™æ¸¬è©¦æ•¸æ“š
        print("ğŸ“ æº–å‚™æ¸¬è©¦æ•¸æ“š...")
        session = (
            db.query(SessionModel).filter(SessionModel.tenant_id == "island").first()
        )

        if not session:
            print("âŒ æ‰¾ä¸åˆ°æ¸¬è©¦ session")
            return

        case = db.query(Case).filter(Case.id == session.case_id).first()
        client = db.query(Client).filter(Client.id == case.client_id).first()

        test_transcript = """
        å®¶é•·ï¼šä½ ä»Šå¤©åœ¨å­¸æ ¡éå¾—æ€éº¼æ¨£ï¼Ÿ
        å­©å­ï¼šé‚„å¥½å•Š
        å®¶é•·ï¼šæœ‰ä»€éº¼é–‹å¿ƒçš„äº‹å—ï¼Ÿ
        å­©å­ï¼šæ²’æœ‰
        å®¶é•·ï¼šé‚£æœ‰ä»€éº¼ä¸é–‹å¿ƒçš„äº‹å—ï¼Ÿ
        å­©å­ï¼šä¹Ÿæ²’æœ‰
        """

        print(f"   Session ID: {session.id}")
        print(f"   Client: {client.name}")
        print()

        # é–‹å§‹è©³ç´°è¨ˆæ™‚
        print("ğŸš€ é–‹å§‹è©³ç´°è¨ˆæ™‚æ¸¬è©¦")
        print("-" * 60)

        total_start = time.time()
        timings = {}

        # 1. å»ºç«‹ context
        step_start = time.time()
        context_str = _build_context(session, client, case)
        timings["context_building"] = (time.time() - step_start) * 1000
        print(f"   1. å»ºç«‹ Context: {timings['context_building']:.2f} ms")

        # 2. å»ºç«‹ prompt
        step_start = time.time()
        full_transcript = session.transcript_text or "ï¼ˆå°šç„¡å®Œæ•´é€å­—ç¨¿ï¼‰"
        prompt_template = """ä½ æ˜¯è¦ªå­æ•™é¤Šå°ˆå®¶ï¼Œåˆ†æå®¶é•·èˆ‡å­©å­çš„å°è©±ã€‚

èƒŒæ™¯è³‡è¨Šï¼š
{context}

å®Œæ•´å°è©±é€å­—ç¨¿ï¼š
{full_transcript}

æœ€è¿‘å°è©±ï¼š
{transcript_segment}

è«‹åˆ†æä¸¦è¿”å› JSON æ ¼å¼ï¼š
{{
    "safety_level": "green|yellow|red",
    "severity": 1-3,
    "display_text": "çµ¦å®¶é•·çš„æç¤ºæ–‡å­—",
    "action_suggestion": "å»ºè­°æ¡å–çš„è¡Œå‹•"
}}
"""
        prompt = prompt_template.format(
            context=context_str,
            full_transcript=full_transcript,
            transcript_segment=test_transcript[:500],
        )
        timings["prompt_building"] = (time.time() - step_start) * 1000
        print(f"   2. å»ºç«‹ Prompt: {timings['prompt_building']:.2f} ms")

        # 3. Gemini API èª¿ç”¨
        step_start = time.time()
        gemini = GeminiService()
        ai_response = await gemini.generate_text(
            prompt, temperature=0.3, response_format={"type": "json_object"}
        )
        timings["gemini_api"] = (time.time() - step_start) * 1000
        print(
            f"   3. Gemini API èª¿ç”¨: {timings['gemini_api']:.2f} ms ({timings['gemini_api']/1000:.2f}s)"
        )

        # 4. è§£æ AI response
        step_start = time.time()
        import json

        result_data = json.loads(ai_response)
        timings["response_parsing"] = (time.time() - step_start) * 1000
        print(f"   4. è§£æ Response: {timings['response_parsing']:.2f} ms")

        # 5. RAG æª¢ç´¢
        step_start = time.time()
        openai_service = OpenAIService()
        rag_retriever = RAGRetriever(openai_service)
        try:
            rag_results = await rag_retriever.search(
                query=test_transcript[:200],
                top_k=3,
                threshold=0.7,
                db=db,
                category="parenting",
            )
            timings["rag_retrieval"] = (time.time() - step_start) * 1000
            print(
                f"   5. RAG æª¢ç´¢: {timings['rag_retrieval']:.2f} ms ({timings['rag_retrieval']/1000:.2f}s)"
            )
        except Exception as e:
            timings["rag_retrieval"] = (time.time() - step_start) * 1000
            rag_results = []
            print(
                f"   5. RAG æª¢ç´¢: {timings['rag_retrieval']:.2f} ms (å¤±æ•—: {str(e)[:50]}...)"
            )

        # 6. çµ„è£çµæœ
        step_start = time.time()
        rag_documents = [
            {
                "doc_id": None,
                "title": r["document"],
                "content": r["text"],
                "relevance_score": r["score"],
                "chunk_id": None,
            }
            for r in rag_results
        ]
        result_data["rag_documents"] = rag_documents
        timings["result_assembly"] = (time.time() - step_start) * 1000
        print(f"   6. çµ„è£çµæœ: {timings['result_assembly']:.2f} ms")

        # ç¸½è¨ˆ
        total_time = (time.time() - total_start) * 1000
        timings["total"] = total_time

        print()
        print("=" * 60)
        print("ğŸ“Š æ™‚é–“åˆ†è§£")
        print("=" * 60)
        print()

        # è¨ˆç®—æ‰€æœ‰å·²çŸ¥æ­¥é©Ÿçš„æ™‚é–“
        known_time = sum(
            [
                timings["context_building"],
                timings["prompt_building"],
                timings["gemini_api"],
                timings["response_parsing"],
                timings["rag_retrieval"],
                timings["result_assembly"],
            ]
        )

        # æœªçŸ¥æ™‚é–“ï¼ˆå¯èƒ½æ˜¯ç¶²è·¯å»¶é²ã€Python ç­‰å¾…ç­‰ï¼‰
        unknown_time = total_time - known_time

        print(
            f"1. Context å»ºç«‹:     {timings['context_building']:>8.2f} ms ({timings['context_building']/total_time*100:>5.1f}%)"
        )
        print(
            f"2. Prompt å»ºç«‹:      {timings['prompt_building']:>8.2f} ms ({timings['prompt_building']/total_time*100:>5.1f}%)"
        )
        print(
            f"3. Gemini API:       {timings['gemini_api']:>8.2f} ms ({timings['gemini_api']/total_time*100:>5.1f}%) â­"
        )
        print(
            f"4. Response è§£æ:    {timings['response_parsing']:>8.2f} ms ({timings['response_parsing']/total_time*100:>5.1f}%)"
        )
        print(
            f"5. RAG æª¢ç´¢:         {timings['rag_retrieval']:>8.2f} ms ({timings['rag_retrieval']/total_time*100:>5.1f}%) â­"
        )
        print(
            f"6. çµæœçµ„è£:         {timings['result_assembly']:>8.2f} ms ({timings['result_assembly']/total_time*100:>5.1f}%)"
        )
        print(
            f"7. å…¶ä»–/æœªçŸ¥:        {unknown_time:>8.2f} ms ({unknown_time/total_time*100:>5.1f}%)"
        )
        print("-" * 60)
        print(f"   ç¸½è¨ˆ:             {total_time:>8.2f} ms ({total_time/1000:.2f}s)")
        print()

        # é—œéµç™¼ç¾
        print("ğŸ” é—œéµç™¼ç¾:")
        print(f"   â€¢ Gemini API è€—æ™‚: {timings['gemini_api']/1000:.2f}s")
        print(f"   â€¢ RAG æª¢ç´¢è€—æ™‚: {timings['rag_retrieval']/1000:.2f}s")
        print(
            f"   â€¢ é€™å…©é …åˆè¨ˆ: {(timings['gemini_api'] + timings['rag_retrieval'])/1000:.2f}s"
        )
        print(f"   â€¢ å…¶ä»–æ™‚é–“: {unknown_time/1000:.2f}s")

        if unknown_time > 1000:
            print()
            print("âš ï¸  è­¦å‘Š: æœ‰å¤§é‡æœªçŸ¥æ™‚é–“ï¼Œå¯èƒ½åŸå› ï¼š")
            print("   - ç¶²è·¯å»¶é²")
            print("   - Python async/await èª¿åº¦é–‹éŠ·")
            print("   - JSON åºåˆ—åŒ–/ååºåˆ—åŒ–")
            print("   - å…¶ä»–ç³»çµ±é–‹éŠ·")

    finally:
        db.close()


def _build_context(session, client, case) -> str:
    """å»ºç«‹ context string"""
    context_parts = []

    client_info = f"æ¡ˆä¸»è³‡è¨Š: {client.name}"
    if client.current_status:
        client_info += f", ç•¶å‰ç‹€æ³: {client.current_status}"
    context_parts.append(client_info)

    case_info = f"æ¡ˆä¾‹ç›®æ¨™: {case.goals or 'æœªè¨­å®š'}"
    if case.problem_description:
        case_info += f", å•é¡Œæ•˜è¿°: {case.problem_description}"
    context_parts.append(case_info)

    session_info = f"æœƒè«‡æ¬¡æ•¸: ç¬¬ {session.session_number} æ¬¡"
    if session.notes:
        session_info += f", æœƒè«‡å‚™è¨»: {session.notes}"
    context_parts.append(session_info)

    return "\n".join(context_parts)


if __name__ == "__main__":
    asyncio.run(test_detailed_timing())
