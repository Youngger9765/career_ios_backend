#!/usr/bin/env python3
"""
æ¸¬è©¦è¼•é‡ vs é‡é‡åˆ†æçš„é€Ÿåº¦å°æ¯”

æ¸¬è©¦æ–¹æ¡ˆï¼š
1. Rule-based onlyï¼ˆç´”é—œéµå­— + éš¨æ©Ÿé¼“å‹µå¥ï¼‰
2. Gemini Flashï¼ˆç„¡ RAGï¼Œç°¡å–® promptï¼‰
3. Gemini Flash + RAGï¼ˆå®Œæ•´åˆ†æï¼‰

ç›®æ¨™ï¼šæ‰¾å‡ºæœ€ä½³çš„è¼•é‡ç´šæ–¹æ¡ˆ
"""

import asyncio
import random
import time
from typing import Dict

# æ¨¡æ“¬ Gemini API
try:
    import google.generativeai as genai

    from app.core.config import settings

    genai.configure(api_key=settings.GOOGLE_API_KEY)
except ImportError:
    print("âš ï¸ ç„¡æ³•å°å…¥ Geminiï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š")
    genai = None


# ============================================
# æ–¹æ¡ˆ 1: Rule-based Onlyï¼ˆç´”é—œéµå­—æª¢æ¸¬ï¼‰
# ============================================

DANGER_KEYWORDS = [
    "æ‰“",
    "ç½µ",
    "è¨å­ä½ ",
    "å»æ­»",
    "ä¸æƒ³æ´»",
    "é›¢å®¶å‡ºèµ°",
    "å‚·å®³",
    "è‡ªæ®º",
    "æš´åŠ›",
    "æ¨ä½ ",
]

ENCOURAGEMENTS = {
    "green": [
        "åšå¾—å¾ˆå¥½ï¼ç¹¼çºŒä¿æŒé€™æ¨£çš„æºé€šæ–¹å¼",
        "å¾ˆæ£’çš„äº’å‹•ï¼Œå­©å­èƒ½æ„Ÿå—åˆ°ä½ çš„é—œå¿ƒ",
        "ç¶­æŒæ­£å¸¸èªé€Ÿï¼Œçµ¦å­©å­æ€è€ƒçš„ç©ºé–“",
        "è¨˜å¾—ä¿æŒçœ¼ç¥æ¥è§¸ï¼Œè®“å­©å­æ„Ÿå—åˆ°è¢«é‡è¦–",
        "ä½ çš„èªæ°£å¾ˆæº«å’Œï¼Œé€™å°å­©å­å¾ˆé‡è¦",
    ],
    "yellow": [
        "æ³¨æ„å­©å­çš„æƒ…ç·’è®ŠåŒ–ï¼Œå¯èƒ½éœ€è¦èª¿æ•´èªæ°£",
        "è©¦è‘—å¤šè½å°‘èªªï¼Œçµ¦å­©å­è¡¨é”çš„æ©Ÿæœƒ",
        "è¨˜å¾—å…ˆåŒç†å­©å­çš„æ„Ÿå—ï¼Œå†æå‡ºå»ºè­°",
        "æ·±å‘¼å¸ï¼Œä¿æŒå†·éœï¼Œå­©å­éœ€è¦ä½ çš„ç©©å®š",
        "å¯ä»¥æš«åœä¸€ä¸‹ï¼Œçµ¦å½¼æ­¤ä¸€äº›ç©ºé–“",
    ],
}


def rule_based_analysis(transcript: str, last_safety_level: str = "green") -> Dict:
    """æ–¹æ¡ˆ 1: Pure rule-based"""
    start = time.time()

    # æª¢æŸ¥å±éšªé—œéµå­—
    has_danger = any(keyword in transcript for keyword in DANGER_KEYWORDS)

    if has_danger:
        result = {"type": "trigger_heavy", "reason": "æª¢æ¸¬åˆ°å±éšªé—œéµå­—"}
    else:
        # è¿”å›é¼“å‹µå¥
        suggestion = random.choice(
            ENCOURAGEMENTS.get(last_safety_level, ENCOURAGEMENTS["green"])
        )
        result = {
            "type": "light",
            "safety_level": last_safety_level,
            "suggestion": suggestion,
            "method": "rule-based",
        }

    elapsed = time.time() - start
    result["elapsed_ms"] = elapsed * 1000

    return result


# ============================================
# æ–¹æ¡ˆ 2: Gemini Flashï¼ˆç„¡ RAGï¼‰
# ============================================

LIGHT_PROMPT_TEMPLATE = """ä½ æ˜¯è¦ªå­æ•™é¤ŠåŠ©ç†ï¼Œå¿«é€Ÿè©•ä¼°å°è©±ä¸¦çµ¦äºˆç°¡çŸ­é¼“å‹µã€‚

å°è©±å…§å®¹ï¼š
{transcript}

è«‹ç”¨ JSON æ ¼å¼è¿”å›ï¼ˆä¸è¦æ›è¡Œï¼‰ï¼š
{{"suggestion": "ä¸€å¥è©±é¼“å‹µï¼ˆ20å­—å…§ï¼‰", "safety_level": "green|yellow|red"}}

è¦å‰‡ï¼š
- åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—
- å»ºè­°å¿…é ˆç°¡çŸ­ã€æ­£é¢ã€å…·é«”
- å¦‚æœå°è©±æ­£å¸¸ â†’ green
- å¦‚æœæœ‰è¼•å¾®è¡çª â†’ yellow
- å¦‚æœæœ‰å±éšªè©å½™ â†’ red
"""


async def gemini_light_analysis(transcript: str) -> Dict:
    """æ–¹æ¡ˆ 2: Gemini Flash without RAG"""
    start = time.time()

    if genai is None:
        # æ¨¡æ“¬æ•¸æ“š
        await asyncio.sleep(0.5)  # æ¨¡æ“¬ API å»¶é²
        result = {
            "type": "light",
            "safety_level": "green",
            "suggestion": "åšå¾—å¾ˆå¥½ï¼ç¹¼çºŒä¿æŒ",
            "method": "gemini-light (simulated)",
        }
    else:
        try:
            model = genai.GenerativeModel("gemini-2.0-flash-exp")

            prompt = LIGHT_PROMPT_TEMPLATE.format(transcript=transcript)

            response = await model.generate_content_async(
                prompt,
                generation_config={
                    "temperature": 0.3,
                    "max_output_tokens": 100,
                    "response_mime_type": "application/json",
                },
            )

            import json

            data = json.loads(response.text)

            result = {
                "type": "light",
                "safety_level": data.get("safety_level", "green"),
                "suggestion": data.get("suggestion", "ç¹¼çºŒä¿æŒ"),
                "method": "gemini-light",
            }
        except Exception as e:
            result = {"type": "error", "error": str(e), "method": "gemini-light"}

    elapsed = time.time() - start
    result["elapsed_ms"] = elapsed * 1000

    return result


# ============================================
# æ–¹æ¡ˆ 3: Gemini Flash + RAGï¼ˆå®Œæ•´åˆ†æï¼‰
# ============================================

HEAVY_PROMPT_TEMPLATE = """ä½ æ˜¯å°ˆæ¥­è¦ªå­æ•™é¤Šé¡§å•ï¼Œç²¾é€šå¤šç¨®æ•™é¤Šç†è«–ã€‚

ã€èƒŒæ™¯çŸ¥è­˜ã€‘ï¼ˆä¾†è‡ª RAG çŸ¥è­˜åº«ï¼‰
{rag_context}

ã€å°è©±å…§å®¹ã€‘
{transcript}

ã€æœ€è¿‘å°è©± - ç”¨æ–¼å®‰å…¨è©•ä¼°ã€‘
{recent_transcript}

è«‹åˆ†æä¸¦è¿”å› JSONï¼š
{{
  "safety_level": "green|yellow|red",
  "severity": 1-3,
  "suggestions": ["å»ºè­°1", "å»ºè­°2", "å»ºè­°3"],
  "theory_basis": "ä½¿ç”¨çš„ç†è«–"
}}
"""


async def gemini_heavy_analysis(transcript: str) -> Dict:
    """æ–¹æ¡ˆ 3: Gemini Flash + RAG (å®Œæ•´åˆ†æ)"""
    start = time.time()

    if genai is None:
        # æ¨¡æ“¬æ•¸æ“š
        await asyncio.sleep(2.5)  # æ¨¡æ“¬ RAG + AI å»¶é²
        result = {
            "type": "heavy",
            "safety_level": "green",
            "suggestions": ["å»ºè­°1", "å»ºè­°2", "å»ºè­°3"],
            "theory_basis": "è–©æçˆ¾æ¨¡å¼",
            "method": "gemini-heavy (simulated)",
        }
    else:
        try:
            # æ¨¡æ“¬ RAG æª¢ç´¢ï¼ˆå¯¦éš›æ‡‰è©²èª¿ç”¨ RAG serviceï¼‰
            rag_context = "ä¾é™„ç†è«–æŒ‡å‡ºï¼Œå­©å­éœ€è¦ç©©å®šçš„æƒ…æ„Ÿé€£çµ..."

            model = genai.GenerativeModel("gemini-2.0-flash-exp")

            prompt = HEAVY_PROMPT_TEMPLATE.format(
                rag_context=rag_context,
                transcript=transcript,
                recent_transcript=transcript[-200:],  # æœ€è¿‘ 200 å­—
            )

            response = await model.generate_content_async(
                prompt,
                generation_config={
                    "temperature": 0.3,
                    "max_output_tokens": 500,
                    "response_mime_type": "application/json",
                },
            )

            import json

            data = json.loads(response.text)

            result = {
                "type": "heavy",
                "safety_level": data.get("safety_level", "green"),
                "suggestions": data.get("suggestions", []),
                "theory_basis": data.get("theory_basis", ""),
                "method": "gemini-heavy",
            }
        except Exception as e:
            result = {"type": "error", "error": str(e), "method": "gemini-heavy"}

    elapsed = time.time() - start
    result["elapsed_ms"] = elapsed * 1000

    return result


# ============================================
# æ¸¬è©¦åŸ·è¡Œ
# ============================================


async def run_speed_test():
    """åŸ·è¡Œé€Ÿåº¦å°æ¯”æ¸¬è©¦"""

    # æ¸¬è©¦å ´æ™¯
    test_cases = [
        {
            "name": "æ­£å¸¸å°è©±",
            "transcript": "å®¶é•·ï¼šä½ ä»Šå¤©åœ¨å­¸æ ¡éå¾—æ€éº¼æ¨£ï¼Ÿ\nå­©å­ï¼šé‚„å¥½å•Š\nå®¶é•·ï¼šæœ‰ä»€éº¼é–‹å¿ƒçš„äº‹å—ï¼Ÿ",
            "expected_safety": "green",
        },
        {
            "name": "è¼•å¾®è¡çª",
            "transcript": "å®¶é•·ï¼šä½ æ€éº¼é‚„ä¸å¯«ä½œæ¥­ï¼Ÿ\nå­©å­ï¼šæˆ‘å°±æ˜¯ä¸æƒ³å¯«ï¼\nå®¶é•·ï¼šä½ é€™æ˜¯ä»€éº¼æ…‹åº¦ï¼Ÿ",
            "expected_safety": "yellow",
        },
        {
            "name": "å±éšªæƒ…æ³",
            "transcript": "å­©å­ï¼šæˆ‘è¨å­ä½ ï¼æˆ‘æ¨ä½ ï¼\nå®¶é•·ï¼šä½ èªªä»€éº¼ï¼Ÿ\nå­©å­ï¼šæˆ‘ä¸æƒ³æ´»äº†ï¼",
            "expected_safety": "red",
        },
    ]

    print("=" * 60)
    print("ğŸ§ª è¼•é‡ vs é‡é‡åˆ†æé€Ÿåº¦æ¸¬è©¦")
    print("=" * 60)
    print()

    for case in test_cases:
        print(f"ğŸ“ æ¸¬è©¦å ´æ™¯ï¼š{case['name']}")
        print(f"   å°è©±ï¼š{case['transcript'][:50]}...")
        print()

        # æ–¹æ¡ˆ 1: Rule-based
        result1 = rule_based_analysis(case["transcript"])
        print("   æ–¹æ¡ˆ 1 [Rule-based Only]:")
        print(f"   â±ï¸  è€—æ™‚: {result1['elapsed_ms']:.2f} ms")
        print(f"   ğŸ“Š çµæœ: {result1.get('suggestion', result1.get('reason'))}")
        print()

        # æ–¹æ¡ˆ 2: Gemini Light
        result2 = await gemini_light_analysis(case["transcript"])
        print("   æ–¹æ¡ˆ 2 [Gemini Flash - ç„¡ RAG]:")
        print(
            f"   â±ï¸  è€—æ™‚: {result2['elapsed_ms']:.2f} ms ({result2['elapsed_ms']/1000:.2f}s)"
        )
        print(f"   ğŸ“Š çµæœ: {result2.get('suggestion', result2.get('error', 'N/A'))}")
        print()

        # æ–¹æ¡ˆ 3: Gemini Heavy
        result3 = await gemini_heavy_analysis(case["transcript"])
        print("   æ–¹æ¡ˆ 3 [Gemini Flash + RAG]:")
        print(
            f"   â±ï¸  è€—æ™‚: {result3['elapsed_ms']:.2f} ms ({result3['elapsed_ms']/1000:.2f}s)"
        )
        print(f"   ğŸ“Š çµæœ: {len(result3.get('suggestions', []))} å€‹å»ºè­°")
        print()

        # é€Ÿåº¦å°æ¯”
        print("   ğŸ é€Ÿåº¦å°æ¯”:")
        print("   Rule-based:  1x (baseline)")
        if result2["elapsed_ms"] > 0:
            print(
                f"   Gemini Light: {result2['elapsed_ms']/result1['elapsed_ms']:.1f}x slower"
            )
        if result3["elapsed_ms"] > 0:
            print(
                f"   Gemini Heavy: {result3['elapsed_ms']/result1['elapsed_ms']:.1f}x slower"
            )
        print()
        print("-" * 60)
        print()

    # ç¸½çµ
    print("=" * 60)
    print("ğŸ“Š æ¸¬è©¦çµè«–")
    print("=" * 60)
    print()
    print("æ–¹æ¡ˆå°æ¯”ï¼š")
    print()
    print("1ï¸âƒ£ Rule-based Only:")
    print("   âœ… é€Ÿåº¦: <10ms (æ¥µå¿«)")
    print("   âœ… æˆæœ¬: $0 (å…è²»)")
    print("   âš ï¸  å“è³ª: é€šç”¨é¼“å‹µå¥ï¼Œç„¡é‡å°æ€§")
    print()
    print("2ï¸âƒ£ Gemini Light (ç„¡ RAG):")
    print("   ğŸŸ¡ é€Ÿåº¦: ~500-1500ms (ä¸­ç­‰)")
    print("   ğŸŸ¡ æˆæœ¬: ~$0.02/æ¬¡")
    print("   âœ… å“è³ª: å€‹æ€§åŒ–é¼“å‹µï¼Œæœ‰é‡å°æ€§")
    print()
    print("3ï¸âƒ£ Gemini Heavy (+ RAG):")
    print("   ğŸ”´ é€Ÿåº¦: ~2500-5000ms (æ…¢)")
    print("   ğŸ”´ æˆæœ¬: ~$0.26/æ¬¡")
    print("   âœ… å“è³ª: å®Œæ•´åˆ†æï¼Œç†è«–æ”¯æ’")
    print()


# ============================================
# ä¸»ç¨‹å¼
# ============================================

if __name__ == "__main__":
    asyncio.run(run_speed_test())
