"""rename tables and add multi-tenant auth fields

Revision ID: 4f0f21a16be0
Revises: 2f49d72287b5
Create Date: 2025-10-28 11:24:08.300088

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '4f0f21a16be0'
down_revision: Union[str, None] = '2f49d72287b5'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###

    # Step 1: Create new tables
    op.create_table('counselors',
    sa.Column('email', sa.String(), nullable=False),
    sa.Column('username', sa.String(), nullable=False),
    sa.Column('full_name', sa.String(), nullable=False),
    sa.Column('hashed_password', sa.String(), nullable=False),
    sa.Column('tenant_id', sa.String(), nullable=False),
    sa.Column('role', sa.Enum('COUNSELOR', 'SUPERVISOR', 'ADMIN', name='counselorrole'), nullable=False),
    sa.Column('is_active', sa.Boolean(), nullable=True),
    sa.Column('last_login', sa.DateTime(timezone=True), nullable=True),
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_counselors_email'), 'counselors', ['email'], unique=True)
    op.create_index(op.f('ix_counselors_tenant_id'), 'counselors', ['tenant_id'], unique=False)
    op.create_index(op.f('ix_counselors_username'), 'counselors', ['username'], unique=True)
    op.create_table('clients',
    sa.Column('code', sa.String(), nullable=False),
    sa.Column('name', sa.String(), nullable=False),
    sa.Column('nickname', sa.String(), nullable=True),
    sa.Column('age', sa.Integer(), nullable=True),
    sa.Column('gender', sa.String(), nullable=True),
    sa.Column('occupation', sa.String(), nullable=True),
    sa.Column('education', sa.String(), nullable=True),
    sa.Column('location', sa.String(), nullable=True),
    sa.Column('economic_status', sa.String(), nullable=True),
    sa.Column('family_relations', sa.Text(), nullable=True),
    sa.Column('other_info', sa.JSON(), nullable=True),
    sa.Column('tags', sa.JSON(), nullable=True),
    sa.Column('notes', sa.Text(), nullable=True),
    sa.Column('tenant_id', sa.String(), nullable=False),
    sa.Column('counselor_id', sa.UUID(), nullable=False),
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.ForeignKeyConstraint(['counselor_id'], ['counselors.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_clients_code'), 'clients', ['code'], unique=True)
    op.create_index(op.f('ix_clients_tenant_id'), 'clients', ['tenant_id'], unique=False)
    op.create_table('refresh_tokens',
    sa.Column('token', sa.String(), nullable=False),
    sa.Column('counselor_id', sa.UUID(), nullable=False),
    sa.Column('tenant_id', sa.String(), nullable=False),
    sa.Column('expires_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('is_revoked', sa.Boolean(), nullable=True),
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.ForeignKeyConstraint(['counselor_id'], ['counselors.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_refresh_tokens_tenant_id'), 'refresh_tokens', ['tenant_id'], unique=False)
    op.create_index(op.f('ix_refresh_tokens_token'), 'refresh_tokens', ['token'], unique=True)
    op.create_table('document_quality_metrics',
    sa.Column('document_id', sa.Integer(), nullable=False),
    sa.Column('content_accuracy', sa.Float(), nullable=True),
    sa.Column('structural_score', sa.Float(), nullable=True),
    sa.Column('expertise_depth', sa.Float(), nullable=True),
    sa.Column('readability_score', sa.Float(), nullable=True),
    sa.Column('topic_coverage', sa.JSON(), nullable=True),
    sa.Column('knowledge_depth', sa.JSON(), nullable=True),
    sa.Column('evaluated_by', sa.String(length=100), nullable=True),
    sa.Column('evaluation_notes', sa.Text(), nullable=True),
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.ForeignKeyConstraint(['document_id'], ['documents.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # Step 2: Migrate data from users to counselors (if users table exists)
    # Set default tenant_id to 'career' for existing data
    # Use conditional check to avoid error if users table doesn't exist
    connection = op.get_bind()
    if connection.dialect.has_table(connection, 'users'):
        op.execute("""
            INSERT INTO counselors (id, email, username, full_name, hashed_password, tenant_id, role, is_active, created_at, updated_at)
            SELECT id, email, username, full_name, hashed_password, 'career' AS tenant_id, role::text::counselorrole, is_active, created_at, updated_at
            FROM users
        """)

    # Step 3: Migrate data from visitors to clients (if visitors table exists)
    # Note: visitors don't have counselor_id, so we need to handle this differently
    # For now, we'll skip migrating visitors directly - they'll be created through the new flow
    # op.execute("""
    #     INSERT INTO clients (id, code, nickname, age, gender, tags, notes, tenant_id, counselor_id, name, created_at, updated_at)
    #     SELECT id, code, nickname, NULL AS age, gender, tags, notes, 'career' AS tenant_id,
    #            (SELECT id FROM counselors LIMIT 1) AS counselor_id,
    #            COALESCE(nickname, code) AS name, created_at, updated_at
    #     FROM visitors
    #     WHERE EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = 'visitors')
    # """)

    # Step 4: Drop old tables that are no longer needed (in correct order - children first)
    # Drop child tables first
    op.drop_index('idx_expert_case_comments_case_id', table_name='expert_case_comments')
    op.drop_index('idx_expert_case_comments_parent_id', table_name='expert_case_comments')
    op.drop_index('idx_expert_case_comments_user_id', table_name='expert_case_comments')
    op.drop_table('expert_case_comments')

    op.drop_index('idx_expert_case_attachments_case_id', table_name='expert_case_attachments')
    op.drop_table('expert_case_attachments')

    # Now drop parent table
    op.drop_index('idx_expert_cases_case_number', table_name='expert_cases')
    op.drop_index('idx_expert_cases_category', table_name='expert_cases')
    op.drop_index('idx_expert_cases_created_by', table_name='expert_cases')
    op.drop_index('idx_expert_cases_is_published', table_name='expert_cases')
    op.drop_table('expert_cases')

    # Drop other independent tables
    op.drop_index('idx_embeddings_gemini_chunk_id', table_name='embeddings_gemini')
    op.drop_table('embeddings_gemini')

    op.drop_index('idx_case_templates_category', table_name='case_templates')
    op.drop_index('idx_case_templates_created_by', table_name='case_templates')
    op.drop_index('idx_case_templates_is_active', table_name='case_templates')
    op.drop_table('case_templates')
    # Step 5: Modify cases table - add columns with nullable first, then populate, then set not null
    op.add_column('cases', sa.Column('client_id', sa.UUID(), nullable=True))  # Allow NULL temporarily
    op.add_column('cases', sa.Column('tenant_id', sa.String(), nullable=True))  # Allow NULL temporarily

    # Set default tenant_id for existing cases
    op.execute("UPDATE cases SET tenant_id = 'career' WHERE tenant_id IS NULL")

    # Copy visitor_id to client_id temporarily (we'll fix relationships later)
    op.execute("UPDATE cases SET client_id = visitor_id WHERE client_id IS NULL")

    # Now make them non-nullable
    op.alter_column('cases', 'client_id', nullable=False)
    op.alter_column('cases', 'tenant_id', nullable=False)
    op.create_index(op.f('ix_cases_tenant_id'), 'cases', ['tenant_id'], unique=False)
    op.drop_constraint('cases_visitor_id_fkey', 'cases', type_='foreignkey')
    op.drop_constraint('cases_counselor_id_fkey', 'cases', type_='foreignkey')
    op.create_foreign_key(None, 'cases', 'clients', ['client_id'], ['id'])
    op.create_foreign_key(None, 'cases', 'counselors', ['counselor_id'], ['id'])
    op.drop_column('cases', 'visitor_id')
    op.drop_index('idx_chunks_doc_strategy', table_name='chunks')
    op.drop_index('idx_chunks_strategy', table_name='chunks')
    op.create_index(op.f('ix_chunks_chunk_strategy'), 'chunks', ['chunk_strategy'], unique=False)
    op.alter_column('evaluation_results', 'experiment_id',
               existing_type=sa.UUID(),
               nullable=False)
    # Step 6: Modify reports table - add columns
    op.add_column('reports', sa.Column('client_id', sa.UUID(), nullable=True))  # Allow NULL temporarily
    op.add_column('reports', sa.Column('tenant_id', sa.String(), nullable=True))  # Allow NULL temporarily
    op.add_column('reports', sa.Column('mode', sa.String(), nullable=True))
    op.add_column('reports', sa.Column('quality_score', sa.Integer(), nullable=True))
    op.add_column('reports', sa.Column('quality_grade', sa.String(), nullable=True))
    op.add_column('reports', sa.Column('quality_strengths', sa.JSON(), nullable=True))
    op.add_column('reports', sa.Column('quality_weaknesses', sa.JSON(), nullable=True))

    # Set default values for existing reports
    op.execute("UPDATE reports SET tenant_id = 'career' WHERE tenant_id IS NULL")
    # Get client_id from session->case->client relationship
    op.execute("""
        UPDATE reports r
        SET client_id = c.client_id
        FROM sessions s
        JOIN cases c ON s.case_id = c.id
        WHERE r.session_id = s.id AND r.client_id IS NULL
    """)

    # Make them non-nullable
    op.alter_column('reports', 'client_id', nullable=False)
    op.alter_column('reports', 'tenant_id', nullable=False)
    op.create_index(op.f('ix_reports_tenant_id'), 'reports', ['tenant_id'], unique=False)
    op.drop_constraint('reports_created_by_id_fkey', 'reports', type_='foreignkey')
    op.drop_constraint('reports_reviewed_by_id_fkey', 'reports', type_='foreignkey')
    op.create_foreign_key(None, 'reports', 'counselors', ['reviewed_by_id'], ['id'])
    op.create_foreign_key(None, 'reports', 'clients', ['client_id'], ['id'])
    op.create_foreign_key(None, 'reports', 'counselors', ['created_by_id'], ['id'])
    # Step 7: Modify sessions table
    op.add_column('sessions', sa.Column('tenant_id', sa.String(), nullable=True))  # Allow NULL temporarily

    # Set default tenant_id for existing sessions
    op.execute("UPDATE sessions SET tenant_id = 'career' WHERE tenant_id IS NULL")

    # Make it non-nullable
    op.alter_column('sessions', 'tenant_id', nullable=False)
    op.create_index(op.f('ix_sessions_tenant_id'), 'sessions', ['tenant_id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_sessions_tenant_id'), table_name='sessions')
    op.drop_column('sessions', 'tenant_id')
    op.drop_constraint(None, 'reports', type_='foreignkey')
    op.drop_constraint(None, 'reports', type_='foreignkey')
    op.drop_constraint(None, 'reports', type_='foreignkey')
    op.create_foreign_key('reports_reviewed_by_id_fkey', 'reports', 'users', ['reviewed_by_id'], ['id'])
    op.create_foreign_key('reports_created_by_id_fkey', 'reports', 'users', ['created_by_id'], ['id'])
    op.drop_index(op.f('ix_reports_tenant_id'), table_name='reports')
    op.drop_column('reports', 'quality_weaknesses')
    op.drop_column('reports', 'quality_strengths')
    op.drop_column('reports', 'quality_grade')
    op.drop_column('reports', 'quality_score')
    op.drop_column('reports', 'mode')
    op.drop_column('reports', 'tenant_id')
    op.drop_column('reports', 'client_id')
    op.alter_column('evaluation_results', 'experiment_id',
               existing_type=sa.UUID(),
               nullable=True)
    op.drop_index(op.f('ix_chunks_chunk_strategy'), table_name='chunks')
    op.create_index('idx_chunks_strategy', 'chunks', ['chunk_strategy'], unique=False)
    op.create_index('idx_chunks_doc_strategy', 'chunks', ['doc_id', 'chunk_strategy'], unique=False)
    op.add_column('cases', sa.Column('visitor_id', sa.UUID(), autoincrement=False, nullable=False))
    op.drop_constraint(None, 'cases', type_='foreignkey')
    op.drop_constraint(None, 'cases', type_='foreignkey')
    op.create_foreign_key('cases_counselor_id_fkey', 'cases', 'users', ['counselor_id'], ['id'])
    op.create_foreign_key('cases_visitor_id_fkey', 'cases', 'visitors', ['visitor_id'], ['id'])
    op.drop_index(op.f('ix_cases_tenant_id'), table_name='cases')
    op.drop_column('cases', 'tenant_id')
    op.drop_column('cases', 'client_id')
    op.create_table('expert_case_comments',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('expert_case_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('parent_comment_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('content', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('is_expert_insight', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['expert_case_id'], ['expert_cases.id'], name='expert_case_comments_expert_case_id_fkey', ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['parent_comment_id'], ['expert_case_comments.id'], name='expert_case_comments_parent_comment_id_fkey', ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name='expert_case_comments_user_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='expert_case_comments_pkey')
    )
    op.create_index('idx_expert_case_comments_user_id', 'expert_case_comments', ['user_id'], unique=False)
    op.create_index('idx_expert_case_comments_parent_id', 'expert_case_comments', ['parent_comment_id'], unique=False)
    op.create_index('idx_expert_case_comments_case_id', 'expert_case_comments', ['expert_case_id'], unique=False)
    op.create_table('case_templates',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('name', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('description', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('category', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('template_schema', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('is_active', sa.BOOLEAN(), server_default=sa.text('true'), autoincrement=False, nullable=False),
    sa.Column('created_by', sa.UUID(), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['created_by'], ['users.id'], name='case_templates_created_by_fkey'),
    sa.PrimaryKeyConstraint('id', name='case_templates_pkey')
    )
    op.create_index('idx_case_templates_is_active', 'case_templates', ['is_active'], unique=False)
    op.create_index('idx_case_templates_created_by', 'case_templates', ['created_by'], unique=False)
    op.create_index('idx_case_templates_category', 'case_templates', ['category'], unique=False)
    op.create_table('expert_case_attachments',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('expert_case_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('filename', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('file_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('file_url', sa.VARCHAR(length=512), autoincrement=False, nullable=False),
    sa.Column('file_size', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('description', sa.TEXT(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['expert_case_id'], ['expert_cases.id'], name='expert_case_attachments_expert_case_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='expert_case_attachments_pkey')
    )
    op.create_index('idx_expert_case_attachments_case_id', 'expert_case_attachments', ['expert_case_id'], unique=False)
    op.create_table('embeddings_gemini',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('chunk_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('embedding', pgvector.sqlalchemy.vector.VECTOR(dim=768), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['chunk_id'], ['chunks.id'], name='embeddings_gemini_chunk_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='embeddings_gemini_pkey'),
    sa.UniqueConstraint('chunk_id', name='embeddings_gemini_chunk_id_key'),
    comment='Gemini text-embedding-004 vectors for comparison with OpenAI embeddings'
    )
    op.create_index('idx_embeddings_gemini_chunk_id', 'embeddings_gemini', ['chunk_id'], unique=False)
    op.create_table('expert_cases',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('title', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('case_number', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('category', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('difficulty', sa.VARCHAR(length=20), server_default=sa.text("'beginner'::character varying"), autoincrement=False, nullable=False),
    sa.Column('tags', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('background', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('presenting_issue', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('assessment', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('intervention', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('outcome', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('key_learnings', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('client_profile', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('session_count', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('duration_weeks', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('created_by', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('expert_notes', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('is_published', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=False),
    sa.Column('is_featured', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=False),
    sa.Column('view_count', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False),
    sa.Column('teaching_points', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('discussion_questions', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('reference_materials', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['created_by'], ['users.id'], name='expert_cases_created_by_fkey'),
    sa.PrimaryKeyConstraint('id', name='expert_cases_pkey'),
    sa.UniqueConstraint('case_number', name='expert_cases_case_number_key')
    )
    op.create_index('idx_expert_cases_is_published', 'expert_cases', ['is_published'], unique=False)
    op.create_index('idx_expert_cases_created_by', 'expert_cases', ['created_by'], unique=False)
    op.create_index('idx_expert_cases_category', 'expert_cases', ['category'], unique=False)
    op.create_index('idx_expert_cases_case_number', 'expert_cases', ['case_number'], unique=False)
    op.drop_table('document_quality_metrics')
    op.drop_index(op.f('ix_refresh_tokens_token'), table_name='refresh_tokens')
    op.drop_index(op.f('ix_refresh_tokens_tenant_id'), table_name='refresh_tokens')
    op.drop_table('refresh_tokens')
    op.drop_index(op.f('ix_clients_tenant_id'), table_name='clients')
    op.drop_index(op.f('ix_clients_code'), table_name='clients')
    op.drop_table('clients')
    op.drop_index(op.f('ix_counselors_username'), table_name='counselors')
    op.drop_index(op.f('ix_counselors_tenant_id'), table_name='counselors')
    op.drop_index(op.f('ix_counselors_email'), table_name='counselors')
    op.drop_table('counselors')
    # ### end Alembic commands ###
