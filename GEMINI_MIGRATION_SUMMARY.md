# Gemini é·ç§»å®Œæˆæ‘˜è¦

**é·ç§»æ—¥æœŸ**: 2025-11-25
**ç‹€æ…‹**: âœ… å®Œæˆ Phase 1 + Phase 2

---

## ğŸ“‹ è®Šæ›´æ‘˜è¦

### âœ… å·²å®Œæˆçš„è®Šæ›´

#### 1. **åŸºç¤è¨­æ–½æº–å‚™**
- âœ… `app/core/config.py` - æ·»åŠ  Gemini é…ç½®
  - `GEMINI_PROJECT_ID`, `GEMINI_LOCATION`, `GEMINI_CHAT_MODEL`
  - `DEFAULT_LLM_PROVIDER` = `"gemini"` (é è¨­)

- âœ… `app/services/gemini_service.py` - æ“´å±•åŠŸèƒ½
  - æ”¯æ´ `chat_completion_with_messages()` (OpenAI æ ¼å¼)
  - æ”¯æ´ `response_format={"type": "json_object"}` (JSON mode)
  - æ”¯æ´ `model_name` åƒæ•¸ï¼ˆå¯åˆ‡æ›æ¨¡å‹ï¼‰

#### 2. **æœå‹™é·ç§»ï¼ˆé›™ Provider æ”¯æ´ï¼‰**
æ‰€æœ‰æœå‹™éƒ½æ”¯æ´ `provider` åƒæ•¸ï¼š`"openai"` æˆ– `"gemini"`

- âœ… `app/services/session_summary_service.py`
  - æ–°å¢ `provider` åƒæ•¸
  - é è¨­ä½¿ç”¨ Gemini (å¾ `settings.DEFAULT_LLM_PROVIDER`)
  - Gemini å¤±æ•—è‡ªå‹• fallback åˆ° OpenAI

- âœ… `app/services/report_service.py`
  - æ–°å¢ `provider` åƒæ•¸
  - æ‰€æœ‰æ–¹æ³•æ”¯æ´é›™ providerï¼š
    - `_parse_transcript_info()` - è§£æé€å­—ç¨¿
    - `_generate_structured_report()` - ç”Ÿæˆå ±å‘Š
    - `_extract_key_dialogues()` - æå–å°è©±

- âœ… `app/utils/report_grader.py`
  - æ–°å¢ `provider` åƒæ•¸
  - é è¨­ä½¿ç”¨ Gemini (çœ 94% æˆæœ¬)
  - OpenAI ä¿ç•™ç‚ºå‚™ç”¨ï¼ˆä½¿ç”¨ gpt-4oï¼‰

- âœ… `app/api/rag_report.py`
  - é è¨­ `rag_system="gemini"` (åŸç‚º `"openai"`)

#### 3. **ç’°å¢ƒè®Šæ•¸æ›´æ–°**
- âœ… `.env.example` - æ·»åŠ  Gemini é…ç½®èªªæ˜

---

## ğŸ“‚ æª”æ¡ˆè®Šæ›´æ¸…å–®

```
app/core/config.py                          # æ–°å¢ Gemini é…ç½®
app/services/gemini_service.py              # æ“´å±•åŠŸèƒ½
app/services/session_summary_service.py     # æ”¯æ´é›™ provider
app/services/report_service.py              # æ”¯æ´é›™ provider
app/utils/report_grader.py                  # æ”¯æ´é›™ provider
app/api/rag_report.py                       # é è¨­æ”¹ç‚º Gemini
.env.example                                # æ›´æ–°ç’°å¢ƒè®Šæ•¸èªªæ˜
```

---

## ğŸ”§ ç’°å¢ƒè®Šæ•¸è¨­ç½®

### æ–°å¢çš„ç’°å¢ƒè®Šæ•¸

```bash
# Gemini / Vertex AI (ä¸»è¦ LLM)
GEMINI_PROJECT_ID=groovy-iris-473015-h3
GEMINI_LOCATION=us-central1
GEMINI_CHAT_MODEL=gemini-2.5-flash

# LLM Provider Selection (é è¨­ä½¿ç”¨ Gemini)
DEFAULT_LLM_PROVIDER=gemini  # "openai" or "gemini"
```

### ä¿ç•™çš„ OpenAI è¨­ç½®
```bash
# OpenAI (ç”¨æ–¼ Embeddings, Whisper STT, RAG Chat)
OPENAI_API_KEY=sk-xxx
```

---

## âœ… ä¿ç•™ OpenAI çš„åŠŸèƒ½ï¼ˆæœªè®Šæ›´ï¼‰

1. **Whisper STT** (`app/services/stt_service.py`)
   - èªéŸ³è½‰æ–‡å­—
   - ç„¡éœ€è®Šæ›´

2. **Text Embeddings** (`app/services/openai_service.py`)
   - `create_embedding()`
   - `create_embeddings_batch()`
   - RAG å‘é‡æœå°‹

3. **RAG Chat** (`app/services/openai_service.py`)
   - `chat_completion_with_context()`
   - èˆ‡ç¾æœ‰ embeddings é…åˆä½¿ç”¨

---

## ğŸ¯ é è¨­è¡Œç‚ºè®Šæ›´

### è®Šæ›´å‰ (OpenAI)
```python
# æ‰€æœ‰æœå‹™éƒ½ä½¿ç”¨ OpenAI
SessionSummaryService()  # â†’ gpt-4o-mini
ReportGenerationService()  # â†’ gpt-4o-mini
grade_report_with_llm()  # â†’ gpt-4o
rag_report.py: rag_system="openai"  # â†’ gpt-4o-mini
```

### è®Šæ›´å¾Œ (Gemini é è¨­)
```python
# æ‰€æœ‰æœå‹™é è¨­ä½¿ç”¨ Gemini
SessionSummaryService()  # â†’ gemini-2.5-flash
ReportGenerationService()  # â†’ gemini-2.5-flash
grade_report_with_llm()  # â†’ gemini-2.5-flash
rag_report.py: rag_system="gemini"  # â†’ gemini-2.5-flash
```

### å¦‚ä½•åˆ‡æ›å› OpenAI
```python
# æ–¹æ³• 1: ç’°å¢ƒè®Šæ•¸
DEFAULT_LLM_PROVIDER=openai

# æ–¹æ³• 2: åˆå§‹åŒ–æ™‚æŒ‡å®š
SessionSummaryService(provider="openai")
ReportGenerationService(provider="openai")
grade_report_with_llm(provider="openai")

# æ–¹æ³• 3: API åƒæ•¸
POST /api/report/generate
{
  "rag_system": "openai"
}
```

---

## ğŸ’° æˆæœ¬å½±éŸ¿

### è®Šæ›´å‰ï¼ˆå…¨ OpenAIï¼‰
- æœƒè«‡æ‘˜è¦: `gpt-4o-mini` ($0.15/$0.60)
- å ±å‘Šç”Ÿæˆ: `gpt-4o-mini` ($0.15/$0.60)
- å ±å‘Šè©•åˆ†: `gpt-4o` ($2.50/$10.00) âš ï¸ æœ€è²´
- RAG å ±å‘Š: `gpt-4o-mini` ($0.15/$0.60)

### è®Šæ›´å¾Œï¼ˆé è¨­ Geminiï¼‰
- æœƒè«‡æ‘˜è¦: `gemini-2.5-flash` ($0.15/$0.60) - åŒåƒ¹
- å ±å‘Šç”Ÿæˆ: `gemini-2.5-flash` ($0.15/$0.60) - åŒåƒ¹
- å ±å‘Šè©•åˆ†: `gemini-2.5-flash` ($0.15/$0.60) - **çœ 94%** ğŸ‰
- RAG å ±å‘Š: `gemini-2.5-flash` ($0.15/$0.60) - åŒåƒ¹

**çµè«–**: å ±å‘Šè©•åˆ†çœ 94% æˆæœ¬ï¼Œå…¶ä»–åŠŸèƒ½åŒåƒ¹ä½†å¯èƒ½æ€§èƒ½æ›´å¥½

---

## ğŸ§ª æ¸¬è©¦å»ºè­°

### 1. å–®å…ƒæ¸¬è©¦
```bash
# ç¢ºä¿ç¾æœ‰æ¸¬è©¦é€šé
poetry run pytest tests/unit/ -v
```

### 2. Integration Tests
```bash
# æ¸¬è©¦ RAG å ±å‘Šç”Ÿæˆ
poetry run pytest tests/integration/test_reports_api.py -v

# æ¸¬è©¦æ‰€æœ‰ integration tests
poetry run pytest tests/integration/ -v
```

### 3. æ‰‹å‹•æ¸¬è©¦
```bash
# æ¸¬è©¦ Gemini å ±å‘Šç”Ÿæˆ
curl -X POST http://localhost:8000/api/report/generate \
  -H "Content-Type: application/json" \
  -d '{
    "transcript": "...",
    "rag_system": "gemini"
  }'

# æ¸¬è©¦ OpenAI å ±å‘Šç”Ÿæˆï¼ˆfallbackï¼‰
curl -X POST http://localhost:8000/api/report/generate \
  -H "Content-Type: application/json" \
  -d '{
    "transcript": "...",
    "rag_system": "openai"
  }'
```

### 4. å“è³ªé©—è­‰
- [ ] æŠ½æ¨£ 20 ä»½æœƒè«‡æ‘˜è¦æ¯”è¼ƒ Gemini vs OpenAI
- [ ] æŠ½æ¨£ 20 ä»½å ±å‘Šæ¯”è¼ƒå“è³ª
- [ ] é©—è­‰å ±å‘Šè©•åˆ†ä¸€è‡´æ€§ï¼ˆ50 ä»½æ­·å²å ±å‘Šï¼‰

---

## ğŸš€ éƒ¨ç½²æ­¥é©Ÿ

### Staging ç’°å¢ƒ

1. **æ›´æ–°ç’°å¢ƒè®Šæ•¸**
```bash
# æ·»åŠ åˆ° .env
GEMINI_PROJECT_ID=groovy-iris-473015-h3
GEMINI_LOCATION=us-central1
GEMINI_CHAT_MODEL=gemini-2.5-flash
DEFAULT_LLM_PROVIDER=gemini
```

2. **é‡å•Ÿæœå‹™**
```bash
# Docker
docker-compose restart

# Cloud Run (æœƒè‡ªå‹•é‡æ–°éƒ¨ç½²)
git push origin staging
```

3. **é©—è­‰ Gemini å¯ç”¨**
```bash
# æª¢æŸ¥ logs
tail -f logs/app.log | grep -i gemini

# æ¸¬è©¦ API
curl http://staging-url/api/report/generate \
  -d '{"transcript": "test", "rag_system": "gemini"}'
```

### Production ç’°å¢ƒï¼ˆæ¼¸é€²å¼åˆ‡æ›ï¼‰

**Week 1: 10% æµé‡**
```bash
# ä¿æŒé è¨­ OpenAIï¼Œæ‰‹å‹•æ¸¬è©¦ Gemini
DEFAULT_LLM_PROVIDER=openai
```

**Week 2: 50% æµé‡**
```bash
# åˆ‡æ›é è¨­ç‚º Gemini
DEFAULT_LLM_PROVIDER=gemini
```

**Week 3: 100% æµé‡**
```bash
# å…¨é¢ä½¿ç”¨ Gemini
DEFAULT_LLM_PROVIDER=gemini
# OpenAI åƒ…ç”¨æ–¼ Embeddings + Whisper
```

---

## ğŸ”„ å›æ»¾è¨ˆç•«

### ç·Šæ€¥å›æ»¾ï¼ˆå¦‚æœ Gemini å‡ºç¾å•é¡Œï¼‰

**æ–¹æ³• 1: ç’°å¢ƒè®Šæ•¸**
```bash
# æ”¹è®Šç’°å¢ƒè®Šæ•¸ï¼Œé‡å•Ÿæœå‹™
DEFAULT_LLM_PROVIDER=openai
```

**æ–¹æ³• 2: API å±¤ç´š**
```python
# app/api/rag_report.py
rag_system: str = "openai"  # æ”¹å›é è¨­ OpenAI
```

**æ–¹æ³• 3: ç¨‹å¼ç¢¼ç†±ä¿®å¾©**
```python
# app/core/config.py
DEFAULT_LLM_PROVIDER: str = "openai"
```

---

## ğŸ“Š ç›£æ§æŒ‡æ¨™

### éœ€è¦ç›£æ§çš„æŒ‡æ¨™

1. **API å»¶é²**
   - Gemini vs OpenAI å›æ‡‰æ™‚é–“
   - ç›®æ¨™: < 5 ç§’ (å ±å‘Šç”Ÿæˆ)

2. **éŒ¯èª¤ç‡**
   - Gemini API éŒ¯èª¤ç‡
   - Fallback åˆ° OpenAI çš„é »ç‡

3. **æˆæœ¬**
   - Vertex AI (Gemini) æœˆè²»ç”¨
   - OpenAI æœˆè²»ç”¨æ¯”è¼ƒ

4. **å“è³ª**
   - å ±å‘Šè©•åˆ†åˆ†ä½ˆï¼ˆäººå·¥æŠ½æŸ¥ï¼‰
   - ä½¿ç”¨è€…å›é¥‹

### ç›£æ§å·¥å…·
```bash
# GCP Billing
gcloud billing accounts list

# Application Logs
tail -f logs/app.log | grep -E "(gemini|openai|error)"

# API å¥åº·æª¢æŸ¥
curl http://localhost:8000/health
```

---

## ğŸ‰ å®Œæˆç‹€æ…‹

âœ… Phase 1: åŸºç¤è¨­æ–½æº–å‚™
âœ… Phase 2: æœå‹™é·ç§»
âœ… ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥ (ruff check)
â¸ï¸ Phase 3: æ¸¬è©¦èˆ‡é©—è­‰ (å¾…åŸ·è¡Œ)
â¸ï¸ Phase 4: éƒ¨ç½² (å¾…åŸ·è¡Œ)

---

## ğŸ“ å¾ŒçºŒæ­¥é©Ÿ

1. **æ¸¬è©¦é©—è­‰** (é è¨ˆ 2-3 å¤©)
   - [ ] åŸ·è¡Œ integration tests
   - [ ] å“è³ªæ¯”è¼ƒ (Gemini vs OpenAI)
   - [ ] æˆæœ¬ç›£æ§è¨­ç½®

2. **Staging éƒ¨ç½²** (é è¨ˆ 1-2 å¤©)
   - [ ] éƒ¨ç½²åˆ° Staging
   - [ ] æ‰‹å‹•æ¸¬è©¦æ‰€æœ‰åŠŸèƒ½
   - [ ] é©—è­‰ Gemini fallback æ©Ÿåˆ¶

3. **Production æ¼¸é€²å¼åˆ‡æ›** (é è¨ˆ 2-3 é€±)
   - [ ] Week 1: 10% æµé‡æ¸¬è©¦
   - [ ] Week 2: 50% æµé‡æ¸¬è©¦
   - [ ] Week 3: 100% åˆ‡æ›å®Œæˆ

---

## ğŸ”— ç›¸é—œæ–‡æª”

- [COST_ANALYSIS.md](./COST_ANALYSIS.md) - æˆæœ¬åˆ†æ
- [GEMINI_MIGRATION_PLAN.md](./GEMINI_MIGRATION_PLAN.md) - è©³ç´°é·ç§»è¨ˆç•«
- [CLAUDE.md](./CLAUDE.md) - é–‹ç™¼ç­–ç•¥

---

**é·ç§»å®Œæˆ**ï¼Gemini ç¾ç‚ºé è¨­ LLMï¼ŒOpenAI ä¿ç•™ç”¨æ–¼ Embeddings/Whisper/RAGã€‚
