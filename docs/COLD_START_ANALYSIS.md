# Staging ç’°å¢ƒ Cold Start å»¶é²åˆ†æ

## ğŸ“Š æ¸¬è©¦çµæœ

### æ¸¬è©¦ç’°å¢ƒ
- **æœå‹™**: `career-app-api-staging`
- **URL**: `https://career-app-api-staging-kxaznpplqq-uc.a.run.app`
- **æ¸¬è©¦æ™‚é–“**: 2025-11-10
- **éƒ¨ç½²ç‰ˆæœ¬**: `7e71bc1`

---

## â±ï¸ API å›æ‡‰æ™‚é–“

### 1. Login API (POST /api/auth/login)
```
Request 1: 200 - 2.468s
Request 2: 200 - 2.702s
Request 3: 200 - 2.669s

å¹³å‡: ~2.6 ç§’
```

### 2. Get Reports API (GET /api/v1/reports)
```
Request 1: 200 - 3.104s
Request 2: 200 - 2.421s
Request 3: 200 - 2.757s

å¹³å‡: ~2.8 ç§’
```

---

## ğŸ”§ Cloud Run é…ç½® (ci.yml:161-163)

```yaml
--min-instances=0     # âš ï¸ é—œéµï¼šæ²’æœ‰æµé‡æ™‚ç¸®æ¸›åˆ° 0
--max-instances=1     # æœ€å¤š 1 å€‹å¯¦ä¾‹
--memory=1Gi          # è¨˜æ†¶é«” 1GB
--cpu=1               # 1 å€‹ CPU
--timeout=300         # è¶…æ™‚ 5 åˆ†é˜
--concurrency=1000    # æ¯å€‹å¯¦ä¾‹å¯è™•ç† 1000 å€‹ä¸¦ç™¼è«‹æ±‚
--cpu-throttling      # CPU throttling å•Ÿç”¨
```

---

## ğŸŒ Cold Start å•é¡Œåˆ†æ

### ä»€éº¼æ˜¯ Cold Startï¼Ÿ

ç•¶ `min-instances=0` æ™‚ï¼š
- **æ²’æœ‰æµé‡** â†’ Cloud Run ç¸®æ¸›åˆ° 0 å€‹å¯¦ä¾‹ï¼ˆçœéŒ¢ï¼‰
- **ç¬¬ä¸€å€‹è«‹æ±‚é€²ä¾†** â†’ éœ€è¦å•Ÿå‹•æ–°å®¹å™¨
- **Cold Start å»¶é²** = å®¹å™¨å•Ÿå‹•æ™‚é–“ + Python è¼‰å…¥æ™‚é–“ + FastAPI åˆå§‹åŒ–

### Cold Start æ™‚é–“çµ„æˆ

```
ç¸½ Cold Start æ™‚é–“ (~5-10 ç§’)
â”œâ”€â”€ å®¹å™¨å•Ÿå‹• (~2-3 ç§’)
â”‚   â”œâ”€â”€ æ‹‰å– Docker image
â”‚   â”œâ”€â”€ å•Ÿå‹•å®¹å™¨
â”‚   â””â”€â”€ ç¶²è·¯é…ç½®
â”œâ”€â”€ Python ç’°å¢ƒè¼‰å…¥ (~1-2 ç§’)
â”‚   â”œâ”€â”€ Python runtime
â”‚   â”œâ”€â”€ è¼‰å…¥ä¾è³´ (FastAPI, SQLAlchemy, etc.)
â”‚   â””â”€â”€ åˆå§‹åŒ–æ‡‰ç”¨
â””â”€â”€ è³‡æ–™åº«é€£æ¥ (~1-2 ç§’)
    â”œâ”€â”€ å»ºç«‹ connection pool
    â””â”€â”€ ç¬¬ä¸€æ¬¡æŸ¥è©¢
```

### ç•¶å‰è§€å¯Ÿ

**âŒ å•é¡Œ**ï¼š
- Login API: **2.6 ç§’** (ç†æƒ³æ‡‰è©² < 500ms)
- Get Reports: **2.8 ç§’** (ç†æƒ³æ‡‰è©² < 1s)
- é€™äº›æ™‚é–“**åŒ…å«** warm instance çš„æ™‚é–“
- å¦‚æœæ˜¯ cold startï¼Œå¯èƒ½éœ€è¦ **5-10 ç§’**

**âœ… å¥½æ¶ˆæ¯**ï¼š
- æœå‹™ç©©å®šé‹è¡Œ
- æ²’æœ‰ timeout å•é¡Œ
- å¾ŒçºŒè«‹æ±‚æœƒå¿«å¾ˆå¤š (warm instance)

---

## ğŸ’¡ å„ªåŒ–å»ºè­°

### é¸é … 1: è¨­å®š min-instances=1 (æ¨è–¦ç”¨æ–¼ production)

**å„ªé»**ï¼š
- âœ… æ¶ˆé™¤ cold start å»¶é²
- âœ… ç¬¬ä¸€å€‹è«‹æ±‚ä¹Ÿå¾ˆå¿« (~500ms)
- âœ… ä½¿ç”¨è€…é«”é©—æ›´å¥½

**ç¼ºé»**ï¼š
- âŒ æˆæœ¬å¢åŠ ï¼ˆ24/7 é‹è¡Œä¸€å€‹å¯¦ä¾‹ï¼‰
- âŒ Staging å¯èƒ½ä¸éœ€è¦

**ä¿®æ”¹æ–¹å¼**ï¼š
```yaml
# .github/workflows/ci.yml:161
--min-instances=1  # æ”¹ç‚º 1
```

**æˆæœ¬ä¼°ç®—**ï¼š
- 1 å€‹å¯¦ä¾‹ (1 vCPU, 1GB RAM)
- ç´„ $50-60/æœˆ (è¦–ä½¿ç”¨é‡)

---

### é¸é … 2: ä½¿ç”¨ Cloud Run v2 + Startup CPU Boost

**å„ªé»**ï¼š
- âœ… Cold start æ™‚ CPU åŠ å€
- âœ… åŠ å¿«å•Ÿå‹•é€Ÿåº¦
- âœ… min-instances=0 æ™‚ä»æœ‰æ•ˆ

**ä¿®æ”¹æ–¹å¼**ï¼š
```yaml
gcloud run services update career-app-api-staging \
  --execution-environment=gen2 \
  --cpu-boost
```

---

### é¸é … 3: å„ªåŒ– Docker Image

**ç•¶å‰ image å¯èƒ½çš„å•é¡Œ**ï¼š
- å¤ªå¤šä¾è³´
- æ²’æœ‰ä½¿ç”¨ multi-stage build
- æ²’æœ‰å¿«å– Python packages

**å„ªåŒ–æ­¥é©Ÿ**ï¼š

1. **ä½¿ç”¨ slim Python image**
```dockerfile
FROM python:3.11-slim  # ä¸æ˜¯ python:3.11
```

2. **Multi-stage build**
```dockerfile
# Build stage
FROM python:3.11 as builder
RUN pip install poetry
COPY pyproject.toml poetry.lock ./
RUN poetry export -f requirements.txt > requirements.txt

# Runtime stage
FROM python:3.11-slim
COPY --from=builder requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY app/ ./app/
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8080"]
```

3. **ç§»é™¤ä¸å¿…è¦çš„ä¾è³´**
```bash
# æª¢æŸ¥å“ªäº› package çœŸçš„éœ€è¦
poetry show --tree
```

---

### é¸é … 4: Lazy Loading

**å»¶é²è¼‰å…¥ä¸å¸¸ç”¨çš„æ¨¡çµ„**ï¼š

```python
# app/main.py
from fastapi import FastAPI

app = FastAPI()

# âŒ ä¸è¦åœ¨å•Ÿå‹•æ™‚è¼‰å…¥æ‰€æœ‰ service
# from app.services.openai_service import OpenAIService

@app.get("/api/v1/reports")
def get_reports():
    # âœ… åªåœ¨çœŸæ­£éœ€è¦æ™‚è¼‰å…¥
    from app.services.openai_service import OpenAIService
    ...
```

---

### é¸é … 5: é ç†±è«‹æ±‚ (Warm-up Request)

**ä½¿ç”¨ Cloud Scheduler å®šæœŸç™¼é€è«‹æ±‚**ï¼š

```bash
# æ¯ 5 åˆ†é˜ç™¼é€ä¸€æ¬¡ health check
gcloud scheduler jobs create http staging-warmup \
  --schedule="*/5 * * * *" \
  --uri="https://career-app-api-staging.../health" \
  --http-method=GET
```

**æˆæœ¬**ï¼šå¹¾ä¹å…è²»

---

## ğŸ“ˆ å»ºè­°çš„æ”¹é€²è¨ˆç•«

### Staging ç’°å¢ƒ (ç•¶å‰)
```yaml
min-instances: 0        # ä¿æŒç‚º 0ï¼ˆçœéŒ¢ï¼‰
optimization:
  - å„ªåŒ– Docker image   # æ¸›å°‘å•Ÿå‹•æ™‚é–“
  - ä½¿ç”¨ CPU boost      # Cloud Run v2
  - Lazy loading        # å»¶é²è¼‰å…¥
```

**é æœŸæ”¹å–„**ï¼šCold start å¾ ~8s â†’ ~3-4s

---

### Production ç’°å¢ƒ (æœªä¾†)
```yaml
min-instances: 1        # è¨­ç‚º 1ï¼ˆæ¶ˆé™¤ cold startï¼‰
max-instances: 10       # å¢åŠ åˆ° 10ï¼ˆæ‡‰å°é«˜æµé‡ï¼‰
cpu: 2                  # 2 vCPU
memory: 2Gi             # 2GB RAM
```

**é æœŸæ•ˆæœ**ï¼š
- ç¬¬ä¸€å€‹è«‹æ±‚ï¼š~500ms
- å¾ŒçºŒè«‹æ±‚ï¼š~200-300ms

---

## ğŸ¯ ç«‹å³å¯åšçš„æ”¹é€²

1. **æª¢æŸ¥ Docker image å¤§å°**
   ```bash
   docker images | grep career-app
   ```

2. **Profile å•Ÿå‹•æ™‚é–“**
   ```python
   # app/main.py
   import time
   start = time.time()

   # ... æ‡‰ç”¨åˆå§‹åŒ– ...

   print(f"App startup time: {time.time() - start:.2f}s")
   ```

3. **ç§»é™¤ä¸å¿…è¦çš„ä¾è³´**
   ```bash
   poetry show | wc -l  # æª¢æŸ¥æœ‰å¤šå°‘ä¾è³´
   ```

---

## ğŸ“š ç›¸é—œè³‡æº

- [Cloud Run Cold Start æœ€ä½³å¯¦è¸](https://cloud.google.com/run/docs/tips/general#optimize_cold_start_time)
- [FastAPI Performance Tips](https://fastapi.tiangolo.com/deployment/concepts/)
- [Container Optimization](https://cloud.google.com/run/docs/tips/general#container)

---

## ğŸ” ç›£æ§å»ºè­°

å®šæœŸæª¢æŸ¥ Cloud Run metricsï¼š
- Cold start frequency
- Request latency (P50, P95, P99)
- Instance count
- CPU / Memory usage

**æŒ‡ä»¤**ï¼š
```bash
gcloud run services describe career-app-api-staging \
  --region=us-central1 \
  --format="table(status.url, status.latestReadyRevision)"
```
