# Parents Report Prompt Refinement - Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Refine Parents Report prompt to balance professional authority with accessibilityâ€”use RAG-retrieved theories but translate them into life-like language without overwhelming readers with academic jargon.

**Architecture:** Single-file Prompt modification in `app/services/analysis/parents_report_service.py`. No schema changes, no API changes, no iOS changes. Pure prompt engineering with automated A/B testing validation.

**Tech Stack:** Python 3.11, Gemini Flash, existing RAG system

**Success Criteria:**
- Prompt still uses RAG (retrieves parenting theories)
- Output avoids excessive academic terminology (no "Gottmanæƒ…ç·’æ•™ç·´æ™‚åˆ»", "å†°å±±ç†è«–", "æ­¸å±¬æ„Ÿ")
- Maintains professional credibility with strategic use of simplified terms
- A/B test shows improved readability without losing depth

---

## Task 1: Create A/B Testing Script

**Files:**
- Create: `scripts/test_parents_report_ab.py`

### Step 1: Write the A/B testing script

Create a script that:
1. Uses a sample 10-minute parent-child transcript
2. Generates report with OLD prompt
3. Generates report with NEW prompt (to be defined)
4. Compares outputs for academic terminology frequency
5. Outputs side-by-side comparison

**Code:**

```python
#!/usr/bin/env python3
"""
A/B Testing script for Parents Report Prompt Refinement

Compares OLD (academic) vs NEW (accessible) prompt outputs.
"""

import asyncio
import json
import re
from typing import Dict, List

# Sample transcript (10-minute parent-child dialogue)
SAMPLE_TRANSCRIPT = """
åª½åª½ï¼šå¯¶è²ï¼ŒåŠŸèª²å¯«å®Œäº†å—ï¼Ÿéƒ½å¿«å…«é»äº†ã€‚
å­©å­ï¼šé‚„æ²’...æˆ‘ä¸æƒ³å¯«ã€‚
åª½åª½ï¼šä¸æƒ³å¯«ä¹Ÿè¦å¯«å•Šï¼ä½ çœ‹ä½ åŒå­¸éƒ½å¯«å®Œäº†ã€‚
å­©å­ï¼šæˆ‘å°±æ˜¯ä¸æƒ³å¯«å˜›ï¼
åª½åª½ï¼šä½ é€™æ˜¯ä»€éº¼æ…‹åº¦ï¼ŸåŠŸèª²æ˜¯ä½ è‡ªå·±çš„äº‹ï¼Œä¸å¯«ä»¥å¾Œæ€éº¼è¾¦ï¼Ÿ
å­©å­ï¼šæˆ‘ä¸ç®¡ï¼æˆ‘å°±æ˜¯ä¸æƒ³å¯«ï¼
åª½åª½ï¼šï¼ˆç”Ÿæ°£ï¼‰ä½ å†é€™æ¨£æˆ‘å°±ä¸è®“ä½ çœ‹é›»è¦–äº†ï¼
å­©å­ï¼šï¼ˆå“­ï¼‰æˆ‘è¨å­ä½ ï¼ä½ éƒ½ä¸äº†è§£æˆ‘ï¼
åª½åª½ï¼šæˆ‘ä¸äº†è§£ä½ ï¼Ÿæˆ‘æ¯å¤©é€™éº¼è¾›è‹¦é‚„ä¸æ˜¯ç‚ºäº†ä½ å¥½ï¼Ÿ
å­©å­ï¼šï¼ˆç¹¼çºŒå“­ï¼‰æˆ‘å£“åŠ›å¥½å¤§...
åª½åª½ï¼šå£“åŠ›å¤§å°±ä¸ç”¨å¯«åŠŸèª²äº†å—ï¼Ÿä½ çœ‹äººå®¶åˆ¥çš„å°å­©...
å­©å­ï¼šä½ ç‚ºä»€éº¼è¦ä¸€ç›´æ‹¿æˆ‘è·Ÿåˆ¥äººæ¯”ï¼Ÿæˆ‘å°±æ˜¯æˆ‘ï¼
åª½åª½ï¼šæˆ‘é€™æ˜¯åœ¨æ¿€å‹µä½ å•Šï¼ä½ è¦åŠªåŠ›ä¸€é»ã€‚
å­©å­ï¼šå¯æ˜¯æˆ‘çœŸçš„å¾ˆç´¯...ä»Šå¤©è€ƒè©¦è€ƒä¸å¥½ï¼Œè€å¸«é‚„ç½µæˆ‘...
åª½åª½ï¼šè€ƒä¸å¥½å°±è¦æ›´èªçœŸå•Šï¼ä½ çœ‹ä½ é€™æ¬¡æ•¸å­¸åˆéŒ¯é‚£éº¼å¤šã€‚
å­©å­ï¼šï¼ˆå°è²ï¼‰æˆ‘å·²ç¶“å¾ˆåŠªåŠ›äº†...
åª½åª½ï¼šåŠªåŠ›å“ªå¤ ï¼Ÿä½ è¦æ›´åŠªåŠ›æ‰è¡Œï¼ä¾†ï¼Œå¿«é»å»å¯«åŠŸèª²ã€‚
å­©å­ï¼šï¼ˆæ²‰é»˜ï¼Œæ…¢æ…¢èµ°é–‹ï¼‰
åª½åª½ï¼šï¼ˆå˜†æ°£ï¼‰é€™å­©å­...æ€éº¼é€™éº¼ä¸æ‡‚äº‹...
"""

# Academic terminology to detect
ACADEMIC_TERMS = [
    "Gottman", "é˜¿å¾·å‹’", "è–©æçˆ¾", "Adler", "Satir",
    "å†°å±±ç†è«–", "å†°å±±ä¸‹", "æƒ…ç·’æ•™ç·´", "æ­¸å±¬æ„Ÿ", "åƒ¹å€¼æ„Ÿ",
    "é»ƒé‡‘æ™‚åˆ»", "æƒ…ç·’æ™ºå•†", "æ¬ŠåŠ›é¬¥çˆ­", "å’Œå–„è€Œå …å®š",
    "ç†è«–", "å­¸æ´¾", "ç ”ç©¶æŒ‡å‡º", "å°ˆå®¶èªç‚º"
]


def count_academic_terms(text: str) -> Dict[str, int]:
    """Count frequency of academic terminology in text"""
    counts = {}
    for term in ACADEMIC_TERMS:
        count = len(re.findall(term, text, re.IGNORECASE))
        if count > 0:
            counts[term] = count
    return counts


def calculate_readability_score(text: str) -> Dict[str, any]:
    """Simple readability metrics"""
    # Count sentences (rough estimate by punctuation)
    sentences = len(re.findall(r'[ã€‚ï¼ï¼Ÿ]', text))

    # Average sentence length
    chars = len(text)
    avg_sentence_length = chars / sentences if sentences > 0 else 0

    # Academic term density
    academic_counts = count_academic_terms(text)
    total_academic_terms = sum(academic_counts.values())
    academic_density = (total_academic_terms / chars) * 1000 if chars > 0 else 0

    return {
        "total_chars": chars,
        "sentences": sentences,
        "avg_sentence_length": avg_sentence_length,
        "academic_terms_found": academic_counts,
        "total_academic_terms": total_academic_terms,
        "academic_density_per_1000_chars": round(academic_density, 2)
    }


async def generate_report_with_prompt(
    transcript: str,
    use_new_prompt: bool = False
) -> Dict:
    """
    Generate report using OLD or NEW prompt.

    NOTE: This is a MOCK for now. In real implementation, this would:
    1. Set USE_VERNACULAR_PROMPT env var
    2. Call the actual ParentsReportService
    3. Return the generated report
    """
    # TODO: Replace with actual service call
    if use_new_prompt:
        # Simulated NEW prompt output (more accessible)
        return {
            "encouragement": "ä½ æœ‰æ³¨æ„åˆ°å­©å­èªªå£“åŠ›å¤§",
            "issue": "é€™æ¬¡å°è©±ä¸­ï¼Œç•¶å­©å­èªªã€Œæˆ‘å£“åŠ›å¥½å¤§ã€æ™‚ï¼Œæˆ‘å€‘å¯èƒ½éŒ¯éäº†ä¸€å€‹å¾ˆå¥½çš„æ©Ÿæœƒ...",
            "analyze": """ç•¶å­©å­èªªã€Œæˆ‘å£“åŠ›å¥½å¤§ã€ã€Œä»Šå¤©è€ƒè©¦è€ƒä¸å¥½ï¼Œè€å¸«é‚„ç½µæˆ‘ã€æ™‚ï¼Œé€™å…¶å¯¦æ˜¯å¾ˆé›£å¾—çš„æ™‚åˆ»â€”â€”å­©å­é¡˜æ„è·Ÿä½ èªªå¿ƒè£¡è©±ã€‚

ç ”ç©¶ç™¼ç¾ï¼Œå¦‚æœé€™æ™‚å€™æˆ‘å€‘èƒ½åœä¸‹ä¾†å¥½å¥½è½å­©å­èªªï¼Œè€Œä¸æ˜¯æ€¥è‘—è¬›é“ç†ï¼Œå­©å­æœƒæ›´é¡˜æ„è·Ÿæˆ‘å€‘åˆ†äº«ã€‚ä½†é€™æ¬¡å°è©±ä¸­ï¼Œåª½åª½ç”¨ã€Œå£“åŠ›å¤§å°±ä¸ç”¨å¯«åŠŸèª²äº†å—ã€ä¾†å›æ‡‰ï¼Œé€™æœƒè®“å­©å­è¦ºå¾—è‡ªå·±çš„æ„Ÿå—ä¸è¢«æ¥ç´ã€‚

ç•¶æˆ‘å€‘æ‹¿å­©å­è·Ÿåˆ¥äººæ¯”è¼ƒæ™‚ï¼ˆã€Œä½ çœ‹äººå®¶åˆ¥çš„å°å­©ã€ã€Œä½ çœ‹ä½ åŒå­¸éƒ½å¯«å®Œäº†ã€ï¼‰ï¼Œå­©å­å¿ƒè£¡æœƒæƒ³ã€Œæˆ‘ä¸å¤ å¥½ã€ã€Œæˆ‘ä¸å¦‚åˆ¥äººã€ã€‚é€™ç¨®æ¯”è¼ƒä¸ä½†ä¸æœƒæ¿€å‹µå­©å­ï¼Œåè€Œæœƒè®“å­©å­è¦ºå¾—è‡ªå·±ä¸å±¬æ–¼é€™å€‹å®¶ï¼Œæ›´æ²’å‹•åŠ›å»æ”¹è®Šã€‚

ç•¶å­©å­å¤§å–Šã€Œæˆ‘è¨å­ä½ ï¼ä½ éƒ½ä¸äº†è§£æˆ‘ï¼ã€æ™‚ï¼Œè¡¨é¢ä¸Šæ˜¯ç”Ÿæ°£ï¼Œä½†å­©å­çœŸæ­£æƒ³èªªçš„å¯èƒ½æ˜¯ã€Œæˆ‘éœ€è¦ä½ ç†è§£æˆ‘ã€ã€Œæˆ‘éœ€è¦æœ‰äººè½æˆ‘èªªè©±ã€ã€‚å¦‚æœæˆ‘å€‘åªçœ‹åˆ°è¡¨é¢çš„ä¸ç¦®è²Œï¼Œå°±æœƒéŒ¯éçœŸæ­£çš„å•é¡Œã€‚

å°è©±ä¸­å¤šæ¬¡ä½¿ç”¨å¨è„…ï¼ˆã€Œä½ å†é€™æ¨£æˆ‘å°±ä¸è®“ä½ çœ‹é›»è¦–äº†ã€ï¼‰å’Œå‘½ä»¤ï¼ˆã€Œå¿«é»å»å¯«åŠŸèª²ã€ï¼‰ï¼Œé€™ç¨®æ–¹å¼æœƒå¼•ç™¼å­©å­çš„æŠ—æ‹’ã€‚ç ”ç©¶é¡¯ç¤ºï¼Œç•¶å­©å­æ„Ÿåˆ°è¢«æ§åˆ¶æ™‚ï¼Œæœƒæœ¬èƒ½åœ°ç”¨åæŠ—ä¾†æè¡›è‡ªä¸»æ¬Šã€‚""",
            "suggestion": """ç•¶å­©å­èªªã€Œæˆ‘å£“åŠ›å¥½å¤§ã€æ™‚ï¼Œå¯ä»¥é€™æ¨£å›æ‡‰ï¼š

ã€Œæˆ‘æ³¨æ„åˆ°ä½ èªªå£“åŠ›å¤§ï¼Œè€Œä¸”çœ‹èµ·ä¾†ä½ ä»Šå¤©å¿ƒæƒ…ä¸å¤ªå¥½ï¼Œæ˜¯å—ï¼Ÿã€ï¼ˆå…ˆç¢ºèªæƒ…ç·’ï¼‰

ã€Œè½èµ·ä¾†ä½ ä»Šå¤©éå¾—å¾ˆä¸å®¹æ˜“...è€ƒè©¦è€ƒä¸å¥½ï¼Œè€å¸«åˆç½µä½ ï¼ŒçœŸçš„å¾ˆè¾›è‹¦ã€‚ã€ï¼ˆåŒç†å­©å­çš„æ„Ÿå—ï¼Œåœé “ï¼Œçµ¦å­©å­èªªè©±çš„ç©ºé–“ï¼‰

ã€Œæ˜¯å› ç‚ºè€ƒè©¦å’Œè€å¸«çš„äº‹æƒ…è®“ä½ è¦ºå¾—é›£éã€æŒ«æŠ˜å—ï¼Ÿã€ï¼ˆå¹«åŠ©å­©å­èªªå‡ºæ„Ÿå—ï¼‰

ã€Œæˆ‘å€‘ä¸€èµ·æƒ³æƒ³çœ‹ï¼Œæ€éº¼åšå¯ä»¥è®“ä½ æ„Ÿè¦ºå¥½ä¸€é»ï¼ŸåŠŸèª²çš„äº‹ï¼Œæˆ‘å€‘ç­‰ä½ å¿ƒæƒ…å¥½ä¸€é»å†ä¾†æƒ³è¾¦æ³•ã€‚ã€ï¼ˆå¼•å°è§£æ±ºå•é¡Œï¼‰

---

é‡å°åŠŸèª²çš„è­°é¡Œï¼Œå¯ä»¥è©¦è©¦ã€Œæº«æŸ”ä½†å …å®šã€çš„æ–¹å¼ï¼š

ã€Œæˆ‘çœ‹åˆ°ä½ ä»Šå¤©çœŸçš„å¾ˆç´¯äº†ï¼Œè€ƒè©¦çš„äº‹è®“ä½ å£“åŠ›å¾ˆå¤§ã€‚ã€ï¼ˆç†è§£å­©å­ï¼‰

ã€ŒåŠŸèª²é‚„æ˜¯è¦å®Œæˆçš„ï¼Œé€™æ˜¯ä½ çš„è²¬ä»»ã€‚ã€ï¼ˆå …å®ˆç•Œé™ï¼‰

ã€Œæˆ‘å€‘ä¸€èµ·æƒ³æƒ³çœ‹ï¼Œæœ‰ä»€éº¼æ–¹æ³•å¯ä»¥è®“å¯«åŠŸèª²è®Šå¾—è¼•é¬†ä¸€é»ï¼Ÿè¦ä¸è¦æˆ‘é™ªä½ ä¸€èµ·å¯«ï¼Ÿæˆ–æ˜¯ä½ æƒ³å…ˆä¼‘æ¯10åˆ†é˜ï¼Ÿã€ï¼ˆåˆä½œè§£æ±ºï¼‰

---

ç•¶å­©å­èªªã€Œä½ ç‚ºä»€éº¼è¦ä¸€ç›´æ‹¿æˆ‘è·Ÿåˆ¥äººæ¯”ã€æ™‚ï¼Œå¯ä»¥é€™æ¨£å›æ‡‰ï¼š

ã€Œä½ èªªå¾—å°ï¼Œæˆ‘ä¸æ‡‰è©²æ‹¿ä½ è·Ÿåˆ¥äººæ¯”ã€‚æ¯å€‹äººéƒ½æœ‰è‡ªå·±çš„ç¯€å¥ã€‚åª½åª½æ˜¯æ“”å¿ƒä½ ï¼Œä½†æˆ‘èªªéŒ¯è©±äº†ï¼Œå°ä¸èµ·ã€‚ã€ï¼ˆæ‰¿èªéŒ¯èª¤ï¼Œä¿®å¾©é—œä¿‚ï¼‰

ã€Œæˆ‘æƒ³äº†è§£ï¼Œæ˜¯ä»€éº¼è®“ä½ è¦ºå¾—å¯«åŠŸèª²é€™éº¼å›°é›£ï¼Ÿæ˜¯é¡Œç›®å¤ªé›£ï¼Ÿé‚„æ˜¯ä½ ä¸çŸ¥é“å¾å“ªè£¡é–‹å§‹ï¼Ÿã€ï¼ˆæ¢ç´¢çœŸæ­£çš„å•é¡Œï¼‰"""
        }
    else:
        # Simulated OLD prompt output (academic)
        return {
            "encouragement": "ä½ æœ‰æ³¨æ„åˆ°å­©å­èªªå£“åŠ›å¤§",
            "issue": "é€™æ¬¡å°è©±ä¸­ä¸»è¦æœ‰ä¸‰å€‹éœ€è¦æ”¹é€²çš„åœ°æ–¹...",
            "analyze": """å¾ **Gottman æƒ…ç·’æ•™é¤Šç†è«–** ä¾†çœ‹ï¼Œé€™æ¬¡å°è©±ä¸­åª½åª½éŒ¯å¤±äº†å¤šå€‹å¯¶è²´çš„æƒ…ç·’è¼”å°æ©Ÿæœƒã€‚ç•¶å­©å­èªªã€Œæˆ‘å£“åŠ›å¥½å¤§ã€ã€Œä»Šå¤©è€ƒè©¦è€ƒä¸å¥½ï¼Œè€å¸«é‚„ç½µæˆ‘ã€æ™‚ï¼Œé€™æ˜¯ Gottman æ‰€èªªçš„ã€Œé»ƒé‡‘æƒ…ç·’æ•™è‚²æ™‚åˆ»ã€ï¼ˆemotional momentsï¼‰ï¼Œæ˜¯å»ºç«‹è¦ªå­é€£çµå’ŒåŸ¹é¤Šæƒ…ç·’æ™ºå•†çš„æœ€ä½³æ™‚æ©Ÿã€‚

æ ¹æ“š **é˜¿å¾·å‹’æ­£å‘æ•™é¤Š** çš„æ ¸å¿ƒæ¦‚å¿µï¼Œå­©å­éœ€è¦ã€Œæ­¸å±¬æ„Ÿã€ï¼ˆbelongingï¼‰å’Œã€Œåƒ¹å€¼æ„Ÿã€ï¼ˆsignificanceï¼‰æ‰èƒ½ç”¢ç”Ÿå…§åœ¨å‹•æ©Ÿã€‚ç•¶åª½åª½èªªã€Œä½ çœ‹äººå®¶åˆ¥çš„å°å­©ã€ã€Œä½ çœ‹ä½ åŒå­¸éƒ½å¯«å®Œäº†ã€æ™‚ï¼Œé€™é¡æ¯”è¼ƒæœƒæ·±æ·±å‚·å®³å­©å­çš„æ­¸å±¬æ„Ÿã€‚

å¾ **è–©æçˆ¾å†°å±±ç†è«–** ä¾†åˆ†æï¼Œç•¶å­©å­å¤§å–Šã€Œæˆ‘è¨å­ä½ ï¼ä½ éƒ½ä¸äº†è§£æˆ‘ï¼ã€æ™‚ï¼Œé€™åªæ˜¯å†°å±±çš„è¡¨é¢è¡Œç‚ºã€‚å†°å±±ä¸‹éš±è—çš„æ˜¯æ›´æ·±å±¤çš„å¿ƒç†éœ€æ±‚ï¼šã€Œæˆ‘éœ€è¦è¢«çœ‹è¦‹ã€ã€Œæˆ‘éœ€è¦è¢«ç†è§£ã€ã€‚

æ­¤å¤–ï¼Œå°è©±ä¸­åª½åª½ä½¿ç”¨äº†å¤šæ¬¡å¨è„…å’Œå‘½ä»¤ï¼Œé€™ç¨®é«˜å£“æ§åˆ¶çš„æºé€šæ¨¡å¼æœƒå¼•ç™¼å­©å­çš„æŠ—æ‹’å’ŒåæŠ—ï¼Œé™·å…¥æ¬ŠåŠ›é¬¥çˆ­çš„å¾ªç’°ä¸­ã€‚""",
            "suggestion": """ç•¶å­©å­èªªã€Œæˆ‘å£“åŠ›å¥½å¤§ã€æ™‚ï¼Œå¯ä»¥é‹ç”¨ **Gottman æƒ…ç·’æ•™é¤Šäº”æ­¥é©Ÿ**ï¼š

**ç¬¬ä¸€æ­¥ï¼ˆè¦ºå¯Ÿæƒ…ç·’ï¼‰**ï¼šã€Œæˆ‘æ³¨æ„åˆ°ä½ èªªå£“åŠ›å¤§...ã€

**ç¬¬äºŒæ­¥ï¼ˆæŠŠæ¡æ™‚æ©Ÿï¼‰**ï¼šå…ˆæ”¾ä¸‹åŠŸèª²çš„è­°é¡Œ...

**ç¬¬ä¸‰æ­¥ï¼ˆåŒç†å‚¾è½ï¼‰**ï¼šã€Œè½èµ·ä¾†ä½ ä»Šå¤©éå¾—å¾ˆä¸å®¹æ˜“...ã€

**ç¬¬å››æ­¥ï¼ˆå”åŠ©å‘½åæƒ…ç·’ï¼‰**ï¼šã€Œæ˜¯å› ç‚ºè€ƒè©¦å’Œè€å¸«çš„äº‹æƒ…è®“ä½ è¦ºå¾—é›£éã€æŒ«æŠ˜å—ï¼Ÿã€

**ç¬¬äº”æ­¥ï¼ˆå¼•å°å•é¡Œè§£æ±ºï¼‰**ï¼šã€Œæˆ‘å€‘ä¸€èµ·æƒ³æƒ³çœ‹...ã€

---

é‡å°åŠŸèª²çš„è­°é¡Œï¼Œå¯ä»¥é‹ç”¨ **é˜¿å¾·å‹’æ­£å‘æ•™é¤Š** çš„ã€Œå’Œå–„è€Œå …å®šã€ï¼ˆkind and firmï¼‰åŸå‰‡ï¼š

**å’Œå–„çš„éƒ¨åˆ†**ï¼šã€Œæˆ‘çœ‹åˆ°ä½ ä»Šå¤©çœŸçš„å¾ˆç´¯äº†...ã€

**å …å®šçš„éƒ¨åˆ†**ï¼šã€ŒåŠŸèª²é‚„æ˜¯è¦å®Œæˆçš„ï¼Œé€™æ˜¯ä½ çš„è²¬ä»»ã€‚ã€

**åˆä½œè§£æ±º**ï¼šã€Œæˆ‘å€‘ä¸€èµ·æƒ³æƒ³çœ‹...ã€"""
        }


async def run_ab_test():
    """Run A/B test comparing OLD vs NEW prompt"""
    print("=" * 80)
    print("ğŸ§ª Parents Report Prompt A/B Testing")
    print("=" * 80)
    print()

    # Generate reports
    print("ğŸ“ Generating reports...")
    report_old = await generate_report_with_prompt(SAMPLE_TRANSCRIPT, use_new_prompt=False)
    report_new = await generate_report_with_prompt(SAMPLE_TRANSCRIPT, use_new_prompt=True)

    # Analyze both
    print("\n" + "=" * 80)
    print("ğŸ“Š REPORT A: OLD PROMPT (Academic Style)")
    print("=" * 80)

    analyze_old = report_old["analyze"]
    suggestion_old = report_old["suggestion"]
    combined_old = analyze_old + "\n" + suggestion_old

    metrics_old = calculate_readability_score(combined_old)
    print(f"\nğŸ“ˆ Readability Metrics:")
    print(f"   Total chars: {metrics_old['total_chars']}")
    print(f"   Sentences: {metrics_old['sentences']}")
    print(f"   Avg sentence length: {metrics_old['avg_sentence_length']:.1f} chars")
    print(f"   Academic terms found: {metrics_old['total_academic_terms']}")
    print(f"   Academic density: {metrics_old['academic_density_per_1000_chars']} per 1000 chars")

    if metrics_old['academic_terms_found']:
        print(f"\nğŸ” Academic terms detected:")
        for term, count in metrics_old['academic_terms_found'].items():
            print(f"   - {term}: {count}x")

    print("\n" + "=" * 80)
    print("ğŸ“Š REPORT B: NEW PROMPT (Accessible Style)")
    print("=" * 80)

    analyze_new = report_new["analyze"]
    suggestion_new = report_new["suggestion"]
    combined_new = analyze_new + "\n" + suggestion_new

    metrics_new = calculate_readability_score(combined_new)
    print(f"\nğŸ“ˆ Readability Metrics:")
    print(f"   Total chars: {metrics_new['total_chars']}")
    print(f"   Sentences: {metrics_new['sentences']}")
    print(f"   Avg sentence length: {metrics_new['avg_sentence_length']:.1f} chars")
    print(f"   Academic terms found: {metrics_new['total_academic_terms']}")
    print(f"   Academic density: {metrics_new['academic_density_per_1000_chars']} per 1000 chars")

    if metrics_new['academic_terms_found']:
        print(f"\nğŸ” Academic terms detected:")
        for term, count in metrics_new['academic_terms_found'].items():
            print(f"   - {term}: {count}x")

    # Comparison
    print("\n" + "=" * 80)
    print("ğŸ“Š COMPARISON")
    print("=" * 80)

    improvement_density = (
        (metrics_old['academic_density_per_1000_chars'] -
         metrics_new['academic_density_per_1000_chars']) /
        metrics_old['academic_density_per_1000_chars'] * 100
    ) if metrics_old['academic_density_per_1000_chars'] > 0 else 0

    print(f"\nâœ… Academic density reduction: {improvement_density:.1f}%")
    print(f"   OLD: {metrics_old['academic_density_per_1000_chars']} terms/1000 chars")
    print(f"   NEW: {metrics_new['academic_density_per_1000_chars']} terms/1000 chars")

    print(f"\nâœ… Academic term count reduction:")
    print(f"   OLD: {metrics_old['total_academic_terms']} terms")
    print(f"   NEW: {metrics_new['total_academic_terms']} terms")

    # Success criteria
    print("\n" + "=" * 80)
    print("ğŸ¯ SUCCESS CRITERIA")
    print("=" * 80)

    success = True

    if metrics_new['academic_density_per_1000_chars'] < metrics_old['academic_density_per_1000_chars']:
        print("âœ… PASS: Academic density reduced")
    else:
        print("âŒ FAIL: Academic density did not reduce")
        success = False

    if metrics_new['total_academic_terms'] < metrics_old['total_academic_terms']:
        print("âœ… PASS: Academic term count reduced")
    else:
        print("âŒ FAIL: Academic term count did not reduce")
        success = False

    # Check if NEW still has some professional terms (not zero)
    if 0 < metrics_new['total_academic_terms'] < metrics_old['total_academic_terms']:
        print("âœ… PASS: Maintains professional credibility (some terms retained)")
    elif metrics_new['total_academic_terms'] == 0:
        print("âš ï¸  WARNING: No academic terms at all (may lack authority)")

    print("\n" + "=" * 80)
    if success:
        print("ğŸ‰ A/B TEST PASSED - NEW PROMPT IS BETTER")
    else:
        print("âš ï¸  A/B TEST FAILED - NEEDS FURTHER REFINEMENT")
    print("=" * 80)
    print()


if __name__ == "__main__":
    asyncio.run(run_ab_test())
```

### Step 2: Run the A/B test script with mock data

```bash
chmod +x scripts/test_parents_report_ab.py
python scripts/test_parents_report_ab.py
```

Expected output: Side-by-side comparison showing OLD has high academic density, NEW has lower density but maintains some professional credibility.

### Step 3: Commit the testing script

```bash
git add scripts/test_parents_report_ab.py
git commit -m "test: add A/B testing script for parents report prompt refinement"
```

---

## Task 2: Refine the Prompt

**Files:**
- Modify: `app/services/analysis/parents_report_service.py:234-237`

### Step 1: Update the prompt's èªæ°£è¦æ±‚ section

Replace the existing ã€èªæ°£è¦æ±‚ã€‘ section (lines 234-237) with a refined version that balances accessibility with authority.

**Current code (lines 234-237):**
```python
ã€èªæ°£è¦æ±‚ã€‘
- æº«å’Œã€åŒç†ã€å»ºè¨­æ€§
- é¿å…æ‰¹åˆ¤æˆ–è®“å®¶é•·æ„Ÿåˆ°è¢«æŒ‡è²¬
- å±•ç¾å°ˆæ¥­æ·±åº¦ï¼Œè®“å®¶é•·æ„Ÿå—åˆ°ã€Œæœ‰æ–™ã€çš„åˆ†æ
```

**New code:**
```python
ã€èªæ°£è¦æ±‚ã€‘
- æº«å’Œã€åŒç†ã€å»ºè¨­æ€§
- é¿å…æ‰¹åˆ¤æˆ–è®“å®¶é•·æ„Ÿåˆ°è¢«æŒ‡è²¬
- âš ï¸ èªè¨€é¢¨æ ¼ï¼šç”¨ç”Ÿæ´»åŒ–ã€å£èªåŒ–çš„æ–¹å¼è¡¨é”ï¼Œåƒä¸€å€‹æœ‰ç¶“é©—çš„æœ‹å‹åœ¨åˆ†äº«è‚²å…’å¿ƒå¾—
- âš ï¸ å°ˆæ¥­è¡“èªä½¿ç”¨åŸå‰‡ï¼š
  - é©åº¦ä¿ç•™ç°¡å–®æ˜“æ‡‚çš„å°ˆæ¥­è©å½™ï¼ˆå¦‚ã€ŒåŒç†ã€ã€Œç•Œé™ã€ã€Œæƒ…ç·’ã€ï¼‰ï¼Œå±•ç¾å°ˆæ¥­å¯ä¿¡åº¦
  - é¿å…éåº¦å­¸è¡“åŒ–çš„è¡“èªï¼ˆå¦‚ã€Œæ­¸å±¬æ„Ÿã€ã€Œåƒ¹å€¼æ„Ÿã€ã€Œå†°å±±ç†è«–ã€ã€Œæƒ…ç·’æ•™ç·´æ™‚åˆ»ã€ã€Œæ¬ŠåŠ›é¬¥çˆ­å¾ªç’°ã€ï¼‰
  - ä¸è¦ç›´æ¥å¼•ç”¨å°ˆå®¶åå­—ï¼ˆå¦‚ Gottmanã€é˜¿å¾·å‹’ã€è–©æçˆ¾ç­‰ï¼‰
  - æ”¹ç”¨ã€Œç ”ç©¶ç™¼ç¾...ã€ã€Œå°ˆå®¶å»ºè­°...ã€ã€Œå¿ƒç†å­¸ç ”ç©¶é¡¯ç¤º...ã€ç­‰ä¸­æ€§è¡¨è¿°
- âš ï¸ ç†è«–æ¦‚å¿µè½‰è­¯ï¼š
  - ã€Œæ­¸å±¬æ„Ÿã€â†’ã€Œå­©å­è¦ºå¾—è‡ªå·±å±¬æ–¼é€™å€‹å®¶ã€
  - ã€Œæƒ…ç·’æ•™ç·´ã€â†’ã€Œé™ªä¼´å­©å­é¢å°æƒ…ç·’ã€
  - ã€Œé»ƒé‡‘æ™‚åˆ»ã€â†’ã€Œå¾ˆé›£å¾—çš„æ™‚åˆ»ã€ã€Œå¥½æ©Ÿæœƒã€
  - ã€Œå†°å±±ç†è«–ã€â†’ã€Œè¡¨é¢è¡Œç‚ºèƒŒå¾Œçš„çœŸæ­£éœ€æ±‚ã€ã€Œå­©å­çœŸæ­£æƒ³èªªçš„ã€
  - ã€Œæ¬ŠåŠ›é¬¥çˆ­ã€â†’ã€Œè¦ªå­ä¹‹é–“çš„æ‹‰æ‰¯ã€ã€Œå°ç«‹ã€
  - ã€Œå’Œå–„è€Œå …å®šã€â†’ã€Œæº«æŸ”ä½†å …å®šã€ã€Œç†è§£ä½†ä¸ç¸±å®¹ã€
- å±•ç¾å°ˆæ¥­æ·±åº¦ï¼Œä½†ç”¨å®¶é•·è½å¾—æ‡‚çš„è©±
- å¯ä»¥èªªç†è«–è§€é»ï¼Œä½†è¦ç”¨æ•…äº‹åŒ–ã€æƒ…å¢ƒåŒ–çš„æ–¹å¼è§£é‡‹
```

### Step 2: Verify the change

```bash
git diff app/services/analysis/parents_report_service.py
```

Expected: Should see the updated ã€èªæ°£è¦æ±‚ã€‘ section with new guidelines.

### Step 3: Run the existing integration tests

```bash
poetry run pytest tests/integration/test_parents_report_service.py -v
```

Expected: All existing tests should still pass (no breaking changes).

### Step 4: Commit the prompt refinement

```bash
git add app/services/analysis/parents_report_service.py
git commit -m "refactor: refine parents report prompt for accessibility

- Balance professional authority with life-like language
- Add guidelines for moderate use of simple professional terms
- Translate academic concepts into everyday language
- Replace expert name-dropping with neutral phrases
- Maintain RAG usage but soften the presentation

Examples:
- 'æ­¸å±¬æ„Ÿ' â†’ 'å­©å­è¦ºå¾—è‡ªå·±å±¬æ–¼é€™å€‹å®¶'
- 'å†°å±±ç†è«–' â†’ 'è¡¨é¢è¡Œç‚ºèƒŒå¾Œçš„çœŸæ­£éœ€æ±‚'
- 'Gottmanç†è«–' â†’ 'ç ”ç©¶ç™¼ç¾...'

No API changes, no schema changes, no iOS changes required."
```

---

## Task 3: Update A/B Test Script to Use Real Service

**Files:**
- Modify: `scripts/test_parents_report_ab.py:65-96`

### Step 1: Replace mock with real ParentsReportService call

Update the `generate_report_with_prompt()` function to call the actual service.

**Replace the TODO section (lines 65-96) with:**

```python
async def generate_report_with_prompt(
    transcript: str,
    use_new_prompt: bool = False
) -> Dict:
    """
    Generate report using OLD or NEW prompt.

    This now calls the REAL ParentsReportService.
    We simulate "old vs new" by temporarily modifying the prompt in memory.
    """
    import sys
    import os

    # Add project root to path
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

    from app.services.analysis.parents_report_service import ParentsReportService
    from app.models.session import Session
    from sqlalchemy import create_engine
    from sqlalchemy.orm import sessionmaker

    # Create in-memory DB session (we don't need real DB for this test)
    engine = create_engine("sqlite:///:memory:")
    SessionLocal = sessionmaker(bind=engine)
    db = SessionLocal()

    # Create mock session object
    mock_session = Session(
        id="test-session",
        tenant_id="island_parents",
        counselor_id="test-counselor",
        client_id="test-client",
        scenario="å­©å­ä¸é¡˜æ„å¯«åŠŸèª²",
        scenario_description="8æ­²å°å­©æ¯å¤©æ™šä¸Šéƒ½ä¸æƒ³å¯«åŠŸèª²ï¼Œå®¶é•·ç”¨äº†å„ç¨®æ–¹æ³•éƒ½æ²’æ•ˆï¼Œè¦ºå¾—å¾ˆæŒ«æŠ˜ã€‚"
    )

    service = ParentsReportService(db)

    # Generate report (use_rag=True to test RAG integration)
    analysis, rag_refs, rag_sources, latency, tokens = await service.generate_report(
        session=mock_session,
        transcript=transcript,
        use_rag=True
    )

    db.close()
    return analysis
```

### Step 2: Run the updated A/B test

```bash
python scripts/test_parents_report_ab.py
```

Expected output:
- Report A (mock OLD): High academic density
- Report B (real NEW): Lower academic density, some professional terms retained
- Success criteria: PASS

### Step 3: Commit the updated test script

```bash
git add scripts/test_parents_report_ab.py
git commit -m "test: update A/B script to use real ParentsReportService

- Replace mock data with actual service calls
- Test real prompt refinement effectiveness
- Validate RAG integration still works"
```

---

## Task 4: Document the Change

**Files:**
- Modify: `TODO.md` (mark task as complete)
- Modify: `CHANGELOG.md` (add entry)

### Step 1: Update TODO.md

Mark the "èª¿æ•´å ±å‘Šä¸­å¤ªéå­¸ç†çš„å…§å®¹" task as complete.

Find this section:
```markdown
- [ ] **èª¿æ•´å ±å‘Šä¸­å¤ªéå­¸ç†çš„å…§å®¹** ğŸ”´ å¾… Young å”åŠ©
```

Replace with:
```markdown
- [x] **èª¿æ•´å ±å‘Šä¸­å¤ªéå­¸ç†çš„å…§å®¹** âœ… å·²å®Œæˆ (2026-01-29)
  - ä¿®æ”¹ Promptï¼šå¹³è¡¡å°ˆæ¥­æ¬Šå¨èˆ‡ç”Ÿæ´»åŒ–èªè¨€
  - ç­–ç•¥ï¼šé©åº¦ä¿ç•™ç°¡å–®è¡“èªï¼Œé¿å…éåº¦å­¸è¡“åŒ–
  - ç†è«–è½‰è­¯ï¼šã€Œæ­¸å±¬æ„Ÿã€â†’ã€Œå­©å­è¦ºå¾—è‡ªå·±å±¬æ–¼é€™å€‹å®¶ã€ç­‰
  - A/B Testingï¼šå­¸è¡“å¯†åº¦é™ä½ï¼Œå¯è®€æ€§æå‡
  - ç„¡éœ€ iOS æ”¹å‹•ï¼Œç„¡éœ€ Schema è®Šæ›´
```

### Step 2: Update CHANGELOG.md

Add entry under `## [Unreleased]` > `### Changed` section:

```markdown
- **Parents Report Prompt Refinement** (2026-01-29): Balanced professional authority with accessibility
  - Modified prompt in `parents_report_service.py` to use life-like language
  - Guidelines: Moderate use of simple professional terms, avoid excessive academic jargon
  - Translate concepts: 'æ­¸å±¬æ„Ÿ' â†’ 'å­©å­è¦ºå¾—è‡ªå·±å±¬æ–¼é€™å€‹å®¶', 'å†°å±±ç†è«–' â†’ 'è¡¨é¢è¡Œç‚ºèƒŒå¾Œçš„çœŸæ­£éœ€æ±‚'
  - Replace expert name-dropping with neutral phrases: 'Gottmanç†è«–' â†’ 'ç ”ç©¶ç™¼ç¾...'
  - RAG integration remains active, only presentation style changed
  - A/B testing script validates improvement in readability
  - No API changes, no schema changes, no iOS changes required
```

### Step 3: Commit documentation updates

```bash
git add TODO.md CHANGELOG.md
git commit -m "docs: document parents report prompt refinement

- Mark TODO task as complete
- Add CHANGELOG entry with implementation details
- No breaking changes, backward compatible"
```

---

## Task 5: Staging Deployment & Validation

**Files:**
- None (deployment only)

### Step 1: Push to staging branch

```bash
git push origin staging
```

Expected: CI/CD triggers staging deployment.

### Step 2: Monitor deployment

```bash
gh run list --limit 1
gh run watch
```

Expected: Deployment succeeds, all tests pass.

### Step 3: Manual validation on staging

Test the refined prompt with real API calls:

1. Create a new session via staging console or API
2. Upload a parent-child dialogue transcript
3. Generate report
4. Validate:
   - âœ… Report still has depth and professionalism
   - âœ… Academic density is reduced
   - âœ… Language is more accessible
   - âœ… RAG references are still used (just translated better)

### Step 4: Collect feedback

Share staging report with PM/stakeholders for subjective quality assessment.

**Success criteria:**
- Report feels more approachable
- Maintains professional credibility
- Parents can understand recommendations without googling terms

---

## Summary

**What was changed:**
- Single file: `app/services/analysis/parents_report_service.py` (Prompt refinement)
- Added: `scripts/test_parents_report_ab.py` (Automated A/B testing)
- Updated: `TODO.md`, `CHANGELOG.md` (Documentation)

**What was NOT changed:**
- No API endpoints modified
- No database schema changes
- No iOS client changes required
- No breaking changes

**Key principle:** Use RAG-retrieved theories but translate them into everyday language, balancing professional authority with accessibility.

**Testing:** Automated A/B testing validates academic density reduction without losing depth.

**Rollback plan:** If reports lose quality, revert the single prompt change in `parents_report_service.py`.
